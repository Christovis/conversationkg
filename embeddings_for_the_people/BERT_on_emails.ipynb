{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel, DistilBertConfig\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Initialise Tokeniser & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defs convert email text to model input and then model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_to_ids(email_body):\n",
    "    return torch.tensor(tokenizer.encode(email_body, add_special_tokens=True))\n",
    "\n",
    "def email_to_vec(email_body_ids, to_id_first=True):\n",
    "    if to_id_first:\n",
    "        input_ids = email_to_ids(email_body)\n",
    "    else:\n",
    "        input_ids = email_body_ids\n",
    "        \n",
    "    input_ids = input_ids.unsqueeze(0)\n",
    "    outputs = model(input_ids)\n",
    "    last_hidden_states = outputs[0][0]\n",
    "    return last_hidden_states.mean(0)  # mean vs sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Load emails and apply tokeniser and conversion to model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../w3c-emails/emails.pkl\", \"rb\") as handle:\n",
    "    emails = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [e.body_raw for e in emails]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_ids = [email_to_ids(t) for t in tqdm(texts)]\n",
    "with open(\"emails_token_ids.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(tok_ids, handle)\n",
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Cut up too emails longer than 512 tokens & group into batches\n",
    "(start from here by loading converted emails from pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"emails_token_ids.pkl\", \"rb\") as handle:\n",
    "    ids = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_up = [id_tens.split(511) for id_tens in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():    \n",
    "    vecs = [[email_to_vec(v, to_id_first=False) for v in tt] for tt in tqdm(cut_up[:5000])]\n",
    "    \n",
    "with open(\"vectors2.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(vecs, handle)\n",
    "    \n",
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vectors.pkl\", \"rb\") as handle:\n",
    "    vecs_loaded = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vecs_loaded), len(vecs_loaded[0]), vecs_loaded[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = [len(t) for t in texts if len(t) < ]\n",
    "\n",
    "plt.hist(lens, bins=30)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
