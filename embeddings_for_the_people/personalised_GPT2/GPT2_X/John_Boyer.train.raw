      Hi Mark,    Actually, I will maintain that exclusion by id only is a bad idea    Inclusion by id is useful because you identify an element whose content WILL  BE in the message digest, so if the identified element's content is changed,  then the message digest will break.    Exclusion by id is bad because you identify an element whose content WILL  NOT BE in the message digest, so if the identified element's content, tag,  attributes, etc. are changed, then the message digest will not break.    The purpose of doing exclusion logic with XPath is that, although it is  possible to do exclusion by id with XPath, it is also possible to do much  better.  One can identify an element, but then add additional tests that  only exclude the element if it has the right properties, properties which  the application author can guarantee do not impact the interpretation of the  signature over the material that is digested.    Exclusion logic is quite unsecure and therefore useless unless appropriate  measures have been taken to be quite specific about what gets excluded.    John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com      -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Mark Bartel  Sent: Monday, March 27, 2000 8:10 AM  (E-mail) ' '  Subject: RE: Enveloped signatures and XPath      Joseph,    Rephrasing my main point, the verifying *application* has to know how the  document was transformed in order to know whether the signature signed  whatever it was supposed to.  The signature engine can check whether the  signature is "valid" but can't do that trust evaluation.  So if there is an  XPath transform, the application has to look at the XPath to decide whether  to trust the document.  With our current spec, an application MUST  understand at least that simple XPath expression in order to use an embedded  signature.  While I'm ok with a signature engine needing to know specific  special XPaths, I'm not comfortable with making that a requirement for any  application that wishes to embed a signature.    So when Petteri suggested that we might create a simpler Transform for  simple exclusion, I thought it was a good idea.    Alternatively, the engine could tell the application "this was a simple  exclusion" but that seems less elegant and would be implementation-specific.  However, if we want to go this way I think we should have specific text in  the draft.    My point about DTDs, Schemas, etc, was just that the application might want  to verify that the document is in a certain form (for document closure, for  example); you can do that with XPath, but you can also do it in other ways.  If you encounter some XPath in a signature that you're not familiar with,  the only general way to determine the effect is to examine the output of the  transforms... one test that could be done is checking validity against a  format or schema.    Basically I think that having only XPath for exclusion makes it complicated  for an application using this specification to decide trust.  I think we  could make it easier by adding a simpler transform.    -Mark Bartel  JetForm    -----Original Message-----  From: Joseph M. Reagle Jr.  Sent: 3/26/2000 4:31 AM  Subject: RE: Enveloped signatures and XPath    On Fri, 24 Mar 2000, Mark Bartel wrote:  > kind of document definition?), or it must understand the XPath  expression  > itself, and "know" that the expression is doing the right things.  It  would  > be much simpler to verify that the exclusion was correct with an IDREF  > exclusion transformation.  "Does the signature itself have the  exclusion id,  > yes or no?"    I'm not exactly sure what you mean by the IDREF exclusion  transformation,  could you provide an example?    > I would like to see an exclusion mechanism that does not involve  > XPath.  The  > fact that the XPath transform can do anything is precisely the reason  > for wanting a simpler transform that can't.    Which is why last time we discussed this we opted for the generality of  XPath, and a specific well defined instance for excluding  SignatureValue,  which Petteri rightfully points out we haven't provided yet (though I  think this is a good path), but ...    > The big difference between the XPath approach and the plain link case  is  > that the verifier is automatically verifying that the document matches  the  > "document definition" when they evaluate the XPath; they can't do  anything  > else.  In the plain link case, the verifier can choose not to test the  > document against the document definition.    I don't recall if this was part of the previous discussion. Something  that  would've been nice to put in (and resolve) in the requirements document  was the necessity of validating the signature (in the XML sense): is the  DTD/schema necessary?    Regardless, Mark, if we provide the profiled Xpath instance for removing  SignatureValue, can't you still code your signature application to its  semantic (as you would do with the other solution) without needing the  DTD? (Find some string 'blah' and remove SignatureValue (be it an Xpath  string or something else.)  Or would the result of the XPath process  and the application 'hack' be intrinsically different (or hard to  make similar)?    And is your concern about DTDs with respect to Signature applications  not  knowing (I doubt this, not too hard to ask Signature applications to  have the DTD/schema around), the fact that whichever XML toolkit you are  using doesn't require them, or the fact that in an Enveloped Signature  you  (by definition) have content from different namespace, which DTDs don't  easily support?        

      Hi,    I have a few concerns that I think can be worked out, so I am requesting  feedback on the information below.  If everything works out, then yes, we  could remove parse() and exact order.    1) On parse(),    I would be in favor of dumping parse() if we can solve ALL of the  implementation problems it solves.  It  solved some interesting, but not too  important problems for XPath transform users, but it also specified how  implementers were to solve certain problems.    Please have a closer look at the output expectations of serialize().  The  serialize() function cannot operate without several features of parse().  In  particular,    i) Serialization of the root node requires that we output the byte order  mark and xmldecl read by parse() on input.  If parse() is not under our  control, we cannot specify that it retains this information.  This would  seem to suggest that root node serialization should result in the empty  string, which in turn suggests that serialize should output in UTF-8  regardless of the input encoding.  That would be OK with me.    ii) Attribute and namespace serialization require a namespace prefix.  Based  on a new read of XPath I believe this information must be available, but I  want to be sure.    iii) If everything else checks out, we can get rid of exact order and just  use lex order provided that lex ordering in UTF-16 results in the same order  as lex ordering in UTF-8 (which is Christopher Maden's claim).    Also, parse() has an additional feature that would need to be dealt with in  some other way:    iv) If the parser used to implement parse() is non-validating, then parse()  is required to throw an exception if it encounters an external reference  that would cause it to interpret the document differently than a validating  parser.  This exception is necessary since an unverifiable signature is  different than an invalid signature.      2) On eliminating exprBOM and exprEncoding.    Sounds fine.  Sounds like any difference of encoding between the Xpath  expression and the transform input will be handled implicitly by the XPath  transform implementation.      3) On automatic serialization,    There was some concern that serialization should be automatic ("why call  serialize() when that's always what we want to do").  Please see the first  paragraph of section 6.6.3.4, which already includes this feature.    Thus if we remove parse(), then there is no *need* to start expressions with  a function call.      4) On providing an initial namespace context    We can provide an initial namespace context as is done in XPointer.    I was reviewing how XPath handles namespaces, and realized that it is  different than what I had previously understood, and it seems broken (so  there must be some good reason why it is done the way its done, or maybe I'm  just misreading the spec).    Section 2.3 says "A QName in the node test is expanded into an expanded-name  using the namespace declarations from the expression context. This is the  same way expansion is done for element type names in start and end-tags  except that the default namespace declared with xmlns is not used: if the  QName does not have a prefix, then the namespace URI is null (this is the  same way attribute names are expanded). It is an error if the QName has a  prefix for which there is no namespace declaration in the expression  context".    This seems to indicate that the input XML document's namespace declarations  are ignored and the expression context's namespace declarations are used  solely.    When XPath claims to be XML namespace compliant, I thought that meant it  would interpret a node's namespace in the context of the namespace  declarations in the document, but that appears not to be true.  To clear  this up, suppose I have an element x:E, and the document containing this  element associates x with www.w3.org, but the expression context associates  x with www.ietf.org, then which value will the namespace-uri() function  applied to x:E return?    If it returns www.ieft.org, then although it seems weird to me that we  aren't using the namespace declarations in the document, it would at least  be good in the sense that it implies XPath implementations have the  namespace prefix kicking around for serialize().    It also would mean that Jonathan Marsh is correct in requiring an initial  namespace context since we could not do ANY namespace comparisons without it  (the XPath seems to say that it is an error to use a QName containing a  namespace prefix in an expression if that namespace prefix is not defined in  the expression context).    I would appreciate your feedback, esp. from those who have sent prior emails  and therefore seem to be most interested in how this turns out.  If you  would please give this some extra priority, I will prepare an alternative  document for consideration before or during the meeting in Adelaide (I  regret that I will not be at that meeting, but I will be at the following  one in Victoria ;-).    John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  jboyer@PureEdge.com      -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of TAMURA Kent  Sent: Friday, March 17, 2000 12:59 AM  Subject: Re: XSL WG comments on XML Signatures        > <John>  > XPath filtering will not be substantially rewritten.  Based on Clark's  > feedback, we can remove the parse function and instead simply assert that  > the transform input is parsed and provided to XPath as a node set.  The  > notions of lex and exact order will be removed (since we cannot directly  > specify the parse).    That's good!  It would be easy to understand, easy to implement,  easy to use.    --  TAMURA Kent @ Tokyo Research Laboratory, IBM        

      Hi Jonathan,    As Donald and Gregor have indicated, the text in Section 4.6 needs to be  tweaked.  When I made the statement in 4.6, I was actually thinking about  the canonical form's node-set, so it's too bad I didn't say it that way :-(,  although Gregor's way of putting it seems better.    So, to be clear, Section 2.3 is correct, and the example does not circumvent  it.  Section 2.3 says that the namespace node is ignored if the *nearest  ancestor* element of the node's parent element **that is in the node-set**  has a namespace node in the node-set with the same local name.  When you  apply the Xpath expression, all of the bar elements and their namespace  declarations disappear from the node-set, which is then representative of  the canonical form's node-set, not the source document's node-set (which  would be a full node-set).    Thanks for bringing this up, and Section 4.6 will be fixed shortly.  John Boyer  Team Leader, Software Development  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>      -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Jonathan Marsh  Sent: Thursday, November 30, 2000 3:49 PM  Subject: Canonical XML typo?      Apologies for missing the CR deadline - this issue just surfaced in our  early implementation efforts.    -------------------  Section 2.3 Processing Model    * Namespace Nodes- A namespace node N is ignored if the nearest  [*]ancestor[*] element of the node's parent element that is in the  node-set has a namespace node in the node-set with the same local name  and value as N. Otherwise, process the namespace node N in the same way  as an attribute node, except assign the local name xmlns to the default  namespace node if it exists (in XPath, the default namespace node has an  empty URI and local name).  -------------------  Section 4.6 Superfluous Namespace Declarations    Unnecessary namespace declarations are not made in the canonical form.  Whether for an empty default namespace, a non-empty default namespace,  or a namespace prefix binding, the XML canonicalization method omits a  declaration if it determines that the [*]immediate parent[*] element in  the canonical form contains an equivalent declaration.  --------------------    Given this input:      <foo xmlns="http://www.example.org">      <bar xmlns="">        <foo xmlns="http://www.example.org">          <bar xmlns="">            <foo xmlns="http://www.example.org">          </bar>        </foo>      </bar>    </foo>    And a nodelist which strips the bar elements, something like:      //.[not(self::bar)] | //namespace::*[not(parent::bar)]    The canonical output would appear to be:      <foo xmlns="http://www.example.org">      <foo>        <foo xmlns="http://www.example.org"/>      </foo>    </foo>    (Please excuse any canonicalization errors or whitespace differences  here that aren't germain to my point.)    It appears that superfluous declarations can still squeak through.  In  other words, this example is so contrived to circumvent section 2.3, by  ensuring that no ancestor in the source document has a duplicate  namespace node.  And 4.6 only applies to immediate parents in the output  document, and not to ancestors, and thus applies to the first child foo,  but not the grandchild foo.    Should "immediate parent" in 4.6 instead be removed in favor of  something that more closely resembled the scoping rules of the Namespace  Spec?    Thanks,    Jonathan Marsh  jmarsh@microsoft.com        

      Hi Joseph,    As you know there is a wonderful debate in the W3C community now about  whether or not namespace URIs should be absolutized.  I'm not on the xml-uri  list, but have mailed this anyway.  Perhaps you could consider posting this  for me if it doesn't show up there.    The newest XBase spec does not mention XPath in the list of affected  specifications, but it is claimed that XBase is required by XLink, which  relies on XPath.    The XPath Recommendation states that URIs are absolutized, but no mechanism  for specifying the base URL is given.  I need to know as soon as possible  whether an erratum to XPath will be issued to state that XBase will be the  way of doing it.  Alternately, will there be an erratum stating that XPath  does not absolutize URIs?    It is very important to our dsig implementers, whose XPath implementations  seem not to absolutize URIs.    By the way, absolutizing URIs does not serve a useful purpose.  The desire  to absolutize seems to be based on the idea that a relative URI in a  namespace declaration might point to different things as a document moves  from machine to machine, and those different documents might alter the  meaning of the namespace qualified element of the document.    Well, there's no point in doing this.  The document's interpretation cannot  be the subject of serious debate unless it is digitally signed.  Even with  an absolute URI, it cannot be guaranteed that the target remains unchanged.  In other words, if you want to claim that the namespace URI is something  more than a string, that it imparts meaning to the document, then you will  be lost unless you compare not URIs but the contents at the URI.  If the  content changes, then it does not matter that the URI has not.  The only way  to do this is to store, within the source document, a digest of the result  of dereferencing the namespace URI.  Now, please don't flood my email box  with statements about how this violates the namespace recommendation because  I am aware of the fact that the namespace rec says that-- that's the bone of  contention people are having in the first place.  All I'm saying is that  absolutizing the URIs is also a violation of the same rec, which says they  should be treated like strings, but if you do want to violate that rec, then  you should first consider the fact that it does you no good.    Whether specified by absolute or relative URI, the digest value of the  namespace qualifying document can be included in a digital signature (if the  namespace URI truly does point to something meaningful).  Once the signature  is effected, the relative URI can remain as long as it always points to a  document with precisely the same digest value (possibly after  canonicalization or other transforms).    The signature is the only way to guarantee that the meaning of the document  has not been changed because of a relative URI in a namespace declaration,  and it does not require you to absolutize the URI to have this guarantee. By  comparison, if you absolutize URIs, it means that the document will only  have verifiable meaning if one can access the original machine that  absolutized the    John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com      -----Original Message-----  From: Joseph M. Reagle Jr. [mailto:reagle@w3.org]  Sent: Thursday, June 08, 2000 8:45 AM  Subject: XML Base WD re-enter Last Call      Forwarded Text ----   Date: Thu, 8 Jun 2000 09:27:01 +0200   From: Daniel Veillard <Daniel.Veillard@w3.org>   To: chairs@w3.org   Organization: World Wide Web Consortium (W3C http://www.w3.org/)   Subject: XML Base WD re-enter Last Call   Status:  O     On behalf of the XML Linking Working Group [1], I am pleased to announce   the publication of a new "XML Base" Last Call Working Draft.     The document addresses is:            http://www.w3.org/TR/xmlbase     This draft was made public 7 June 2000     The Last Call review period will end 28 June 2000. Please   send review comments before that date to   www-xml-linking-comments@w3.org (archives available at [2]).     XML Base, is a missing piece of the XML infrastructure needed for XLink:     ----------   XML Base proposes a syntax for providing the equivalent of HTML BASE   functionality generically in XML documents by defining an XML attribute   named xml:base.   ----------     The mission to bring XBase to REC status was given by the XML Coordination   Group 1999-1129 [5] and the XML Linking WG expect it meets the requirement   of a general purpose base mechanism as defined by RFC 2396 [6]     At their June 1 2000 teleconference [3], the XML Linking   Working Group decided to resubmit XML Base WD to Last Call.   The large amount of comments and the changes made to the   document led the group to estimate that a second Last Call   was in order. The disposition of comments document for the   first Last Call is available at:       http://www.w3.org/2000/06/xmlbase-comments-20000607.html       DEPENDENCIES AND REVIEW     All Group Chairs are invited to send their comments to   the public list.     The Working Group has identified dependencies with the following W3C   Working Groups and requests review from them. Even if review   is not possible, we request that the Chairs listed below   announce their review intentions to www-xml-linking-comments@w3.org   (a public mailing list).     Here is the list of the groups which we think should should review   XBase Last Call working drafts, based on our WG charter and   the history of the XML Linking WG:         - HTML WG, Steven Pemberton <steven.pemberton@cwi.nl>       - SVG WG, Chris Lilley <chris@w3.org>       - I18N WG, Misha Wolf <misha.wolf@reuters.com>       - DOM WG, Lauren Wood <lauren@sqwest.bc.ca>       - SMIL WG, Aaron Cohen <aaron.m.cohen@intel.com>       - XSL WG, Sharon Adler <sca@watson.ibm.com>,                 Steve Zilles <szilles@adobe.com>       - XML Core, Paul Grosso <paul@arbortext.com>,                   Arnaud Le Hors <lehors@us.ibm.com>     There are also the groups from the XML activity which may have some   feedback since we define the language for XML fragment identifiers and   this may impact their work:         - XML Query, Paul Cotton <pcotton@microsoft.com>       - XML Schema, Michael Sperberg-McQueen<cmsmcq@w3.org>,                     Dave Hollander <dmh@commerce.net>     Thank you,     Daniel Veillard,   for Eve Maler, Daniel Veillard, XML Linking Working Group co-chairs     [1] http://www.w3.org/XML/Group/Linking.html   [2] http://lists.w3.org/Archives/Public/www-xml-linking-comments/   [3]  http://lists.w3.org/Archives/Member/w3c-xml-linking-wg/2000Jun/0003.html   [4] http://www.w3.org/XML/Group/1998/09/linking-charter.html   [5] http://lists.w3.org/Archives/Member/w3c-xml-cg/1999Dec/0006.html   [6] http://www.ics.uci.edu/pub/ietf/uri/rfc2396.txt.     --   Daniel.Veillard@w3.org | W3C, INRIA Rhone-Alpes  | Today's Bookmarks :   Tel : +33 476 615 257  | 655, avenue de l'Europe | Linux XML libxml WWW   Fax : +33 476 615 207  | 38330 Montbonnot FRANCE | Gnome rpm2html rpmfind    http://www.w3.org/People/all#veillard%40w3.org  | RPM badminton Kaffe    End Forwarded Text ----    _________________________________________________________  Joseph Reagle Jr.  W3C Policy Analyst                mailto:reagle@w3.org  IETF/W3C XML-Signature Co-Chair   http://www.w3.org/People/Reagle/        

      Hi Merlin,    No, a namespace node is not omitted if the element's parent contains the  same namespace declaration.  Please see [1]    [1] http://www.w3.org/TR/xpath#namespace-nodes    which says,    "This means that an element will have a namespace node:    for every attribute on the element whose name starts with xmlns:;    for every attribute on an ancestor element whose name starts xmlns: unless  the element itself or a nearer ancestor redeclares the prefix;    for an xmlns attribute, if the element or some ancestor has an xmlns  attribute, and the value of the xmlns attribute for the nearest such element  is non-empty  "    Thanks,  John Boyer  PureEdge Solutions Inc.    -----Original Message-----  From: merlin@baltimore.ie [mailto:merlin@baltimore.ie]  Sent: Wednesday, October 11, 2000 2:13 AM  Subject: Re: Tentative signature over C14N examples        Hi,    r/jboyer@PureEdge.com/2000.10.10/16:19:06  ><merlin>  >The C14N of e3 should ?not? have xmlns:w3c.  ></merlin>  >  ><john>  >Actually, it should have the w3c namespace.  Each node receives namespace  >nodes for its entire namespace context, including those derived from its  >ancestors.  ></john>    But are they not emitted from C14N if they are in scope and set for  the nearest parent in the node set?    Merlin    [new xpath]    <!-- Evaluate with declaration xmlns:ietf="http://www.ietf.org" -->    (//. | //@* | //namespace::*)  [     self::ietf:e1 or (parent::ietf:e1 and not(self::text() or self::e2))     or     count(id("E3")|ancestor-or-self::node()) =  count(ancestor-or-self::node())  ]    [document]    <!DOCTYPE doc [  <!ATTLIST e2 xml:space (default|preserve) 'preserve'>  <!ATTLIST e3 id ID #IMPLIED>  ]>  <doc xmlns="http://www.ietf.org" xmlns:w3c="http://www.w3.org">     <e1>        <e2 xmlns="">           <e3 id="E3"/>        </e2>     </e1>  </doc>    [suggested c14n]    <e1 xmlns="http://www.ietf.org" xmlns:w3c="http://www.w3.org"><e3 xmlns=""  xmlns:w3c="http://www.w3.org" id="E3" xml:space="preserve"></e3></e1>    [my c14n]    <e1 xmlns="http://www.ietf.org" xmlns:w3c="http://www.w3.org"><e3 xmlns=""  id="E3" xml:space="preserve"></e3></e1>        

      Hi Jonathan,    At the very least, serialize() needs access to the namespace prefix.    Also, I think that serialization is the one thing that you would not expect  an XPath engine to provide (unlike parsing).  So another justification for  adding serialize() as a function is that we are adding DSig's key  functionality using the XPath-defined extension mechanism (function library  modification).  This maintains the property that dsig is an application of  XPath, not something different that happens to use the XPath expression  syntax.    John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com      -----Original Message-----  From: Jonathan Marsh [mailto:jmarsh@microsoft.com]  Sent: Monday, March 27, 2000 10:27 AM  Donald-LDE008; TAMURA Kent; Christopher R. Maden; Ed Simon  Subject: RE: Enveloped signatures and XPath      "However, serialization must be represented as an XPath function since it  requires access to the internal representation of a node-set (see parsing  requirements)."    What does this mean?    > -----Original Message-----  > From: John Boyer [mailto:jboyer@PureEdge.com]  > Sent: Thursday, March 23, 2000 4:15 PM  > To: IETF/W3C XML-DSig WG (E-mail)  > Cc: Martin J. Duerst; James Clark; Joseph Reagle; Eastlake  > Donald-LDE008; TAMURA Kent; Christopher R. Maden; Jonathan Marsh; Ed  > Simon  > Subject: RE: Enveloped signatures and XPath  >  >  > Attached and Pasted below is the HTML for a new version of the XPath  > transform for your consideration.  If you are on the cc line,  > it is because  > you expressed a special interest and/or have provided  > constructive and very  > helpful feedback on the XPath transform in the recent past.  >  > Although I'm sure it's not the final draft, I am excited by  > the possibility  > that we as a group may be close to a sufficient and easy to  > understand and  > implement version of the XPath transform, so I am asking you  > to please take  > some time to review the new specification as it is a very  > important part of  > meeting our partial XML document signing requirement.  >  > Thanks,  > John Boyer  > Software Development Manager  > PureEdge Solutions, Inc. (formerly UWI.Com)  > jboyer@PureEdge.com  >  >  > Executive overview  > ==================  >  > In accordance with group feedback, the following issues have  > been addressed  >  > 1) The parse() function and $input variable binding has been  > eliminated.  > Instead the root of the input XML document is provided as the  > context node  > of the initial evaluation context.  Certain assumptions about what  > information the parser must retain have been expressed, but  > all of these  > assumptions seem to be necessary to support other  > functionality of XPath.  > Specifically, I assume that the QName of an element,  > attribute or namespace  > node can be created using the information available in the  > parse tree of any  > processor that is bundled with an XPath engine.  >  > 2) Exact order is eliminated; lex order on input is  > eliminated; lex order of  > attribute and namespace nodes in the output has been  > specified in accordance  > with group feedback.  >  > 3) The namespace declarations are initialized to those  > available to the  > XPath element containing the Xpath expression, as is done in XPointer.  >  > 4) Variable bindings for expression byte order mark and  > encoding have been  > eliminated.  Instead we have the assumption that the implementation  > translates to the character domain before evaluating the  > XPath expression,  > which is in accordance with the XPath recommendation.  >  > 5) The serialize() function has been retained in part to simplify  > specification and in part because it needs access to the internal  > representation of a node-set.  However, note that it is automatically  > applied to the XPath transform result, so a) it will almost  > never need to be  > called explicitly, and b) XPath transform expressions need  > not start with a  > function call, which seemed to be the source of some concern.  >  > 6) The output encoding has been standardized to UTF-8.  There does not  > appear to be a better option.  >  > 7) Someone mentioned a problem with namespace nodes.  There  > was something  > that we were not addressing, but I did not understand the  > comment.  If you  > are reading, and it was your comment, could you please reiterate and  > elaborate.  >  > ================================================  >  > <h4>6.6.3 <a name="sec-XPath">XPath</a> Filtering </h4>  >  > <dl>  >   <dt>Identifier: </dt>  >   <dd>http://www.w3.org/TR/1999/REC-xpath-19991116 </dd>  > </dl>  >  > <p>The <a href="#ref-XPath">XPath</a> transform output is the  > result of  > applying an  > XPath expression to an input string. The XPath expression appears in a  > parameter  > element named <code>XPath</code>. The input string is  > equivalent to the  > result  > of dereferencing the URI attribute of the  > <code>Reference</code> element  > containing the  > XPath transform, then, in sequence, applying all transforms  > that appear  > before the XPath  > transform in the <code>Reference</code> element's  > <code>Transforms</code>.</p>  >  > <p>The primary purpose of this transform is to ensure that  > only specifically  > defined  > changes to the input XML document are permitted after the signature is  > affixed.  > The XPath expression can created such that it includes all  > elements except  > those  > meeting specific criteria.  It is the responsibility of the  > XPath expression  > author  > to ensure that all necessary information has been included in  > the output  > such that  > modification of the excluded information does not affect the  > interpretation  > of the  > output in the application context.  One simple example of this is the  > omission of an  > enveloped signature's <code>SignatureValue</code> element.</p>  >  > <h4>6.6.3.1 Evaluation Context Initialization</h4>  >  > <p>The XPath transform establishes the following evaluation  > context for the  > XPath expression given in the <code>XPath</code> parameter  > element:</p>  >  > <ul>  > <li>A <b>context node</b>, initialized to the input XML  > document's root  > node.</LI>  > <li>A <b>context position</b>, initialized to 1.</LI>  > <li>A <b>context size</b>, initialized to 1.</LI>  > <li>A <b>library of functions</b> equal to the function set  > defined in <a  > href="#ref-XPath">XPath</a>  > plus the function <a href="#function-serialize">serialize()</a>.</li>  > <li>A set of variable bindings. No means for initializing  > these is defined.  > Thus, the set of  > variable bindings used when evaluating the XPath expression  > is empty, and  > use of a variable  > reference in the XPath expression results in an error.</li>  > <li>The set of namespace declarations in scope for the XPath  > expression.</li>  > </ul>  >  > <h4>6.6.3.2 Parsing Requirements for XPath Evaluation</h4>  >  > <p>An XML processor is used to read the input XML document  > and produce a  > parse  > tree capable of being used as the initial context node for the XPath  > evaluation, as described in the previous section.  If the  > input is not a  > well-formed XML document, then the XPath transform must throw an  > exception.</p>  >  > <p>Validating and non-validating XML processors only behave  > in the same way  > (e.g. with  > respect to attribute value normalization and entity reference  > definition)  > until an external  > reference is encountered.  If the XPath transform  > implementation uses a  > non-validating processor,  > and it encounters an external reference in the input document, then an  > exception must  > be thrown to indicate that the necessary algorithm is  > unavailable (The XPath  > transform cannot  > simply generate incorrect output since many applications  > distinguish an  > unverifiable  > signature from an invalid signature).</p>  >  > <p>As a result of reading the input with an XML processor,  > linefeeds are  > normalized,  > attribute values are normalized, CDATA sections are replaced by their  > content,  > and entity references are recursively replaced by  > substitution text.  In  > addition,  > consecutive characters are grouped into a single text node.</p>  >  > <p>The XPath implementation is expected to convert the  > information in the  > input XML  > document and the XPath expression string to the character  > domain prior to  > making any  > comparisons such that the result of evaluating the expression  > is equivalent  > regardless  > of the initial encoding of the input XML document and XPath  > expression.</p>  >  > <p>Based on the namespace processing rules of XPath, the  > namespace prefix of  > namespace-qualified nodes must be available in the parse tree.</p>  >  > <p>Based on the expression evaluation requirements of the  > XPath function  > library,  > the <b>document order</b> position of each node must be  > available in the  > parse tree,  > except for the attribute and namespace axes.  The XPath  > transform imposes no  > order  > on attribute and namespace nodes during XPath expression  > evaluation, and  > expressions  > based on attribute or namespace node position are not  > interoperable.  The  > XPath  > transform does define an order for namespace and attribute  > nodes during  > <a href="#function-serialize">serialization</a>.</p>  >  > <h4>6.6.3.3 XPath Transform Functions</h4>  >  > <p>The function library of the XPath transform includes all functions  > defined  > by the XPath specification plus the serialize() function defined  > below.  For most XPath transforms, serialize() need not be  > called explicitly  > since it  > is called automatically if the expression result is a  > node-set.  However,  > serialization  > must be represented as an XPath function since it requires  > access to the  > internal  > representation of a node-set (see parsing requirements).</p>  >  > <p>  > <a name="function-serialize"><b>Function: </b><i>string</i>  > <b>serialize</b>(<i>node-set</i>)</a>  > </p>  >  > <p>This function converts a node-set into a string by generating the  > representative text  > for each node in the node-set.  The nodes of a node-set are  > processed in  > ascending order  > of the nodes' <b>document order</b> positions except for attribute and  > namespace nodes,  > which do not have document order positions.</p>  >  > <p>The nodes in the attribute and namespace axes will each be  > processed in  > lexicographic order,  > with the namespace axis preceding the attribute axis.  Lexicographic  > comparison is performed using  > namespace URI as the primary key and local name as secondary  > key (nodes with  > no namespace  > qualification have an empty namespace URI, which is defined to be  > lexicographically least).  > Lexicographic comparison is based on the UCS codepoint  > values, which is  > equivalent to lexical  > ordering based on UTF-8.</p>  >  > <p>The method of text generation is dependent on the node  > type and given in  > the following list:</p>  >  > <ul>  > <li><b>Root Node-</b> Nothing (no byte order mark, no XML  > declaration, no  > document  > type declaration).</li>  >  > <li><b>Element Nodes-</b> An open angle bracket (<), the  > element QName,  > the nodes of the  > namespace axis, the nodes of the attribute axis, a close  > angle bracket (>),  > the descendant  > nodes of the element that are in the node-set (in document  > order), an open  > angle bracket, a  > forward slash (/), the element QName, and a close angle bracket.  > The element <a  > href="http://www.w3.org/TR/REC-xml-names/#NT-QName">QName</a>  > is either the  > local name if the namespace prefix string is empty or the  > namespace prefix  > and a colon,  > then the local name of the element.</li>  >  > <li><b>Namespace and Attribute Nodes-</b> a space, the node's  > QName, an  > equals sign,  > an open double quote, the modified string value, and a close  > double quote.  > The string value of the node is modified by replacing all  > ampersands (&)  > with <code>&amp;</code>,  > and all double quote characters with <code>&quot;</code>, and all  > illegal characters for UTF-8  > encoding with hexadecimal character references (e.g.  > <code>&#x0D;</code>).</li>  >  > <li><b>Text Nodes-</b> the string value, except all  > ampersands are replaced  > by <code>&amp;</code>,  > all open angle brackets (<) are replaced by  > <code>&lt;</code>, and  > all illegal characters  > for UTF-8 encoding with hexadecimal character references (e.g.  > <code>&#x0D;</code>).</li>  >  > <li><b>Processing Instruction Nodes-</b> an open angle  > bracket, a question  > mark, the PI target name  > of the node, a space, the string value, the question mark,  > and a close angle  > bracket.</li>  >  > <li><b>Comment Nodes-</b> the open comment sequence  > (<!--), the string  > value of the node, and the close  > comment sequence (-->).</li>  > </ul>  >  > <h4 name="sec-XPathTransformOutput">6.6.3.4 XPath Transform  > Output</h4>  >  > <p>The result of the XPath expression is a string, boolean, number, or  > node-set.  > If the result of the XPath expression is a string, then the  > string converted  > to  > UTF-8 is the output of the XPath transform. If the result is  > a boolean or  > number,  > then the XPath transform output is computed by calling the  > XPath string()  > function  > on the boolean or number then converting to UTF-8.  > If the result of the XPath expression is a node-set, then the XPath  > transform  > result is computed by applying the serialize() function to  > the node-set,  > then  > converting the resulting string to UTF-8.</p>  >  > <p>For example, consider creating an enveloped signature S1 (a  > <code>Signature</code> element  > with an <code>id</code> attribute equal to "S1").  The signature S1 is  > enveloped because its  > <code>Reference</code> URI indicates some ancestor element of  > S1. Since the  > <code>DigestValue</code>  > in the <code>Reference</code> is calculated before S1's  > <code>SignatureValue</code>, the  > <code>SignatureValue</code> must be omitted from the  > <code>DigestValue</code> calculation.  > This can be done with an XPath transform containing the  > following XPath  > expression in its  > <code>XPath</code> parameter element:</p>  >  > <p> <code>  > /descendant-or-self::node()[<br/>  >      not(self::SignatureValue and  > parent::Signature[@id="S1"]) and<br/>  >      not(self::KeyInfo and  > parent::Signature[@id="S1"]) and<br/>  >      not(self::DigestValue and  > ancestor::*[3 and  > @id="S1"])]  > </code> </p>  >  > <p>The '/descendant-or-self::node()' means that all nodes in  > the entire  > parse  > tree starting at the root node are candidates for the result  > node-set.  For  > each node candidate,  > the node is included in the resultant node-set if and only if  > the node test  > (the boolean expression  > in the square brackets) evaluates to "true" for that node.  > The node test  > returns true for all  > nodes except the <code>SignatureValue</code> and  > <code>KeyInfo</code> child  > elements and the  > and the <code>DigestValue</code> descendants of  > <code>Signature</code> S1.  > Thus, serialize()  > returns a string containing the entire input except for  > omitting the parts  > of S1 that must change  > during core processing of S1, so these changes will not invalidate a  > <code>DigestValue</code>  > computed over the serialize() result.</p>  >  > <p>Note that this expression works even if the XPath transform is  > implemented with a non-validating  > processor because S1 is identified by comparison to the value of an  > attribute named 'id' rather  > than by using the XPath id() function.  Although the id()  > function is useful  > when the 'id'  > attribute is not named 'id', the XPath expression author will  > know the 'id'  > attribute's name when  > writing the expression.</p>  >  > <p>It is RECOMMENDED that the XPath be constructed such that  > the result of  > this operation  > is a well-formed XML document. This should be the case if  > root element of  > the input  > resource is included by the XPath (even if a number of its  > descendant nodes  > are omitted by the XPath expression). It is also RECOMMENDED  > that nodes  > should not be  > omitted from the input if they affect the interpretation of  > the output nodes  > in the  > application context.  The XPath expression author is  > responsible for this  > since the  > XPath expression author knows the application context.</p>  >  >        

      Hi Gregor,    Actually, I did originally intend to violate the validity constraint as is  done in XML errata 70 (with an NMTOKENS in their case) in order to  demonstrate the attribute value normalization that occurs in this case.    However, the example is still wrong, not because of validation failure but  rather because the leading and trailing spaces need to be removed.  As well,  I should probably highlight the existence of this purposeful validity  constraint violation in Section 3.4 and in the paragraph at the top of  section 3.    As well, I will suggest removal of the line containing that element for  those creating canonical forms with a validating processor, and I will add a  line that shows the validating processors should use.      -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Gregor Karlinger  Sent: Wednesday, September 13, 2000 10:28 PM  Subject: Canonical XML comment (example 3.4)      Hi John,    In example 3.4 you declared the attribute "id" for the element  "normId" as being of type ID. An ID attribute value must meet  the name production according to XML 1.0 [1]. Therefore the  value you are using in the input document will produce a parsing  error:    <normId id=' '      	   ' '/>    [1] http://www.xml.com/axml/target.html#sec-attribute-types    Regards, Gregor  ---------------------------------------------------------------  Gregor Karlinger  mailto://gregor.karlinger@iaik.at  http://www.iaik.at  Phone +43 316 873 5541  Institute for Applied Information Processing and Communications  Austria  ---------------------------------------------------------------        

        The primary use in both XSLT and XPointer is to locate nodes relative to a  context node, and thus the LocationPath assumes special importance.  As a  constrained version of Expr, it always returns a nodeset given a context  node.  It seems to me your problem also could benefit from LocationPaths.    <John>  The usual scenario for the XPath transform is to parse the input and obtain  a node-set for serialization.  Therefore it does benefit from LocationPaths  because they can be used within an Expr.  </John>      Yes, Expr could be defined in your spec as the entry point.  In XSLT, certain attributes are defined as Expr and others as LocationPath.  It  should be clarified in the spec exactly which entry point you intend.  I  assumed LocationPath.    <John>  It does not need clarification because we are doing what the spec says.  XSLT needed clarification because they were not always doing what the XPath  specification said.  Your assumption of LocationPath does not constitute it  being 'odd' that I have used the default.  </John>    XPath states: "Expression evaluation occurs with respect to a context. ...  The context consists of: a node (the context node); a pair of non-zero  positive integers (the context position and the context size) ..."    Thus the context position and context size may not be set to zero, and it is  a reasonable assertion that the context node may not be omitted (a null  context node doesn't seem like a context node to me).  I think this goes  beyond "odd".    <John>  So, now it's not simply odd, it's beyond odd!  That's interesting.  Let me  get this right.  It's not odd for XSLT to hi-jack the defined language start  symbol in XPath, but it is *beyond* odd to use an empty node-set as a  starting context (given that the variable bindings and function library  provide a way to create a node-set when needed).    I'm sorry but this sounds like a lot of knit-picking when the reality is  that you simply read the document the way I read it at first and assumed  that everything started with LocationPath, and the authors of XPath simply  did not design it that way (and they seemed to have reason for this given  that XSLT uses Expr as a basis in many places).    As for the starting context of the XPath transform, disallowing an empty  node-set in the starting context is clearly a minor oversight on the part of  the authors of XPath.  It is necessary for XPath implementations to be able  to handle empty node-sets.  Check for example the result of the boolean()  function applied to a node-set.  It is true iff the node-set is non-empty.  Therefore, empty node-sets must exist.  What do you suppose the context  node, position and size should be for empty node-sets?  null, 0 and 0.  </John>    > 1) Everything I did in specifying the XPath transform is a  > kind of extension  > that is permitted by the XPath recommendation.  So, for  > example, I created  > the functions parse() and serialize() because the transform needed  > additional *function*ality, so rather than just making up  > whatever I needed,  > I specified it in terms of a function library addition, which  > is permitted  > by XPath.    I'll grant you that these are legal in an Expr, but not that this will be a  familiar use of XPath to users.  XPath states "The primary purpose of XPath  is to address parts of an XML [XML] document. In support of this primary  purpose, it also provides basic facilities for manipulation of strings,  numbers and booleans."  It seems to me that you have inverted this in your  model.    <John>  I haven't inverted anything.  The XPath specification states that the  starting language symbol is Expr.  I am using the default.  How is that an  inversion???  Furthermore, the primary purpose of the XPath transform is to  address parts of the document.  It is only put together in this particular  way to allow a little more flexibility in use.  </John>    This is of course a philosophical debate, and as such cannot be  "won", but it is our responsibility to at least comment that looks like a  potential source of confusion and inconsistency with existing XPath useage.    > 2) In my original design, I did as you suggested by putting the parsed  > version of the input as the context node.  However, there  > were some nagging  > little problems where people wanted to start with a fragment  > of XML, then  > transform.  Unfortunately, we don't have XML processors that  > work on XML  > fragments.    Do you mean multiple top-level elements?    <John>  Yes, you may have multiple elements as the result of a previous operation,  or you may simply want to add encoding information and a byte order mark to  the front of some UTF-16 markup that would not otherwise parse.  </John>    > So, by making a function parse(), it seemed easy  > to prepend an  > XML declaration (and a byte order mark, if needed) using  > string functions  > available in XPath, then parse the result and use the output  > node-set in  > further location steps.    I'm not completely familiar with your scenario, but doesn't this allow the  user to prepend any old byte order mark and declaration, even if they don't  accurately describe the XML data?  If they aren't prepended correctly, a  parse error could result, right?  It appears that the encoding and BOM are  available as variables, so is it the case that an author must prepend these  variables only (and always) in order for the parse to be successful?  Why  can't this be automated?    <John>  Yes, they can produce an error if they do it wrong, but it isn't like anyone  is ever going to successfully create a signature from an incorrectly  specified transform.    Further, no it can't be automated.  The BOM and encoding variables refer to  the encoding of the XPath expression, not the transform input.  </John>    > 3) In my original design, I assumed that the output would be  > automatically  > serialized.  Then it occured to me that a similar argument to  > that above  > could be applied to say that perhaps some minor fix-up of the  > output would  > be needed and could be done using XPath's string functions.    Scenarios?  If the need for parse() is eliminated, is there still a need for  this?    <John>  Symmetric doesn't mean equal.  parse() allows modification *before* input.  serialize() allows us to wrap changes around it, so we can make changes  *after* the output.  </John>    > So, given that I already felt that the cleanest way, from a  > specification  > standpoint, of adding functionality to XPath was to add  > functions, I now  > also found that I had a use for them.  >  > There are a few additional comments in line below marked by  > <john></john>,  > but hopefully you now see that the current design is works, offers  > additional functionality, and is specified in a way that most closely  > matches the enhancement methods suggested by XPath.  >  > Thanks,  > John Boyer  > Software Development Manager  > PureEdge Solutions, Inc. (formerly UWI.Com)  > jboyer@PureEdge.com  >  >  >  > -----Original Message-----  > From: w3c-ietf-xmldsig-request@w3.org  > [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Jonathan  > Marsh (by  > way of "Joseph M. Reagle Jr." <reagle@w3.org>)  > Sent: Tuesday, March 14, 2000 11:43 AM  > To: IETF/W3C XML-DSig WG  > Cc: w3c-xsl-wg@w3.org  > Subject: XSL WG comments on XML Signatures  >  >  > The XSL WG took a look at the  > http://www.w3.org/TR/xmldsig-core/ draft,  > especially at the XPath and XSLT transformation sections, and had some  > serious concerns.  >  > The section on XPath Filtering provides a capability that has  > often been  > requested - the ability to take shape a nodeset returned by  > the XPath query  > into an XML result.  We feel the model you provide will be a valuable  > contribution.  However, as consituted, the current  > formulation does not use  > XPath in a way consistent with the XPath recommendation.  We  > recommend a  > substantial redesign of this section.  >  > <john>Obviously, this has been refuted.</john>  >  > Notes on particular issues follow.  >  >  > [6.3.3 XPath Filtering] "The XPath transform output is the result of  > applying an XPath expression to an input string."  >  > Conceptually this is odd.  XPaths is designed to be applied to XML  > documents, not to strings.  Serious problems arise from this later on.  >  > <john>The string contains an XML document.  If it does not,  > then functions  > can be used to fix it up before passing it to parse()</john>  >  > "The XPath expression appears in a parameter element named XPath."  >  > No examples of this are shown; I assume the syntax is:  >  >   <Transform Algorithm="http://www.w3.org/TR/1999/REC-xpath-19991116">  >     <XPath>expression/goes/here</XPath>  >   </Transform>  >  > <john>Yes, this is consistent with how all parameters are  > handled, so there  > did not seem to be a need for me to put an example when none  > of the other  > sections contain one. The </john>    I would have appreciated one.  And others in the other sections too.    <John>  Send a letter to the editors.  While you're at it, send a letter to the guys  who wrote the XML spec.  In our case, though, many of our examples are going to be placed in the XML  Signature Scenarios/FAQ document.  </John>    > But the XPath element does not appear to be in the DTD.  An  > example would be  > useful.  >  > <john>True. The editors changed the transforms such that the  > additional  > parameter was needed (the xpath expression used to be the  > direct content of  > the transform), but they have not yet modified the DTD.</john>  >  > "The primary purpose of this transform is to omit information  > from the input  > document that must be allowed to vary after the signature is  > affixed to the  > input document."  >  > Despite this claim, the mechanism uses an XPath to describe  > the information  > that is to be retained, instead of the information that is to  > be omitted.  > Either the mechanism or this description of what is going on should be  > adjusted for consistency.  >  > <john>The result of the XPath is indeed the retained  > material, however, I do  > not see any need for a consistency adjustment.  It is absurd  > to say that the  > omitted information will be the result of the XPath  > expression, since then  > it would not be omitted.  > The purpose of using XPath is that it has a 'not' function  > that allows us to  > precisely define that which should be omitted from the input  > document, and  > the result of those omissions is what we will retain.  > </john>    I'm suggesting that not() is fairly unwieldy if it is the common case.  Instead the filtering mechanism could build "not" into it.  Any nodes  identified by the XPath would be omitted from the result (along with their  children, of course).  This would seem to have a number of advantages:    <John>  All of my transforms can be reduced to using a single call of not(), since  not x and not y and not z = not (x or y or z).  </John>    - simplifies XPaths since you don't need tons of not()s all over the place  - conceptually, this lives up to the name "filtering"  - the default is that the entire tree will pass through -- an empty XPath  query would mean no change  - simplifies serialization algorithm  - improved perf when a generic XPath processor is used (the nodeset of  affected items is much smaller)    But on the other hand - are there situations where you want to filter out an  element, but keep it's children in some way?    <John>  Yes.  We want a scenario where we can extract any subset of the nodes of an  XML document.  My own use often excludes a node and its descendants, but we  are not constraining this transform to just my uses.  </John>    > [6.6.3.1 Evaluation Context Initialization] "A context node,  > initialized to  > null."  >  > Without a context node, the XPath cannot be applied against  > an XML tree.  We  > suggest that an XPath transform parses the document in all  > cases (not just  > when the parse() function is called), and the context node be  > set to the  > root of the parsed XML document.  The context size and  > position can then be  > initialized to 1, consistent with XPointer and XSLT.  >  > <john>It is not necessary to be consisten with XPointer and  > XSLT.  It is  > only necessary that we use XPath in ways permitted by XPath.  I have  > previously shown that this is the case, contrary to your  > claim above</john>    Besides the arguments presented above, I do think consistency with XSLT and  XPointer is desirable from the users perspective.    <John>  What is the inconsistency?  So far, the trivial observation that I start  with an empty node-set, which XPath must support, is the only thing that's  different, other than the fact that XSLT stepped out of the bounds of XPath  by using LocationPath when Expr is the defined root of the language.  </John>    > "(Typically, $input is passed directly to parse(), but if  > $input does not  > contain a well-formed XML document, XPath functions such as  > concat() can be  > used before passing the result to parse())."  >  > The need for this functionality is unclear, but seems to be a  > motivating  > factor in XPath abuse throughout this section.  If indeed  > this need must be  > fulfilled, it should be accomplished by a separate mechanism prior to  > application of XPath to the parsed (thus guaranteed  > well-formed) document.  >  > <john>Why should it be fulfilled by a separate mechanism when  > XPath has  > sufficient string functions to do many fix ups.  If more  > types of fixup are  > required, then we could add additional functions to the XPath  > transform  > library.  That is the appropriate way to extend XPath</john>  >  > "An empty set of namespace declarations. (Note: It is  > possible to address a  > node by its qualified name, even though the evaluation  > context has not been  > initialized with a declaration of the namespace. The XPath  > language provides  > the functions namespace-uri() and local-name() for this purpose)."  >  > It appears quite easy in this syntax (being XML) to allow the user to  > declare namespaces for use within XPaths.  XSLT and XLink  > both provide this  > capability.  Using namespace-uri() and local-name() hinders  > readability and  > impacts performance significantly.  This workaround should  > only be used as a  > last resort, and even then many feel that this mechanism is  > too unwieldy.  > We strongly recommend that a syntax for passing  > author-declared namespace  > bindnigs to the XPath evaluation context be developed.  >  > <john>This is more work than necessary given that we would  > then have to  > define how to resolve conflicts between the author-specified namespace  > declarations versus those appearing in the document</john>    Why?  Pass in all namespaces in scope - only the ones referenced in the  XPath will be needed during evaluation.  And the XML Namespaces mechanism  could be used to ensure there are no conflicts.  E.g.      <Transform Algorithm="http://www.w3.org/TR/1999/REC-xpath-19991116">      <XPath xmlns:foo="uri:foo">//foo:bar</XPath>    </Transform>    This comment is based on my experience that not providing this functionality  results in severe backlash from the user community.  And most of this  experience comes from uses where providing namespace bindings is extremely  difficult (e.g. URIs).  Users have not been forgiving about these mitigating  circumstances.  In your case, this seems trivially easy, and I encourage you  to learn from my mistakes.    <John>  Fair enough.  If it is a real issue, then we can add a namespace binding in  precisely the way currently specified in XPointer.  </John>    > [6.6.3.3 Function Library Additions] "Function: node-set  > parse (stringInput,  > boolean LexOrder)"  >  > This function will not work as intended.  The XPath BNF  > prevents functions  > from being used as a location step - they can only appear  > within predicates.  > Thus parse()/x (which appears to be fundamental to your design) is an  > illegal use of a function.  We recommend that the parsed XML  > be provided to  > an XPath processor through the context node instead, with any  > necessary  > parsing controls specified on the XPath element (for example)  > and applied  > prior to XPath execution.  >  > <john>This has been refuted above</john>  >  > "Function:string serialize(node-set); This function converts  > a node-set into  > a string by generating the representative text for each node in the  > node-set."  >  > Under what circumstances would the serialize function NOT be  > called on a  > node-set return?  Since it appears that the vast majority (if not the  > entirety) of XPath Filtering operations will need to call  > this function,  > this capability should probably be built in instead of  > requiring the author  > to call it explicitly.  >  > <john>This has been refuted above</john>  >  > Are the serialization constraints consistent with  > canonicalization?  Is it  > inappropriate simply to say that the output is canonicalized  > instead of  > defining the exact representation here?  >  > <john>Canonicalization is more work.  If you want to  > canonicalize, use the  > c14n transform</john>    Why then constrain the serialization process so much?    <John>  We needed a way to say "Write the node set out as a string" because digest  algorithms work on octet streams (or bit streams or whatever), they don't  work on node-sets.  The material specified is almost the minimum necessary to say "write it  out".  We cover every type of node that is in XPath, and we tell how to  write it, including the issue of dealing with attribute order.  Other than  that, we don't make any changes.  The most offensive change, for example, is  that c14n creates attributes where there were none before, making non-local  changes to the document.    We are not constraining serialization 'so much', we are simply being  complete in specifying how to write a node-set.  </John>    It seems to me that this feature is introducing a kind of  mini-canonicalization and the relationship to full canonicalization is not  clear.    <John>  It is our goal to specify how to write a node-set, not to write a book to  tell you the difference between xpath transform serialization and c14n.  If  you want, you can discover the relation by reading the c14n spec.  </John>    > [6.6.3.4 XPath Transform Output] "serialize(parse($input,  > "true")/descendant-or-self::node()[  >      not(self::SignatureValue and parent::Signature[@id="S1"]) and  >      not(self::KeyInfo and parent::Signature[@id="S1"]) and  >      not(self::DigestValue and ancestor::*[3 and @id="S1"])]"  >  > If this is the intended usage scenario (omitting  > descendants), perhaps a  > mechanism based on XSLT match patterns (a subset of XPath) should be  > pursued.  Combined with an omission semantic instead of a retention  > semantic, the above might be simplified to:  >  >   Signature[@id="S1"]/SignatureValue | Signature[@id="S1"]/KeyInfo |  > *[3][@id="S1"]//DigestValue  >  > <john>Yes the above is an intended usage scenario.  One  > should also note  > that XSLT transforms may not be retained due to difficulties  > that will be  > harder to resolve than they were in XPath.  So, the suggestion to use  > something from XSLT may not be possible.  However, can you  > explain what the  > above expression does?  How exactly is it indicating that we  > want the whole  > document *except for* the SignatureValue in S1, the KeyInfo  > in S1 and the  > DigestValue in S1?  >  > Also, the above looks vaguely like an XPath expression.  > Perhaps you just  > have a different way of writing the same thing.  > </john>    Yes, XSL Patterns are derived from XPath expressions.  I guess match  patterns are a bad idea.  But I'm not convinced the "not" semantics  shouldn't be built in.  For instance:      Signature[@id="S1"]/SignatureValue |    Signature[@id="S1"]/KeyInfo |    Signature[@id="S1"]/SignedInfo/DigestValue    This LocationPath identifies nodes which (along with their children) would  be trimmed from the tree.  I believe this would simplify the description of  the serialization mechanism, as well as provide a "positive" way for the  user to describe what is to be cut.    <John>  The design tenet I used was that I would not be adding to the XPath syntax  in this specification.  I would apply XPath as stated, extending it only in  ways allowed by the XPath recommendation.  If we extend the expression  syntax, then that guarantees that no current implementation could be used.    So, no.  Use the not() function.  That's what it is there for, and I'm quite  sure it can be made efficient because I currently have implementations in  XFDL of a similar concept known as signature filters which use omission  logic, and they are extremely efficient.    John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  jboyer@PureEdge.com    </John>    > [6.6.4 XSLT Transform] "Identifier:  > http://www.w3.org/TR/1999/REC-xslt-19991116"  >  > <john>I don't care for this transform, so issues about it  > should be taken up  > with the editor</john>  >  > Why is this identifier used instead of the XSLT namespace?  All XSLT  > stylesheets contain version info already.  >  >  > "The Transform element contains a single parameter child  > element called  > XSLT, whose content MUST conform to the XSL Transforms [XSLT] language  > syntax. The processing rules for the XSLT transform are  > stated in the XSLT  > specification [XSLT]."  >  > This seems quite underspecified after the XPath Filtering  > section.  For  > instance, are similar parsing controls needed?  If not, why are they  > necessary in the XPath case?  Are similar serialization  > constraints needed?  > If not, why are they necessary in the XPath case?  Are certain output  > methods required (they are optional in XSLT).  >  >  > [4.3.3.1 The Transforms Element] "<!ELEMENT Transform (#PCDATA)>"  >  > The definition of the "Transform" element is #PCDATA.  This  > will not allow  > an XSLT stylesheet to be included.  The XML Schema defines it  > as "element  > only" but does not define the content.  This definition would  > not allow a  > naked XPath if that is your intent.  >  > In addition, the section mentions that the sequence of  > transformations can  > be XPath, XSLT, or some custom Java algorithm.  It seems rather  > underspecified how this sequence of transformations interact  > (e.g. XSLT  > and XPath operate on nodes and the Java operates on ???).  >  > <john>The output of each transform is the input to the next.  > There are no  > other interactions.  It's all strings of data.</john>  >  > We look forward to working with you to resolve these issues  > in a way that  > meets your needs and is consistent, implementable, and interoperable.  >  > - Jonathan Marsh  >   Microsoft  >  > (With contributions from Alex Milowski.)  >        

      Hello all,    1. Used CSS to show changes  2. XSLT and Minimal C14N  3. Answers to questions posted so far    1. Used CSS  ===========  Attached is a new copy of the overview that implements the CSS  recommendation Joseph made.  My additions are green underlined, the stuff I  struck is in blue.  Normal URLs may also be blue on your browser, but they  aren't struck out so there should be no confusion.    The prior editors' additions are red underlined, and their strike outs are  in grey.  So, if it's not green underlined or blue struck out, I didn't do  it :)    Other than that, I didn't do anything except fix a tiny error, which I  marked with strike in Section 6.5.1.    2. XSLT and Minimal C14N  ========================  I forgot to mention these changes in yesterday's manifest:    a) I added more text to clear up our expectations regarding the XSLT  transform.  I'd be particularly interested in review from Ed Simon and  others who care a lot about this transform because I did not write it as 'we  expect canonicalization of the result  tree', as Ed's previous email indicated.  The reason is that the result tree  may not be describing XML, which means that c14n of the result tree is not  well-defined.  The rest is self-explanatory if you read the text.    b) I added more words to minimal c14n to try capturing what people actually  intend for this transform.  It really needs to be reviewed by those who care  about it.  Basically, the problem stems from the fact that we changed the  processing model to allow node-set input.  If your intent was to minimally  canonicalize XML derived from within the same document, then it is  impossible to do this without doing Canonical XML (which obviates the need  for minimal c14n) or adding something like the words I added, which can be  very hard to implement in the general sense.    ===========================================================================  This is a response to the excellent questions posted so far by Joseph,  Gregor and Kent.    A) Joseph: No explicit C14N? (It's implied?)    John: It's only implied if the final result of URI dereference and  Transforms is an XPath node-set (or sufficiently functional alternative).  If you dereference a URI to an external resource, the result is an octet  stream.  If you apply a base-64 transform or a minimal canonicalization, the  result is still an octet stream, so there's no Canonical C14N applied.    But, if you use a same document reference like URI="#ID", the result is a  node-set.  The DigestMethod requires an octet stream, so we automatically  apply C14N to convert node-set to octet stream.  This was done because we  agreed on the teleconference that we needed to specify how URI="#ID" was  going to turn into an octet stream, and we agreed that it should be C14N,  but the WG did not want the verbosity of setting up a Transforms element  with a C14N Transform just to get the text of an identified element.    B) Joseph: Regarding Don's comment, do we need a parse me transform?  Or  will this be implicit...    John: Didn't seem to need to do it explicitly.  In fact, by leaving it  implicit and defining the I/O for each transform, I was able to improve the  b64 transform so that it automatically stripped the start and end tags,  internal comments and PIs, etc. when the input was a node-set.    C) Gregor: How can the result of the XPath expression test be treated as a  boolean?    John: Anything in XPath can be converted to a boolean.  However, note that  the XPath expressions one must now write are more like those one would write  for an XSLT template.  It's just the predicate expression that used to be in  the square brackets of the former XPath transform, because the XPath  transform has been rewritten to automatically iterate through the input  node-set (or the node-set formed from the input octet stream).    The reason for this change is that the WG requested on the last  teleconference that we keep to a minimum the number of times we actually had  to c14n.  I agree with this request.  We now pass a node-set from transform  to transform if it is possible to do so.  The problem is, consider the  nature of the output node-set of an XPath or enveloped signature transform.  The output is not a node-set that just contains the root node.  It is a  node-set that contains all nodes that should be carried forward to the next  step (which could be c14n).  So, what if you have an enveloped signature  transform followed by an XPath transform?  I expect this to be a common  scenario in my software.  The output of the enveloped signature transform is  a 'full' node-set.  Unless I were to duplicate the parse tree and shave out  all of the omitted nodes, then there is no way I can reset the node-set back  to just having its root element.  In other words, unless I do nearly as much  CPU work as if I'd just done a c14n and then reparsed the document for the  XPath transform, I need to handle the case where the input node-set is a  full node-set, not a node-set that has the root node with context position  and size 1.    By the way, I am assuming that iterating a full node-set, creating a new  node-set containing a single node and evaluating the expression w.r.t. that  node-set is cost-effective.  I assume this because I assume that the  node-set data structure of a reasonable implementation would be something  like {root of tree, context pos, context size, list of nodes, other data}.  In other words, I assume that you don't have to duplicate the parse tree to  create a new node-set, and I assume that given a node, you can use all of  the axes defined in XPath (e.g. go to ancestors) even if the ancestors  aren't in the node-set.  If these are false assumptions, then we may have to  revert to the more costly alternatives.    D) Joseph, Gregor, Kent: Comment issue will cause confusion, and people will  wonder whether to include them.  If an app wants them, they can write an  XPath to keep them.    John: Firstly, the fact that we require the non-comment and recommend the  commented version should make it pretty clear which should be used most of  the time.  Secondly, I had real trouble with comments because it turns out  that you can't just do an XPath to include them.    The reasoning went as follows:    When we have a Reference to an external resource, the result is an octet  stream (including comments).  For a same-document reference, if we strip  comments, then they can never be recovered by an XPath transform AND it  makes life really hard on those who just want to self-reference the document  and do minimal c14n (suddenly they have to strip comments).  Therefore, same  document references should retain comments.    An XPath transform receives either a node-set or an octet stream.  If a  node-set, the comments are still in it (unless stripped out by a prior XPath  transform).  If input is an octet stream, then XPath creates node-set  including comments, so again comments are retained unless the XPath  expression in the transform omits them.  However, the output is a node-set,  not an octet stream.  So, how do you get an octet stream that includes  comments?  Well, you have to canonicalize the node-set.  The problem is that  most people seem hellbent on having c14n exclude comments by default. Hence,  we need a canonicalizer that does not strip the comments.  Since we have a  c14n algorithm that can easily be told whether or not to get rid of  comments, it seems easy to create a second transform for this purpose.    I would be interested in being told exactly where the document gets more  complicated as a result of this change.  I think that more is being said  about how we derive the data to be signed, but that was the purpose of  rewriting the processing model.  However, the with or without comments  problem does not occupy much space in the changes.  The complexity comes  from actually solving as opposed to repeatedly failing to solve the  enveloped signature problem.    E) Gregor, Kent:  Why add all of the XPointer complexity?  Specifically, why  do a location-set when we don't support ranges and reduce it down to a  node-set, why the distinction between full versus other xpointers w.r.t.  comments, and why those two special full Xpointers?    John:  For starters, let's address location-set.  According to the W3C  candidate recommendation known as XPointer, the thing after the # is an  XPointer, not an XPath.  XPointers return a location-set, not a node-set. We  can 'declare' it to be a node-set, but the truth is that we say full support  of XPointer is 'OPTIONAL', not 'FORBIDDEN'.  Thus, it is incumbent on us to  say what should be done with point and range nodes (which are the  only difference between a location-set and a node-set).  Moreover, on the  question of ranges, the fact that there is a question is precisely why we  needed to write down what should be done with them.  We support as much of  ranges as can be supported by a node-set because we convert the range to the  set of nodes that it spans.  I feel that ranges will get used a lot, so  saying nothing about how they fit into our processing model is a failure to  provide enough detail for those who want to implement this OPTIONAL part.    To be honest, when we decided to stick to Xpath and node-set, it looked like  no progress was being made on the XPointer/XLink front.  At the last FTF, I  proposed the idea that we switch to location-set, an XPointer transform, and  switch c14n to canonicalizing location-set.  I still think this is the right  idea, but the WG voted against, so we are stuck with this translation (or  stuck with saying that our spec FORBIDS anything after the # except an ID).    Now, for the question of why some distinctions were made between URI="#ID"  and URI='#xpointer(id("ID"))' as well as the distinction between URI=""  versus URI="#xpointer(//. | //@ | //namespace::*)".  The distinction is that  the full xpointers include the comments in the node-set and the shorter URIs  don't.  Why do this?  Well, as I said above, I feel that the same-document  URI dereference SHOULD result in the retention of comments, which can be  excluded later by the default XML C14N.  However, comments are a real  problem because there are a lot of tools out there that toss the comments.  So, if I'd said that URI="" and URI="#ID" retain the comments, then some of  the WG would likely have written in to say that we can't REQUIRE retention  of comments :).    So, the write-up currently reflects the fact that support for comment  retention is RECOMMENDED but not REQUIRED.  If we omit the full xpointers  and let URI="" and URI="#ID" retain comments, then some implementations  would be violating the processing rules by not supporting the comments.  However, as far as I can tell, the situation would clean itself up before  they got to the DigestMethod, so their reference validation would still  work.  However, it puts those who omit comment support into 'hack' status,  and I did not feel I could do that-- the WG needs to decide to do that.    Finally, note that whether or not this gets changed, we still need the C14N  with Comments for those who want the comments signed.    ============================================================================  ======    Hopefully, it is now clear why it took a whole day to make these  modifications.  There were a lot of picky little issues and scenarios to  account for.    John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>            text/html attachment: Overview.html          

      Hi Gregor,    When you say 'igore passages highlighted in blue', do you mean that you want  them omitted?    Thanks,    John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Gregor Karlinger  Sent: Wednesday, July 26, 2000 6:23 AM  Subject: [w3c-ietf-xmldsig] <none>      Joseph,    please find attached my comments regarding the 10/07/00 XML-Signature draft.      * Errors are highlighted in red and followed by a linked comment    * Questions/suggestions are highlighted in green and followed by a linked  comment    * Please ignore passages highlighed in blue    Regards, Gregor  ---------------------------------------------------------------  Gregor Karlinger  mailto://gregor.karlinger@iaik.at  http://www.iaik.at  Phone +43 316 873 5541  Institute for Applied Information Processing and Communications  Austria  ---------------------------------------------------------------        

      Hi Gregor and Joseph,    Other implementers ran into same problems you are reporting.  At the  Pittburgh F2F, we decided to address that problem by    1) Removing the here() function from the XPath transform    2) Specifying the enveloped signature transform as follows:    <Reference URI="#xpointer((//. | //@* | //namespace::*)     [count(ancestor-or-self::dsig:Signature |  here()/ancestor::dsig:Signature[1]) >     count(ancestor-or-self::dsig:Signature)])">  <Transforms>  <Transform Algorithm="http://www.w3.org/TR/2000/WD-xml-c14n-20000710"/>  </Transforms>  </Reference>    In other words, take the current document, apply the same XPath that we  previously specified, then canonicalize the result.    As I sit here today trying to write that up, I realize that it fixes the  XPath transform, but does not solve the underlying problem, which is that  the enveloped signature transform needs an extra piece of information that  is simply not in our transform processing model.    It is important to realize that although we can say 'it must behave as if'  the signature were created by the above Reference, but that doesn't fix the  fact that it is still a transform, so our processing model does not allow it  to act like the above Reference.    Instead, it is necessary to fix the processing model. The reason that we  cannot do this by giving transforms access to the parse tree is NOT that it  is a hack, but rather that it is actually not going to work.  Even with  access to the parse tree, the here() function cannot return a node of the  parse tree because it is the parse tree of the current document not the  parse tree of the octet stream's copy of the parse tree.    It occurs to me today that we can fix this problem by adding a second  implicit string parameter to each transform.  All we have ever really needed  is to uniquely identify the signature we are currently processing.  We have  found that it is hard to do this by 'id'.  However, the path from a node  (such as the Signature element) to the root of a tree (the document root) is  unique and therefore it is relatively easy to dynamically compute a simple  XPath expression to describe its location within the document.    I propose that the processing of Transforms should begin with computing the  XPath expression string that describes where the Signature element is within  the current document.  The Signature identifier string remains constant  during the processing of transforms, but any transform needing implicit  access to this information can have it.    The expression would be of the form /doc/echild[n1]/.../Signature[nk], where  the signature is at depth k below the doc root (which is depth 0), and the  numbers n1...nk are a unique signature identifying the path between the root  and the Signature.  Obviously, if the Signature is the root element, then  the string would be "/Signature".    I propose that the XPath and enveloped signature transforms should use this  expression to obtain a node within the parse tree representing the octet  stream input.  This could be returned by a function such as  this-signature().  This would obviously replace the here() function.    Chairs:  Can we now seek consensus from stakeholders on this proposal?  As  soon as consensus is reached, I can provide the modified text.    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        

      Actually, no it isn't enough to excluded by IDREF and no we shouldn't add  more transforms.    1) Exclusion by IDREF simply means that some element given by ID was  excluded at the time of signing and is now excluded.  It is difficult to say  anything about what was the excluded element was at the time of signing.  It  would have to be excluded if and only if:    a) it's ID matched some value  b) it was in fact a SignatureValue  c) it did in fact have a certain ancestry    Otherwise, you run the risk of being able to produce documents that fool the  system at the time of signing.  And its not really that I expect such  fooling around to occur often.  I am more concerned with the attempt to  repudiation transactions based on the argument that such fooling around  'could' occur.  This is how technology disservices the relying party.    2) There should not be a proliferation of transforms that implement parts of  the XPath transform.  If you find the XPath transform useful, use it.  XPath  is sufficiently powerful to deal with any partial document needs you may  have, so there should not be a need for other means of obtaining parts of  the document.    John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  jboyer@PureEdge.com            -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Petteri Stenius  Sent: Thursday, March 23, 2000 11:54 AM  Subject: RE: Enveloped signatures and XPath        Yes, excluding the Signature or SignatureValue element (without using XPath)  is the main concern with enveloped signatures.    I believe it could benefit many if more transforms were added to the spec, a  generic "exclusion by IDREF" algorithm would be enough to solve enveloped  signatures.      Petteri      > -----Original Message-----  > From: Martin J. Duerst [mailto:duerst@w3.org]  > Sent: Thursday, March 23, 2000 5:11 AM  > To: Petteri Stenius; IETF/W3C XML-DSig WG (E-mail)  > Subject: Re: Enveloped signatures and XPath  >  >  > At 00/03/22 19:39 +0200, Petteri Stenius wrote:  >  >  > >The interop requirements doc reads:  > >  > >"Feature: Enveloped Signature MUST  > >         requires: XPath selector that drops SignatureValue"  > >  > >  > >I remember there was some talk about this at the FTF meeting  > in San Jose. It  > >was discussed that it could be possible to detect this  > particular XPath  > >expression without implementing the entire XPath support.  > >  > >Has anyone worked out a (standard?) XPath expression for  > excluding the  > >Signature or SignatureValue element?  >  > If that's the main concern, it may even be possible to define  > a transform that cuts out the SignatureValue element without  > using XPath at all.  >  >  > Regards,   Martin.  >        

      Hi Kevin,    Relocatable signatures also have the problem that they break of the  namespace context changes, however, Merlin seems to be referring to the  problem that if you identify signatures by an id attribute, then you cannot  relocate many of them into the same document (e.g. to form a list of search  results, each of which is signed).    However, if I understand what Merlin is saying correctly (also below), he is  using an Xpointer in the Reference to indicate what to sign.  Let's run with  that basic idea for a moment.    Since XPointer is based on XPath, we could create an XPointer in the  Reference whose expression argument is equal to the XPath we current have in  the enveloped signature specification (except that it is currently in an  XPath transform).    In total, we could    1) drop here() from the XPath transform  2) rewrite the enveloped signature specification to use a Reference with an  Xpointer URI that is equal to the current XPath for enveloped signature.  3) Convert the resulting location-set to a node-set (throw error if there  are any point, range or other non-node parts of the location-set)  4) C14N the resulting XPath node-set.    The second point can be done by using the here() function present in  XPointer, basically using the same XPath expression we currently have in the  specification for enveloped signature.    The third point is an interesting new twist, but I believe it is a problem  with the current dsig spec whether or not we use XPointer to solve the  enveloped signature problem.  We have assumed that people can use a URI that  includes at least a barename Xpointer.  But the result of a barename  XPointer is a *location-set*, not an octet stream.  To fix this, I believe  we have assumed that the canonicalized result of the barename xpointer would  be passed to the transforms (at least I have).  But c14n operates on a  node-set, not a location-set.  However, certainly in the case of barename  xpointer, the location-set is a node-set (there are no non-nodes), so  canonicalizing it presents no real problems.    Finally, I should point out that this idea is pretty similar to the earlier  concept of creating a special XMLTransform first, or somehow treating the  first transform differently, except that it keeps the data flow model for  transforms clean by making the reference URI be that special first  transform.    Would the current primary stakeholders (Merlin, Kevin, Kent, Joseph and Don)  agree with this approach?  If so, I can make the required changes to the  XPath and Enveloped signature sections before the FTF.    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>          -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Kevin Regan  Sent: Monday, July 24, 2000 3:12 PM  Subject: Re: XMLDSIG proposal: enveloped signatures, xpath and here()        Isn't the problem of relocatable signatures more to do with the  fact that the Signature element (and its children) rely on parent  namespace declarations, so it can not be moved to another document  with a different namespace hierarchy?    --Kevin    >  > The problem of relocatable signatures is an interesting one,  > however it can be solved in two ways. One is for the signatures  > to use null references; the referenced data is implicitly the  > associated datum, known to the appication. Alternatively, use an  > XPointer in the reference to identify the relevant data (I believe  > that is the correct technology) and then an XPath, if necessary,  > to select from it:  >  >   <Reference URI='#xpointer(../../previous-sibling)'>  >  > Technologically, all verifiers which support XPath transforms  > contain the necessary tools for XPointer resolution. So adding  > a need for this is a minimal burden.  >  > Merlin  >        

      Hi Gregor,    Yes, non-validating parsers are supposed to recognize the types of  attributes, unless they have been unable to read the declaration (e.g. due  to external declaration), but c14n covers this too by requiring that such a  processor be augmented to read the attribute types so that it can normalize  attributes as if it were a validating processor.    Though an additional encumbrance, this is far less work than actually  requiring the validation work.    The example cases should not pose a problem, though, because the  declarations are internal so even a non-validating parser knows the types of  the attributes and how to normalize the attributes.    John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>          -----Original Message-----  From: Gregor Karlinger [mailto:gregor.karlinger@iaik.at]  Sent: Friday, November 03, 2000 2:22 AM  Subject: AW: Call for Implementation: Canonical XML Becomes a W3C  Candidate Recommendation      > Hi Joseph,  >  > please add IAIK's implementation.  >  > I will give you a report what our implementation is conform with at the  > end of next week.    Joseph,    Please fill in a "Y" in all fields of the matrix, with the following  constraints:    * Example 4 does not result in the expected canonicalization, since the    XML parser used does not correctly normalize an attribute of type ID.    * Example 7 only results in the expected canonicalization, if the test    file is modified in a way, that the example can be parsed using a    validating parser. Otherwise the id function in the document subset    selector XPath will not return any element.    John,    a question regarding example 7: Can I really expect from a non validating  parser, that it recognizes the types of attributes, especially the type  of ID attributes? If not, then an XPath using the id() function cannot be  used for selecting a document subset to be canonicalized.    Regards, Gregor  ---------------------------------------------------------------  Gregor Karlinger  mailto:gregor.karlinger@iaik.at  http://www.iaik.at  Phone +43 316 873 5541  Institute for Applied Information Processing and Communications  Austria  ---------------------------------------------------------------        

      Dear Don,    I can appreciate that you would like to characterize my explorations of this  topic as those of a "narrow-minded programmer" who should simply learn to  "be happy with the under-specified fuzzyness [sic] of it all".    However, as you well know, there are few things in this world that are more  narrow in acceptance of change than a sha-1 hash.  Ultimately, our  processing model boils down to taking a digital digest of some information.    The job of the implementers is to cut through that fuzziness and tell the  computer to do something specific.  If two implementers cut through that  fuzziness in different ways, the result is non-interoperable  implementations.    Perhaps I've spent too long at the business end of the whip wielded by QA  teams who do things like    ...  <dsig:Reference xmlns:dsig="&dsig;" URI="#X" dsig:URI="#Y>  ...    If my implementation picks up URI and your implementation picks up dsig:URI,  then only one of us will correctly validate this beastly signature.    Below you state, "If the text documenting N and/or E doesn't tell you what  to do here, you get to toss a coin or something."  Tossing a coin undermines  the interoperability that is supposedly the cornerstone of XML. The 'if'  part of your statement should not be true for any application of XML, and  therefore not for XML DSig in particular.    As for the issue of why unqualified attributes do not simply default to the  namespace of their parent element, I have been trying to find out from "the  XML authorities" why they did not do it this way because the way they did it  is so specific that it belies intent.  If we toss a coin and pick a  processing model, it may be in violation of their intent. We don't know  unless one of them gives the reason.    Finally, I would add that everything you say below justifies a design in XML  Names that applies an element's namespace to its unqualified attributes.  The fact that it was not this way is the original point that took both  Gregor and me by surprise.  Why is it characterized as 'narrow-minded' to  ask a public working consortium to explain why a very specific feature was  added when it is somewhat contrary to reason and when noone can explain it  except to accuse the interrogator of narrow-mindedness for not processing it  in the way that it would be processed if the design were as we expected it?    Further specific points and answers to your questions are below.    Thanks for your continued patience,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: Donald E. Eastlake 3rd [mailto:dee3@torque.pothole.com]  Sent: Wednesday, August 16, 2000 9:47 AM  Subject: Re: Determining attribute uniqueness seems to require namespace  prefix in Infoset      Hi John,    From:  "John Boyer" <jboyer@PureEdge.com>              "Joseph Reagle" <reagle@w3.org>              "XML DSig" <w3c-ietf-xmldsig@w3.org>  Date:  Fri, 11 Aug 2000 17:13:09 -0700  Message-ID:  <BFEDKCINEPLBDLODCODKEEFCCEAA.jboyer@PureEdge.com>  In-Reply-To:  <200008112057.QAA06998@torque.pothole.com>    >Hi Don,  >  >I see where you are coming from now, and it is both interesting and  correct,  >but it means we need to be saying something more in DSig, if not in XML  >Names.  >  >The appendix refers to the attributes as 'unqualified'.  The section is not  >saying that unqualified attributes are qualified by per element partitions  >(because then it wouldn't be unqualified).  Instead, because it is  >non-normative, it is saying that one is free to look at it this way if it  >makes one feel better.  >  >The implication is that "per element partitions" don't really exist and  need  >not be supported by conforming applications.  In other words, the material  >on per element partitions is a convoluted way of saying that the only thing  >which matters is that an attribute appears within an element and should  >therefore be processed as though it were in that element's namespace unless    But the attribute is NOT "directly" in the element's namespace.  It is  in orbit around that element where the full coordinates of the element  includes the elements namespace.    >it has a non-empty namespace other than the element's.  As well, I think  >this is what you are saying.  >  >Unfortunately, it actually does matter quite a bit.  For starters, suppose  >you have an HTML anchor with two hrefs, one unqualified and the other in  the  >HTML namespace.  Which does one use?  Put in another more general way,  given    Why would there be an href qualified by a namespace?    <john>  It was a specific example of this more general case.  It doesn't matter why someone would do it; what matters is that they can do  it, which opens the question of what our software should do about it.  </john>    >element E in namespace N, if one wants to obtain attribute A from E, which  >of the following processing models is correct?  >  >1) Attr = (N:E).get(N, A)  >2) if Attr is null, Attr = (N:E).get("", A)  >  >or  >  >1) Attr = (N:E).get("", A)  >2) if Attr is null, Attr = (N:E).get(N, A)    The attitude of the XML authorities seems to be "Most of the time it  doesn't matter and where it does the documentation for N:E should tell  you and if it doesn't mention it, then maybe the second processing  model is better, but it really doesn't matter much and you should stop  being such a narrow minded programmer and being so algorithmic and be  happy with the under-specified fuzzyness of it all."    <john>  Fortunately, none of the other XML authorities choose to be so directly  insulting.  Hopefully the message above helps to clear up why this issue remains a  concern.  </john>    >It makes a difference if the XML is <N:E xmlns:N="N" A="2" N:A="1">.  The  >first model gives the attribute whose value is 1, and the second model  gives  >the attribute whose value is 2.    The fuzzy handwaving implications of the wording used in the XML  Namespaces specification is that N:A should be some sort of global  attribute which can appear in many elements while plain A is some sort  of normal local attribute to N:E.  If the text documenting N and/or E  doesn't tell you what to do here, you get to toss a coin or something.    <john>  Coin tosses undermine interoperability.    The problem here is what to do when the local A and the global N:A are both  allowed in the same element.  </john>    >I don't think this can be explained away as a simple differing viewpoint  >because I don't agree that all applications process attributes solely  within  >the context of the parent element.  The prime example of this is XSLT,  which  >uses XPath for template matching.    What I meant to say was that it is a matter of point of view if you  consider attributes without prefixes to be in no namespace and to be  defined relative to their element or you considered them to have a  globally unique name composed of their name, their element's local  name, and their element's namespace if any.  The first point of view  says they are not in any namespace while the second point of view  implies they are, in some sense, in their element's namespace,  although not directly in that namespace.    <john>  There are some XML authorities like Tim B-L who feel that namespace  qualification is an important method for assigning unambiguous meaning to  XML.  With both viewpoints, the unqualified attribute is NOT DIRECTLY in the  namespace.    Still, this is beside the point.  The point remains that the processing  model for an element can govern the type of XPath expression one writes to  match nodes based on the effect they will have when processed.  </john>    >Lets compare the following four occurences of an element E by considering  >the xsl-template's XPath expression that must match E based on whether the  >value of an attribute A is 'test':  >  >1) <N1:E xmlns:N1="http://www.w3.org" xmlns:N2="http://www.PureEdge.com"  >A="test"/>  >2) <N1:E xmlns:N1="http://www.w3.org" xmlns:N2="http://www.PureEdge.com"  >N2:A="test"/>  >3) <N1:E xmlns:N1="http://www.w3.org" xmlns:N2="http://www.PureEdge.com"  >N1:A="Yikes" N2:A="test"/>  >4) <N1:E xmlns:N1="http://www.w3.org" A="test" N1:A="Yikes"/>  >  >The xsl-template cannot simply try to match on the local name A or else  >element E in #2 would be matched, which is clearly not intended. If we add  >to the XPath test a call to namespace-uri() to match the URI for N1, then  #3  >works but #1 doesn't.  If we add a test that finds the local name of A and  a  >namespace-uri() that is either blank or equal to the URI for N1, then #1 -  >#3 work as expected, but #4 has two attributes that match the test.    Aren't XPath node tests by QName?  If you specify the namespace, it  will only look at N1:A, if you don't specify any namespace, it will  only look at A, right?    <john>  Yes, exactly.  It's not a question of how an XPath expression should be  written.  It's a question of which XPath expression one should write.  The  XPath expression is dependent upon the processing rules for the target  application.  As you so eloquently put it above, the processing rules may be  based on a coin toss, which means that creating an XPath expression is  non-deterministic.  </john>    >If the claim is true that attributes should be processed within the context  >of the parent, then A="test" would indicate that the xsl-template should  >match N1:E in #4.  However, N1:A is clearly the attribute A in element E's  >namespace, so for the purposes of the primary processing application for  the  >N1 namespace, N1:A and A are duplicates.    N1:A is A directly in namespace N1.  It is qualified only by N1.  A is  defined to be different because, while it can be viewed as qualified  by both E and N1 and it is defined as not being directly in namespce  N1.    <john>  I understand this.  Hopefully it is now evident that this has nothing to do  with the problem.  </john>    >Personally, I don't believe in duplicate attributes.  The normative part of  >XML Names makes it clear that the attributes are not duplicates in name  >(which is a well-formedness requirement of XML), but if the non-normative  >part of the spec invents some concept that makes the two attributes equal  >for the purposes of processing, then a precedence must be specified. Which  >one has precedence?  Until we know this, the proper xsl-template cannot be  >written.    Why do you say that the non-normative part "makes the two attributes  equal for the purposes of processing"?  It distinguishes them by  saying that one is in the Per-Element-Type attribute partition  associated with that element of the namesapce while the other is in  the Global attribute partition of the namesapce.    <john>  It would be helpful if you could specify how this partitioning changes the  way the attributes should be processed.  Based on your discourse above, N1:A  and A are differentiated by nothing more than a coin toss unless a  particular processing behavior is specified by the application.  Are you now  saying that there is a standard XML technique for processing attributes in  differing partitions?  </john>    >If I had to guess on a processing precedence, I would guess that the  >namespace qualified version should take precedence.  Here's why:  >  >I've been sitting here trying to figure out why the default namespace does  >not apply to attributes, and the only thing that I can think of is that  >unqualified attributes can then be used to apply an attribute value across  >all namespaces.  In other words, a sort of default value to be used when no  >namespace specific attribute is given. Consider the following bit of XML:    As I read it under the namesapces spec, "unqualified" attributes are  super-local, not super-global as you suggest above.    <john>  I was only trying to make a guess at why the authors of XML Names decided  that the default namespace would not apply to unqualified attributes.  Despi  te all of the dancing around and text messages that have flung far and wide,  noone has given an explanation.    Clearly, there was an intent, but in the absence of any of those XML  authorities coming out and saying what the intent was, the only thing we can  do is guess.    Everything you have said so far would justify a design that applies the  element's namespace to unqualified attributes.  If A is super-local, then it  does not seem to make sense to have    <N1:E A="" N1:A=" "/>    so why did the authors of XML names seemingly go out of their way to make  this construction legal?  This is not narrow-mindedness.  I am asking a  question of the language designers about their design.  Why can they not  answer it?  If they did answer it, then the answer might have a bearing on  the processing model that we *should* specify for dsig.  </john>    ><E xmlns:N1="http://www.w3.org" xmlns:N2="http://www.PureEdge.com"  >A="default" N1:A="Value for App that processes N1" N2:A="Value for App that  >processes N2"/>  >  >The information in element E can be used by one application that conforms  to  >specification given at the URI for N1, or it could be processed by a second  >application that conforms to specifications given at N2, or it could be  >processed by some other generic XML processing application.  If, by  >convention, namespace qualified attributes took precedence over unqualified  >attributes for processing, then the value for A would be  >application-dependent.  If unqualified attributes took precedence, then A  >would always equal default.    You are assuming that E is defined in both N1 and N2?  Then I think  you need to read the doucmentation of E in N1 and the documentation of  E in N2 to figure this out.  XML is just plain under-specified and no  amount of thought will change its ambiguous parts into an un-ambiguous  specifiction.    <john>  Agreed, but this is such a specific concept that they seem to have gone out  of their way to talk about (e.g. per-element partitions).  In this case,  it's not a matter of adding more thought.  It's a matter of one of those  authorities saying why they did this so that we can choose a processing  model that doesn't violate their intent.  </john>    >Perhaps XML names will not be changed or clarified, and perhaps they will  >make no recommendation, but for a particular application, esp. a security  >conscious one such as DSig, we should be saying what we expect our  >processors to do when there are qualified and unqualified attributes with  >matching local names.    Sure, probably a good idea to add a few words to our specification to  say what should be done for such "duplicate" attributes for elements  we define.    <john>  Good.  Why so much resistance if you end up agreeing that we should add a  few words to address the problem?  </john>        

      Hi all,    xml version came up quite a while ago, and we decided to leave it out.  Our  rationale was the same one given by Tim Bray several months earlier, namely  that by leaving it out, we are implicitly declaring the document to be v1.0.  We are canonicalizing xml v1.0, not xml v1.1.  We can easily issue a new  c14n recommendation once the data models begin to support storage of the xml  declaration.    I don't know about the latest version of infoset (yet), but prior versions  of infoset didn't include the xml declaration, which is why the prior c14n  group also omitted the xml declaration.    I believe that an infoset for versions of xml after 1.0 MUST include the xml  declaration, and I cannot see the W3C failing to issue another XPath based  on the infoset data model to address the additional components of xml 1.1+.    John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of  muraw3c@attglobal.net  Sent: Monday, July 31, 2000 8:09 AM  Subject: Omission of the XML Version in C14N      The last call perior for the new C14N WD is over.  I should have  raised one issue.    Canonicalized documents do not contain XML declarations.  Is this OK?    First, XML should allow some of the newly-introducedcharacters of  Unicode 3.0 as name characters.  If we introduce them in V1.1 of XML,  validity (e.g., NMTOKEN) of an XML document will be dependent on the  XML version.    Second, Unicode character properties may vary, and thus the same  Unicode-aware regular expression of XML Schema Part 2 may behave  differently for different versions of XML.    Even if the XML version info is absent from APIs such as SAX and DOM,  should we always generate <?xml version="1.0"?>?    Cheers,    IBM Tokyo Research Lab &  International University of Japan, Research Institute    MURATA Makoto  (FAMILY Given)    Speaking for himself only.        

      Hi all,    Nothing to be sorry about.  In the new version of the c14n spec, I have  taken the liberty of changing the way namespaces are handled.  As a result,  the messages signed by forthcoming signatures will be different than ones  generated in the past.  However, there are VERY good reasons for making this  change (including yours), and my perception is that most if not all WG  members will prefer the results.    The change is that, rather than simply writing the full namespace context of  each element in its start tag, we need to eliminate superfluous namespace  declarations.  I apologize for the inconvenience of this change, but I  believe it will not seriously impact implementations.  For anyone doing the  current c14n by ANY mechanism (including SAX), this change should amount to  less than a page of code.    When processing an element, we will only add those namespace declarations  that differ from the setting in the parent element.  For a SAX  implementation, you will have to keep an auxiliary stack whose top contains  the parent element's settings so that when you are notified of the namespace  of the current element, you can have something to compare against (after  which you would push the current node as the new top of stack).  Note that  for document subsetting, one has to go up to the nearest ancestor that is in  the node-set, but for canonicalizing a whole document, that's always the  parent.    Given that the current formulation is verbose but technically correct, why  do this?    1) For starters, xmlns="" shows up in every element for which no default  namespace is declared.  There's nothing technically wrong with this, but the  examples look broken and are harder to explain.  It is particularly hard  when the originating application may not even care about or really be using  namespaces.  Consider the impact on an app that uses a validating processor  but not namespaces.  To use the canonical form, we would like to say they  should simply slap the DTD back onto the front of it.  But we can't because  xmlns would have to be added to the ATTLIST of every element.  This is  unacceptable when it is so easy to fix c14n before it goes to candidate rec.    2) For elimination of superfluous declared namespaces, it was something of a  consistency measure.  It seemed wrong to get rid of extra xmlns="" but not  get rid of extra declared namespaces, esp. when one realizes that it can be  done with the same solution that solves the xmlns="" problem.  In addition  to the consistency, it also makes the examples in the spec much more  readable.    I will be posting the new spec today after I do a few more editorial tweaks.  And, by the way, although the document is massively improved in structure  and explanation, this is THE ONLY CHANGE to the expected output of the  algorithm.    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of merlin  Sent: Wednesday, August 30, 2000 10:46 AM  Subject: Re: C14n and inherited namespaces (again) (sorry)        Not to keep dragging this out.. This is trivial, but of  minor importance for interop where XPaths are involved.  Most should ignore it.    Elements mystically inherit namespace attributes from their  ancestors. In no implementation that I have seen, however,  is there a physical representation of these attributes.    In other words, if you query a node for a namespace prefix,  you'll get the nearest inherited value. But if you look at  the attributes of the element (getAttributes()), they're  not there.    As a result, inherited namespace attributes cannot be part  of a node set because there is no physical entity that can  be placed in a set. Or are we expected to create a physical  representation ourselves if our underlying toolkits do not?    In particular, if I start out with:     <Foo xmlns:bar='baz'><Bar /></Foo>    Then when I start processing, as far as XPath is concerned  this is equal to:      <Foo xmlns:bar='baz'><Bar xmlns:bar='baz' /></Foo>    I use the following xpath:      . namespace::* *    The result is:      <Foo xmlns:bar='baz'><Bar /></Foo>    This is the same as my original document. When I go to C14n  or XPath again, does the inherited attribute reappear, just as  when I went to XPath originally?    Or to start out, should I have physically created all inherited  namespace nodes? Or is this an XPath question.    And again, I apologize for the entropy.    Merlin  --  I will think before I S/:wq.    r/merlin@baltimore.ie/2000.08.30/18:16:28  >  >I understand now.  >  >All elements do actually contain the inherited namespace nodes  >within their namespace axis. I just failed to understand this.  >  >Apologies.  >  >Merlin  >  >r/merlin@baltimore.ie/2000.08.30/18:09:29  >  >>I think my brain is on vacation at the moment. Or maybe this has been  >>addressed and fixed in the working copy of this document. Or brought  >>up before and solved. But...        

      I don't see what's so hard about:    For obtaining byte order mark,    node *MyXMLProcessor(char *filename, char *BOM)  {  FILE *infile = fopen(filename, "r");  fread(infile, 2, 1, BOM);  fclose(infile);    return YourXMLProcessor(filename);  }    For exact order, your implementation should simply throw an algorithm  unavailability exception if your lex-order-aware implementation encountered  an exact order signature.    John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  jboyer@PureEdge.com    -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of TAMURA Kent  Sent: Thursday, March 09, 2000 11:31 PM  Subject: Re: Comments on last call draft        > As for exact order in the XPath transform, are you saying that if we  > eliminated exact order and used only lex order, then we could accomplish  the  > XPath transform with some set of existing tools?    Yes when we use a DOM Level 2 implementation.    We can not sort attributes before XPath processing because DOM  has no reordering function.  So we have to sort after XPath  processing.    <root>    <child b="b-value"/>    <child a="a-value"/>  </root>    "//child/@*"    The result of applying the above XPath expression to the above  document is a node-set consisted of two attribute nodes (Attr in  DOM).  We can not decide whether we may sort the node-set  because Attr has no method returning its parent element and we  can not know whether these attribute nodes are in the same  element.  Attr in DOM Level 2 has the getParentElement() method.    > As for exprEncoding and exprBOM, you should note that you will be  receiving  > an XML document containing a signature element which contains the XPath  > expression, the encoding of that document determines the encoding of the  > XPath expression.  I created exprEncoding and exprBOM as a way of making  it  > clear that the application must provide these pieces of information from  the  > document to the XPath transform precisely so that the expression could be  > reencoded to a format that is suitable for your XPath expression evaluator    We need not these information.    When an XML processor parses a signature document, all  characters including any XPath expression are represented in an  internal encoding, that is UTF-16 in DOM.  XPath evaluators in  Java, Xalan/LotusXSL and XT, receive expressions in UTF-16 and  they implements the XPath `string' instances as UTF-16 sequences.    > As for re-using existing XML processors and XPath libraries, I'm quite  > certain you are incorrect about not being able to use an existing XML  > processor (Clark's parser, for example, can easily be used to create the  > parse tree I've specified).    I do not know XML processors that provide the BOM information of  parsed document.  Some XML processors provide the encoding  information of the document entity with each original method but  it is very difficult or impossible in existing XML processors to  detect an encoding of specific node because XML documents may  contain external entities.    --  TAMURA Kent @ Tokyo Research Laboratory, IBM        

      Hi Juergen,    The algorithm identifier for C14N with comments is different.  It is    http://www.w3.org/TR/2000/WD-xml-c14n-20000907#WithComments    This is reflected in the editors' copies I posted (see the archives), and  will be present in the next rev of the WD.    Thanks,  John Boyer    -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Juergen Brauckmann  Sent: Friday, September 08, 2000 12:31 AM  Subject: xml_dsig, C14N and comments      Hi.    Two questions:    1. How can I know as an implementor of xml_dsig whether a canonicalization  or transform with algorithm  <http://www.w3.org/TR/2000/WD-xml-c14n-20000907> was done with or without  comments?      2. Consider the following example:  <Signature xmlns="http://www.w3.org/2000/07/xmldsig#">    <SignedInfo>     .....     <Reference URI="#Stuff">        <Transforms>           <Transform  Algorithm="http://www.w3.org/TR/2000/WD-xml-c14n-20000907" />        </Transforms>        ....     </Reference>    </SignedInfo>  ...    <Object Id="Stuff">      <MyOwn>        <Additional></Additional>      </MyOwn>    </Object>  </Signature>    Are the elements of Object treated as #PCDATA, or do I have to apply C14N?      Regards,     Juergen        

      From James Clark:    What's twisted and bizarre is using an extension function to get an  initial handle on the source document, instead of using the mechanism  that is built into XPath namely the context node.  This will make XPath  expressions used in your application confusingly different from XPath  expressions used everywhere.    <John>  Where the node-set comes from did not and still does not seem confusing to  me, but it seems to be such a thorn, so obviously parse will be thrown out  (see below).    Further, you still didn't answer the question of what I see as an oversight  in the XPath specification.  You must be able to use empty node-sets by your  own specification, so what should the context node, size and position be for  an empty node-set?  </John>    Because you're not using the language in the way it is designed, there  are likely to be subtle traps.  For example, you will lose the ability  to use the id() function (because functions are not allowed as the right  hand operand of /).  It's also going to be very awkward.  Instead of something like      e1|e2|e3|e4    you will have to write    parse($input,true())/e1|parse($input,true())/e2|parse($input,true())/e3|pars  e($input,true())/e4    <John>  Parsing 4 times in this case is simply not necessary:    parse($input,true())/descendant-or-self::node()[id("e1")|id("e2")|id("e3")|i  d("e4")]    However, it really doesn't matter to me if the spec were modified slightly  to eliminate parse() and instead pass the information in a context node-set  as you recommend.  But while I have the attention of an authority on the  issue, perhaps you could answer a few other questions.    Firstly, would it be fair to assume that any XPath implementation will have  at least two points of entry:  eval() and parse()?  If the XPath transform  must provide the input to the XPath engine as a context node-set, then  presumably the node-set must be something that is understandable by the  XPath engine.  Hence, the XPath engine must provide the parse() in order to  allow it to build a node-set data structure that it will understand when  eval() is called.  In fact, I would not be surprised to see entry points for  construct variable bindings, construct namespace bindings, and construct  initial context, since all of these are data structures that the Xpath  engine's eval function will need.    Secondly, could you suggest whether we should restrict the transform input  to be a well-formed XML document?  The transform input is defined by the WG  (not by me) to be a string of data resulting either from the previous  transform or from URI dereference.  So, *something* must be used to convert  to a node-set.  Currently, I would be using your parser, and I would prefer  not to have to use pieces of your parser to read something which is not a  complete, well-formed XML document.  Is this reasonable?    Finally, since you only discussed problems with parse, I assume you have no  objection to the serialize() function.  This is actually the main function  that we need, as expressed previously in DSig WG face-to-face meetings.  The  transform output MUST be a string, which may be given to a digest algorithm  or as input to a subsequent transform.  The result of an XPath expression  may not be a string.  If it is a boolean or number, we can simply call  string on it implicitly, but if the result is a node-set, then we need to  regenerate the actual XML markup for that node-set based on document order  (and lex order only for the attribute and namespace axes).  Making this into  a function that returns a string, and adding that to the function library  seems to be the XPath specification's recommended way of extending XPath in  a particular application.  Is this reasonable?    Thanks,  John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  jboyer@PureEdge.com    </John>        

      Hi Don,    I see where you are coming from now, and it is both interesting and correct,  but it means we need to be saying something more in DSig, if not in XML  Names.    The appendix refers to the attributes as 'unqualified'.  The section is not  saying that unqualified attributes are qualified by per element partitions  (because then it wouldn't be unqualified).  Instead, because it is  non-normative, it is saying that one is free to look at it this way if it  makes one feel better.    The implication is that "per element partitions" don't really exist and need  not be supported by conforming applications.  In other words, the material  on per element partitions is a convoluted way of saying that the only thing  which matters is that an attribute appears within an element and should  therefore be processed as though it were in that element's namespace unless  it has a non-empty namespace other than the element's.  As well, I think  this is what you are saying.    Unfortunately, it actually does matter quite a bit.  For starters, suppose  you have an HTML anchor with two hrefs, one unqualified and the other in the  HTML namespace.  Which does one use?  Put in another more general way, given  element E in namespace N, if one wants to obtain attribute A from E, which  of the following processing models is correct?    1) Attr = (N:E).get(N, A)  2) if Attr is null, Attr = (N:E).get("", A)    or    1) Attr = (N:E).get("", A)  2) if Attr is null, Attr = (N:E).get(N, A)    It makes a difference if the XML is <N:E xmlns:N="N" A="2" N:A="1">.  The  first model gives the attribute whose value is 1, and the second model gives  the attribute whose value is 2.    I don't think this can be explained away as a simple differing viewpoint  because I don't agree that all applications process attributes solely within  the context of the parent element.  The prime example of this is XSLT, which  uses XPath for template matching.    Lets compare the following four occurences of an element E by considering  the xsl-template's XPath expression that must match E based on whether the  value of an attribute A is 'test':    1) <N1:E xmlns:N1="http://www.w3.org" xmlns:N2="http://www.PureEdge.com"  A="test"/>  2) <N1:E xmlns:N1="http://www.w3.org" xmlns:N2="http://www.PureEdge.com"  N2:A="test"/>  3) <N1:E xmlns:N1="http://www.w3.org" xmlns:N2="http://www.PureEdge.com"  N1:A="Yikes" N2:A="test"/>  4) <N1:E xmlns:N1="http://www.w3.org" A="test" N1:A="Yikes"/>    The xsl-template cannot simply try to match on the local name A or else  element E in #2 would be matched, which is clearly not intended. If we add  to the XPath test a call to namespace-uri() to match the URI for N1, then #3  works but #1 doesn't.  If we add a test that finds the local name of A and a  namespace-uri() that is either blank or equal to the URI for N1, then #1 -  #3 work as expected, but #4 has two attributes that match the test.    If the claim is true that attributes should be processed within the context  of the parent, then A="test" would indicate that the xsl-template should  match N1:E in #4.  However, N1:A is clearly the attribute A in element E's  namespace, so for the purposes of the primary processing application for the  N1 namespace, N1:A and A are duplicates.    Personally, I don't believe in duplicate attributes.  The normative part of  XML Names makes it clear that the attributes are not duplicates in name  (which is a well-formedness requirement of XML), but if the non-normative  part of the spec invents some concept that makes the two attributes equal  for the purposes of processing, then a precedence must be specified. Which  one has precedence?  Until we know this, the proper xsl-template cannot be  written.    If I had to guess on a processing precedence, I would guess that the  namespace qualified version should take precedence.  Here's why:    I've been sitting here trying to figure out why the default namespace does  not apply to attributes, and the only thing that I can think of is that  unqualified attributes can then be used to apply an attribute value across  all namespaces.  In other words, a sort of default value to be used when no  namespace specific attribute is given. Consider the following bit of XML:    <E xmlns:N1="http://www.w3.org" xmlns:N2="http://www.PureEdge.com"  A="default" N1:A="Value for App that processes N1" N2:A="Value for App that  processes N2"/>    The information in element E can be used by one application that conforms to  specification given at the URI for N1, or it could be processed by a second  application that conforms to specifications given at N2, or it could be  processed by some other generic XML processing application.  If, by  convention, namespace qualified attributes took precedence over unqualified  attributes for processing, then the value for A would be  application-dependent.  If unqualified attributes took precedence, then A  would always equal default.    Perhaps XML names will not be changed or clarified, and perhaps they will  make no recommendation, but for a particular application, esp. a security  conscious one such as DSig, we should be saying what we expect our  processors to do when there are qualified and unqualified attributes with  matching local names.    John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Donald E. Eastlake  3rd  Sent: Friday, August 11, 2000 1:57 PM  Subject: Re: Determining attribute uniqueness seems to require namespace  prefix in Infoset        From:  "John Boyer" <jboyer@PureEdge.com>              "XML DSig" <w3c-ietf-xmldsig@w3.org>  Date:  Fri, 11 Aug 2000 13:01:46 -0700  Message-ID:  <BFEDKCINEPLBDLODCODKMEEPCEAA.jboyer@PureEdge.com>  In-Reply-To:  <200008111839.OAA06618@torque.pothole.com>    >Hi Don,  >  >I did not mean to misquote you.  However, I haven't seen any W3C documents,  >nor implementations based on them, that use the term 'qualify' as you are  >using it.  It is not possible to 'qualify' an attribute with anything but a  >namespace URI.    It is syntactically not possible to attach any type of qulifying text  string to an attribute other than a prefix which corresonds to a URI.  However all non-prefixed attributes are automatically 'qualified' by  their element.    >In other words, in the example  >  ><x xmlns:n1="http://www.w3.org" xmlns="http://www.w3.org" >  >  <good a="1"     n1:a="2" />  ></x>  >  >There does not seem to be any basis in W3C work for the interpretation  >  >1) that 'a' is qualified as (n1:good):a,  >2) that 'a' is not qualified by a URI, and  >3) that 'a' is qualified by elements, including any URI which may qualify  >that element    See <http://www.w3.org/TR/1999/REC-xml-names-19990114> section A.2.  I  had to read this section and related material many times to make sense  out of them.    The unprefixed "a" above is in the Per-Element-Type Partition  associated with the element "good" in the namespace http://www.w3.org.  Whether you consider "a" to be "qualified" by n1:good or "local" to it  or part of it's Per-Element-Type Partition is all the same.  And it is  different from n1:a which is in the Global Attribute Partition.    >Therefore, when you said that the attributes "are qualified by their  >element", I assumed you meant 'qualify' in the sense defined by XML Names  >[1, see the abstract], which associates elements and attributes with a  >namespace identified by URI.  With this version of 'qualify', what you said  >is equal to what I said you said.    Unprefixed attributes are not associated with just a namespace.  They  are associated with an element which is in turn associated with a  namespace.    >Finally, ending most of our debate about this issue, Tim Bray states, "An  >attribute whose name contains no prefix is not in any namespace".  This  >means that in the first example of Section 5.2 of XML Names, the href in  <a>  >is not in the HTML namespace.    Well, it's not "directly" in any namespace.  It's in the  Per-Element-Type Partition of the element "a" in the HTML namespace.    No doubt debate is ended by a correct understanding of what Tim Bray  has said just as it is ended by a correct understanding of  http://www.w3.org/TR/1999/REC-xml-names-19990114 or a correct  understanding of the "Namespace Myths Exploded" material at xml.com.  The question is, what is "correct" understanding?    >This means if I put an HTML island in the middle of some XML by adding  >xmlns="http://www.w3.org/TR/REC-html40" to the html tag, then when I want  >the href of some anchor, I cannot simply say  >'get("http://www.w3.org/TR/REC-html40", href)'.  I must instead say  >  >1) get("http://www.w3.org/TR/REC-html40", href)  >2) if that fails, then get("", href)  >  >Once again... Yikes!    I'm not sure I understand this part of what you are saying but if your  understanding is that the treatment of unprefixed attributes is  fundamentally broken perhaps your understanding is incorrect.    Note that the Myths Exploded text keeps saying fuzzy handwaving things  like it doesn't really make much difference (which is why Appendix A  to the Namespaces document is not normative) because real applications  only handle non-prefixed attributes within the conext of the element  where they appear anyway.  In my mind it is just a difference in point  of view whether you consider such attributes to have no "qualifying  stuff" but to be used/operated on by their element, or you try to  induce a universal uniqueness by consdering them qualified by their  element name local part and their element's namespace if any.    >John Boyer  >Development Team Leader,  >Distributed Processing and XML  >PureEdge Solutions Inc.  >Creating Binding E-Commerce  >v: 250-479-8334, ext. 143  f: 250-479-3772  >1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>    Thanks,  Donald    >-----Original Message-----  >From: w3c-ietf-xmldsig-request@w3.org  >[mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Donald E. Eastlake  >3rd  >Sent: Friday, August 11, 2000 11:39 AM  >To: John Boyer  >Cc: xml-names-editor@w3.org; www-xml-infoset-comments@w3.org; XML DSig  >Subject: Re: Determining attribute uniqueness seems to require namespace  >prefix in Infoset  >  >  >  >From:  "John Boyer" <jboyer@PureEdge.com>  >To:  <xml-names-editor@w3.org>  >Cc:  <www-xml-infoset-comments@w3.org>, "XML DSig"  <w3c-ietf-xmldsig@w3.org>  >Date:  Fri, 11 Aug 2000 10:15:32 -0700  >Message-ID:  <BFEDKCINEPLBDLODCODKOEEKCEAA.jboyer@PureEdge.com>  >  >>Dear Editors,  >>  >>Please see the first example of Section 5.2 and the sentence immediately  >>above it, which says "Note that default namespaces do not apply directly  to  >>attributes" [1].  One chairman of the XML DSig group recently commented  >that  >>the word 'directly' may be intended to indicate that unqualified  attributes  >>inherit their namespace setting from the parent element.  This seems  >>sensible to me as the href attribute should be in the same namespace as  the  >>parent element <a>.  >  >No, I did not say that attributes "inherit their namespace setting  >from the parent element".  I said that they are qualified by their  >element.  That is, in  >  ><b:a xmlns:b="foo:bar" c="xyz">  >  >it is "as if" c were actually b:a:c except, of course, that this  >syntax is illegal.  >  >>[1] http://www.w3.org/TR/REC-xml-names/#defaulting  >>  >>However, now look at the last example of Section 5.3.  The second  occurence  >>of <good> has attributes a and n1:a.  This is declared as legal, but if  'a'  >>inherits its namespace setting from good, then a and n1:a appear to be  >>equal.  >  >But n1:a and n1:good:a would be different.  >  >>...  >>  >>Could you please advise us on the correct interpretation (and fix the  error  >>if indeed there is one)?  >>  >>  >>     John Boyer  >>      Development Team Leader,  >>      Distributed Processing and XML  >>      PureEdge Solutions Inc.  >>      Creating Binding E-Commerce  >>      v: 250-479-8334, ext. 143  f: 250-479-3772  >>      1-888-517-2675   http://www.PureEdge.com  >  >Donald  >        

      Hi Joseph,    Section 12 "Authors' Addresses" should be "Editors' addresses"      John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Joseph M. Reagle  Jr.  Sent: Wednesday, July 26, 2000 8:24 AM  Subject: RE: XSL Transform      At 17:29 7/25/2000 -0400, Ed Simon wrote:   >4.  There is no reason why an XSLT transform in an XML Signature should  not   >have a root element of   ><stylesheet xmlns="http://www.w3.org/1999/XSL/Transform">   >and contain complete, valid XSLT stylesheets.   >   >5.  Schemas allow us to enforce point 4.  Enforcing point 4 will make it   >that   >much easier to achieve point 3.    As an aside, the use of ANY has the implied default of  processContents='strict'. This may be approriate in specific instances (like  XSLT) however I think it's a bit too strict for everything in general. So I  propose we move towards <any ...  processContents='lax' ...> in things like  Transorms, Object, PGPData, SPKIData, etc.     >The problem with the <any> element is that even if the namespace attribute   >is "http://www.w3.org/1999/XSL/Transform", it does not   >enforce that the child element is <stylesheet> so it could be quite  possible   >to have    That is true: "Any well-formed XML from any namespace (default)"    If we wanted to do what you are speaking of we'd use a declaration below (I  think). However, XSLT [1] didn't provide a schema anyway and consequently  there might be some other tricks we could do, but seems too complicated for  the derived benefit...    <schema targetNamespace='&dsig;'     version='0.1'     xmlns='http://www.w3.org/1999/XMLSchema'     xmlns:ds='&dsig;'     elementFormDefault='qualified'     xmlns:xsl="http://www.w3.org/1999/XSL/Transform"> <!--Simon-->   <import namespace='http://www.w3.org/1999/XSL/Transform'/> <!--Reagle-->    ...    <element name='Transform'>      <complexType content='mixed'>        <choice minOccurs='1' maxOccurs='unbounded'>          <any namespace='##other' minOccurs='0' maxOccurs='unbounded'/>          <element name='Xpath' type='string'/>          <element ref="xsl:stylesheet"/>    <!--  Simon-->        </choice>        <attribute name='Algorithm' type='uriReference' use='required'/>      </complexType>    </element>  __    [1] http://www.w3.org/TR/1999/REC-xslt-19991116    _________________________________________________________  Joseph Reagle Jr.  W3C Policy Analyst                mailto:reagle@w3.org  IETF/W3C XML-Signature Co-Chair   http://www.w3.org/People/Reagle/        

      To alleviate concerns expressed in [1], I've tweaked the serialization of  text, PI and namespace/attribute nodes (attached).  I also clarified the  namespace node ordering, and I set apart the QName definition and reiterated  the parsing requirement.    [1]  http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/2000AprJun/0034.html    By the way, might we expect to have a new draft prior to the Victoria FTF?    Thanks,  John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com          text/html attachment: transforms4.htm          

      Hi Kevin,    Actually the confusion came from the fact that you sent the letter directly  to me as well as dsig, rather than to John Cowan and the dsig group.    Sincerely,  ***************************************  John Boyer,  Software Development Manager    PureEdge Solutions (formerly UWI.Com)  Creating Binding E-Commerce    v:250-479-8334, ext. 143 f:250-479-3772  1-888-517-2675  http://www.PureEdge.com  ***************************************        -----Original Message-----  From: Kevin Regan [mailto:kevinr@valicert.com]  Sent: Friday, June 23, 2000 3:03 PM  Subject: RE: No Character Normalization?      Sorry,    I should have said "Mr. Cowan" rather than John in  my response.  Didn't mean to confuse anyone... :-)    --Kevin    -----Original Message-----  From: John Boyer [mailto:jboyer@PureEdge.com]  Sent: Friday, June 23, 2000 3:04 PM  Subject: RE: No Character Normalization?      Hi Kevin,    I appreciated your email, however, I did not get it (due to a meeting)  until  after it was already answered.  Full credit for the informative and  authoritative answer belongs to John Cowan.    Sincerely,  ***************************************  John Boyer,  Software Development Manager    PureEdge Solutions (formerly UWI.Com)  Creating Binding E-Commerce    v:250-479-8334, ext. 143 f:250-479-3772  1-888-517-2675  http://www.PureEdge.com  ***************************************        -----Original Message-----  From: Kevin Regan [mailto:kevinr@valicert.com]  Sent: Friday, June 23, 2000 2:58 PM  Subject: RE: No Character Normalization?        John,    Thanks for the information.    My greatest concern is to not have to tell my customer that "No, I  can't sign that.  How did you create that document anyway?"    If it is the usual case that documents are created in the normalized  form, then it does not seem like a big issue.  What would happen  in the case of an editor or application written in Java (Unicode)?  It seems that this is the most important case given the close  coupling of Java and XML.    Another concern is whether a document can become "de-normalized" during  transmission.  My previous question was not specific enough. I  understand  that documents can be converted to other character formats. However, I'm  wondering if a document can leave one application in a normalized form,  go  through various character encodings, and enter another application  with the characters no longer normalized (e.g.  A Java application to  Java  application might go from Unicode, to UTF-8 for transmission, and then  back to Unicode in the other application).    Finally, you mention that the detection of a non-normalized document  would aid in the discovery of forgery.  My question is: should similar  documents with different character models be equivalent?  What would most people expect?  I don't really understand the usage  enough to have an opinion on this...    --Kevin        

      Hi Kevin and Joseph,    Yes, a signature will break if you move it into a different namespace  context, whether or not the changed namespaces are actually being used  within the Signature element.    Canonicalizing an element E must include the full namespace context because  it is impossible to determine which namespaces are actually being used with  E.  E could be an application-specific element with textual content that  makes reference to some namespace.  The Signature element is simply an  instance of this element E.  There can be an XPath Transform somewhere  within the content of Signature.  As well, SignatureProperties appear to be  fairly open, so namespace references could exist within them that we have no  way of determining.    So, the reason we don't restrict namespace context to the subset of the  namespace context in use is because we have no real way of specifying how to  determine the desired namespace context subset.    Finally, if we were to omit namespaces that are being used, security holes  result.  For example, suppose I have an XPath transform that keeps all nodes  in a referenced document D except omitting those based on a certain  namespace qualified tag.  The namespace is available to the XPath transform  but does not get signed.  Therefore, the namespace assignment can be changed  to a different URL without breaking the signature and without breaking the  ability to evaluate the XPath expression.  Thus, I am now able to add  unintended information to D without breaking the signature.  This violates  the notion of document closure.    John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>      -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Kevin Regan  Sent: Wednesday, July 12, 2000 12:33 PM  Subject: Re: namespace question        This brings up a few other issues.  If the namespace declarations of the  parents of the Signature node are to be included in the canonicalization,  you can not simply create a single signature and place it in multiple  locations within the final document.  You would have to compute the  signature multiple times, in a context-sensitive way, even if the two  signatures signed the same set of references.    Also, we have to look at what this means for Object elements  being signed.  In this case, the Signature object must be  created, with its associated namespace declarations and  the digests of Objects must be computed, taking into account  the namespace declarations of the Signature element as well  as its parent elements.    Now, let us apply this to nested signatures (a Signature element  within an Object element of another Signature element).  In this  event, how was the nested Signature element created?  Normally,  it seems to be the case that a nested signature was created by  simply grabbing that signature from somewhere else (it had already  been created), and placing that in an Object element of another  signature.  This would not be possible if signatures are  context-sensitive.    I'm wondering if it would make sense to terminate the namespace  declaration search at the Signature and Object element boundaries.  In this case, we avoid the various problems above.    --Kevin      On Wed, 12 Jul 2000, Kevin Regan wrote:    >  > When signing a portion of an XML document (and Element and its  > children), it is necessary to have the entire document in order  > to determine the namespace declarations of the parents of the  > Element.  >  > An XML Signature represents only a portion of a document.  > Once the Signature element and its children are created,  > it will be inserted somewhere in an XML document.  > Therefore, it may not be known in advance what the parent  > Element of the Signature element will be.  >  > My question is, when canonicalizing the Signature element  > to compute the SignatureValue, is it necessary to include  > the namespace declarations of the parents of the Signature  > element.  If so, it is necessary to know where in the enclosing  > XML document that the newly generated signature will be inserted.  >  > --Kevin  >  >  > > This is done such that you can move a signature and ensure its  > namespace  > > context is taken with it.  > >  > >  >  What I'm not exactly clear on  > >  >is if this applies to the actual Signature element for the signature  > > being  > >  >created.  > >  > > I don't quite follow...  > >  > >  >I don't think that it does (I don't believe that you need to  > >  >look at the parent elements of the Signature element to determine  > > their  > >  >namespace declarations)?  Is this correct?  If not, wouldn't it mean  > > that  > >  >the insertion point for the Signature element must be known in  > advance  > > so  > >  >that these declarations can be obtained?  Are there any differences  > > for  > >  >detached, enveloped, or enveloping signatures?  > >  > > What do you mean known in advance?  > >  > >  > > _________________________________________________________  > > Joseph Reagle Jr.  > > W3C Policy Analyst                mailto:reagle@w3.org  > > IETF/W3C XML-Signature Co-Chair   http://www.w3.org/People/Reagle/  > >  >        

      Hi Gregor,    Short answer:    The attached documents should help demonstrate the point.  They were  produced via the following call:    saxon -o testNS.txt testNS.xml testNS.xsl    Long answer:    Actually, you aren't citing the whole paragraph but just the dependent  clause beginning with the word 'except'.  This dependent clause qualifies  the first part of the paragraph.  The complete paragraph is:    "A QName in the node test is expanded into an expanded-name using the  namespace declarations from the expression context. This is the same way  expansion is done for element type names in start and end-tags except that  the default namespace declared with xmlns is not used: if the QName does not  have a prefix, then the namespace URI is null (this is the same way  attribute names are expanded). It is an error if the QName has a prefix for  which there is no namespace declaration in the expression context." [1]    [1] http://www.w3.org/TR/xpath#node-tests    Thus, it is the QName in the node-test that is expanded without the benefit  of the default namespace URI, should it be defined for the evaluation  context of the XPath expression.    However, the namespace URI of an element in the input document is available  for comparison whether it was specified by explicit or default namespace  qualification.    The attached documents include testNS.xml and testNS.xsl.    The xml file contains a root document element named Test that has three  children with the same local name 'e'.  The first is unqualified, the second  is qualified by default, and the third is qualified by explicit declaration  of the prefix 'NS'.    The xsl file contains three templates.  The first simply latches onto the  root element Test, and applies all templates to its child elements.  The  second template is designed to match elements with local name 'e' and no  namespace URI.  The third template matches elements 'e' that have a  namespace URI of testNS (which is the declared value of the NS prefix).    The result of the transformation appears in testNS.txt.  The exception in  the paragraph of XPath cited above is demonstrated by the fact that the  second template only matches the unqualified element 'e' despite the  declaration within the second template of 'testNS' as the default namespace  URI.  The fact that the third template (bearing the match expression "NS:e")  matches both the second and third elements 'e' demonstrates that input  elements retain their namespace URI if it was derived by default and that  namespace qualified input elements are matched by namespace URI and local  name, regardless of how they obtained their namespace URI.    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: Gregor Karlinger [mailto:gregor.karlinger@iaik.at]  Sent: Thursday, September 07, 2000 11:09 PM  Subject: AW: XPath question      Hi John,    > In the first code example, the Signature is in the default namespace of  > &dsig;.  However, the XPath expression has the dsig prefix  > declared, and the  > match to the Signature is done using dsig:Signature.  Thus, matching  > elements in the default namespace can be done by setting up a prefix with  > the same URI as the default namespace.    What is your source for that information? I think the paragraph I have  cited in my first message, reads quite clear, that the default namespace  is not used in XPath:      "...except that the default namespace declared with xmlns is not used:     if the QName does not have a prefix, then the namespace URI is null     (this is the same way attribute names are expanded). "    I have posted my concerns also in the developer newsgroup of the Apache  Xalan project. The response I got from Joseph Kesselman, one of the  developers, is:      "XPath does not use the default namespace declaration. If you don't  specify    a prefix, the name is assumed to be in _no_ namespace (the original    default, not the changed default). If you want to access a namespaced  node,    you must use an explicit prefix which maps to that namespace.      See the XPath spec, section 2.3 (Node Tests), third paragraph or    thereabouts."    Maybe we should ask the editors of XPath of the intended meaning of the  sentence above.    Regards, Gregor  ---------------------------------------------------------------  Gregor Karlinger  mailto://gregor.karlinger@iaik.at  http://www.iaik.at  Phone +43 316 873 5541  Institute for Applied Information Processing and Communications  Austria  ---------------------------------------------------------------            text/xml attachment: testNS.xml    text/xml attachment: testNS.xsl    text/plain attachment: testNS.txt          

      Hi all,    We are booking for a max of 25 people, which seems to be in excess of the  usual attendance for these meetings (which is around 20).  There will be a  continental breakfast and buffet lunch provided.  A/V equipment =  whiteboard, overhead and either a 1024x768 LCD panel or a computer screen  projector.    Also, there has been some interest in getting together for Tea at the  Empress.  If you are coming to the Victoria meeting, and you would like to  come to tea at 3:30pm on April 19 (the day before the meeting), could you  please send me an email so I can get some idea of how big a booking we will  need.    Thanks,  John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  jboyer@PureEdge.com      -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Donald E. Eastlake  3rd  Sent: Monday, March 13, 2000 4:36 AM  Subject: Face to Face meeting Schedule CHANGE to April 20th in Victoria        Due to several schedule conflicts, the face to face meeting has been  moved one week later.  Our apologies for this change but it was  important to be sure that the primary authors and editors of the  syntax and processing ]document could attend.    There will be a Face to Face meeting of the XMLDSIG WG at the Victoria  Conference Center in Victoria, British Columbia, Thursday April 20th,  hosted by PureEdge Solutions, Inc.  Info on hotels will be posted  shortly but people might want to start looking into airfare.  The  Victoria and Vancouver areas have a number of attractions so you might  consider staying later or arriving earlier and doing some touring.    Thanks,  Donald    =====================================================================   Donald E. Eastlake 3rd                      dee3@torque.pothole.com   65 Shindegan Hill Road, RR#1                     +1 914-276-2668(h)   Carmel, NY 10512 USA                             +1 508-261-5434(w)        

      Hi TAMURA-san,    According to the table you cited, I have so far meant UTF-8N in every  instance where UTF-8 is currently used.    However, I have not before seen any document that prepends an encoding  signature, nor have I ever seen a reference to UTF-8N.  Is there any support  other than this table for the UTF-8N nomenclature, or am I just behind the  curve on this one?    To the contrary, the XML 1.0 specification clearly uses the encoding UTF-8  (which is the default) to mean UTF-8N by the table you cited.  For example,  Section 4.3.3 contains the following sentence:    "Note that since ASCII is a subset of UTF-8, ordinary ASCII entities do not  strictly need an encoding declaration."    Thanks,  ***************************************  John Boyer,  Software Development Manager    PureEdge Solutions (formerly UWI.Com)  Creating Binding E-Commerce    v:250-479-8334, ext. 143 f:250-479-3772  1-888-517-2675  http://www.PureEdge.com  ***************************************        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of TAMURA Kent  Sent: Monday, June 19, 2000 5:52 PM  Subject: Clarify `UTF-8'      XML Signature spec. and Canonical XML spec. refer 'UTF-8' many  times.  Please clarify which is each UTF-8, 'UTF-8' (with UTF-8  signature, EF BB BF) or 'UTF-8N' (without UTF-8 siganture).    See Table 2 in  http://www-4.ibm.com/software/developer/library/utfencodingforms/index.html    --  TAMURA Kent @ Tokyo Research Laboratory, IBM        

      Hi John,    The three issues you've raised are:    1) > encoding.  Right.  I forgot about that seeming hack in the XML spec.  If all XML parsers were 'true' parsers, then there would be no need to  escape ]]> from regular character content since it is not an expected token.  Nonetheless, thanks for reminding me about this, and I will tweak the next  c14n draft to put > encoding back in.    2) Comments.  I apologize if I've offended you in some way, but since I  haven't really corresponded with you before, I don't see how that is  possible. W.R.T. javascript being in comments, they do appear to be in  comments, and when I feed an XML compliant piece of HTML to an XML processor  I have on hand, it does seem to report them as comments, so I don't believe  I am 'calling the dog's tail a leg' so to speak.  However, if you would  prefer, I can remove the reference to javascript since the section    a) points out other reasons for retaining comments  b) easily shows how their elimination can be described.    I seem to recall a SAX 1 technical write-up that claimed that SAX 1 would  not send comment events because comments were for document authors, not  document consumers.  The assumption seemed to be that XML would only be  authored in a text editor.  If I am using a design tool, I don't want it to  toss my comments.  The point being that it is generally better to keep the  comments, then give specific applications the ability to opt out.    3) Whitespace Text node descendants of the root.  The toolsets' elimination  of this whitespace would seem to be in contradiction of section 2.10 of the  XML spec.  However, the point is moot since the problem can be solved by the  same idea as #2 above.  The XPath expression to opt out of this is given.  Therefore, if your particular XML processsor can't support their inclusion,  then set up your application context such that it is clear that you are  using something with behavior that is equivalent to the XPath expression  provided.    TAMURA-san, this should also solve your concern.  By the way, is this a  problem with your current implementation of XPath serialization as well?  I  am reticent to switch to automatic dumping of text node descendants of the  root (and concomitant addition of a linefeed to each end of PI marker)  because means each text node in the node-set must be checked for this  condition, which reduces efficiency.    Also, do the tools you have discard comments outside the main document  element?  In other words, do we have the same toolset problem with comment  node descendants of the root?    John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com      -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of John Cowan  Sent: Thursday, June 01, 2000 8:25 AM  Subject: Comment on Canonical XML draft of 2000-06-01, clause A.3      The reason for requiring ">" rather than simple ">" in previous  drafts of Canonical XML is that the sequence "]]>" is not well-formed  when used in character content.  As written, the document    <foo>]]></foo>    will canonicalize as    <foo>]]></foo>    which is not well-formed.  See XML Recommendation clause 2.4, third  paragraph, last sentence, and note the modal verb "must".    --    Schlingt dreifach einen Kreis um dies! || John Cowan  <jcowan@reutershealth.com>  Schliesst euer Aug vor heiliger Schau,  || http://www.reutershealth.com  Denn er genoss vom Honig-Tau,           || http://www.ccil.org/~cowan  Und trank die Milch vom Paradies.            -- Coleridge (tr. Politzer)        

      I realize this is after the last call period, but the matter was brought to  my attention after the last call period for XML base.    XML base is restricted from applying to external entities.  However, when  you c14n a document, the external entity content is brought into the  document, so xml:base will apply to it.    Right now, I have language in c14n that propagates xml:base to descendant  elements in the case of document subsets, but the problem above occurs even  when one does a c14n of the whole document.    I think c14n is doing the right thing in that it is consistent with what  xml:base should do:  the entities are no longer external, so xml:base  attributes from ancestors should apply to them.  It think the problem is  that the meaning of the content is changed based on where we get it from.    We have no way of retaining information on content derived from external  entities.  In particular, the feature seems to contradict the language of  section 4.4.2 of XML 1.0:    "An entity is included when its replacement text is retrieved and processed,  in place of the reference itself, as though it were part of the document at  the location the reference was recognized. "    Since the replacement text should be treated 'as though it were part of the  document', we should not introduce an attribute into the xml namespace that  violates this concept.           John Boyer        Development Team Leader,        Distributed Processing and XML        PureEdge Solutions Inc.        Creating Binding E-Commerce        v: 250-479-8334, ext. 143  f: 250-479-3772        1-888-517-2675   http://www.PureEdge.com                                

      Hi Gregor,    You can look at that material as a marker to indicate that we *may* need to  do something to deal with the possible loss of information for xml:lang and  xml:space.  However, I do not think it means what you think it means.  Based  on your example below, I would not have expected the internal content of the  poem to appear because its text node does not match the expression given.    However, the expression as given doesn't really do what I want it to do.  What I'd really like to capture is only the ancestors of nodes in X that  have xml:space or xml:lang declarations.  That appears to be a bit more  difficult to express (suggestions welcome).    Actually, the main thing I don't like about the solution I've given is that  it tends to include certain peripheral information that the XPath expression  author really needs to get rid of (hence, the solution is quite unlikely to  stay around).  For example, if you omitted an element's ancestor chain, it  may be your intent to allow the ancestry of the signed element to vary, but  it wouldn't necessarily be able to if the wrong combination of xml:lang and  xml:space appear.    An alternative I've been thinking of is to change the element rendering  algorithm so that any element whose direct parent is not rendered would be  required to run its ancestor chain looking for 'xml:' attributes to  duplicate *within the element's start tag*.    This would set a precedent that 'xml:' attributes *always* apply to  descendants, but it would solve the problem we're currently discussing as  well as deal with the problem we haven't discussed yet, which is what will  happen when XBase becomes a recommendation.  We will need to preserve XML's  understanding of the Base URL in partial documents.  In general, information  lost due to a loss of xml: attributes is contrary to the needs of DSig.  For  a particular XML vocabulary, it is possible to argue that a specific XPath  could not possibly omit meaningful information, but this is based on never  losing relevant information from ancestors.  Unfortunately, XML itself uses  this technique often.  To compensate, we do things like propagate namespaces  down to descendants.  It seems reasonable that we should use the same  practice for xml: attributes, even if no data model currently in  recommendation accounts for this.    I'd be interested to know what you (and the other cc'd people) think of this  alternative.    Thanks,  John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com      -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Gregor Karlinger  Sent: Saturday, June 03, 2000 4:27 AM  Subject: Alternative XML C14N: Document Subsets      Hi John,    I think the approach you are using in section 5 of the alternative C14N  draft,  is impractical for the main use case inside XML-Signature, namely the c14n  of  the SignedInfo Element. Consider the following (simplified) example:    <MyDocument>    <PoemFragment xml:space='preserve'>      Und blicket sie lange verwundert an;      Drauf spricht er: ?Es ist euch gelungen,      Ihr habt das Herz mir bezwungen,      Und die Treue, sie ist doch kein kein leerer Wahn ?      So nehmet auch mich zum Genossen an.      Ich sei, Gew?hrt mir die Bitte,      In eurem Bunde der Dritte.    </PoemFragment>    <PoemAuthor>      Friedrich von Schiller    </PoemAuthor>    <MySignatureContainer>      <Signature>        <SignedInfo Id='SignedInfoId'>          [...]        </SignedInfo>        [...]      </Signature>    </MySignatureContainer>  </MyDocument>    Now, I'd like to c14n my SignedInfo element. Refereing to the new draft,  I have to do the following:    * Set context node to document's root node    * Additionally specify my special XPath expression, which is    "//SignedInfo[Id='SignedInfoId']"    The computation of the XPath results in:      <PoemFragment xml:space='preserve'>      Und blicket sie lange verwundert an;      Drauf spricht er: ?Es ist euch gelungen,      Ihr habt das Herz mir bezwungen,      Und die Treue, sie ist doch kein kein leerer Wahn ?      So nehmet auch mich zum Genossen an.      Ich sei, Gew?hrt mir die Bitte,      In eurem Bunde der Dritte.    </PoemFragment>    <SignedInfo Id='SignedInfoId'>      [...]    </SignedInfo>    which is definitely not the result I would like to have.    I don't see a way how to resolve the problem with xml:space and  xml:lang this way, because the preserving these attributes also  effect the output result.    I think there must be a different process to be applied for  document subsets. Part of this process is to collect the necessary  information about theses attributes AS PART OF THIS PROCESSS, but  not by specifying a XPath which collects the information.    Regards, Gregor  ---------------------------------------------------------------  Gregor Karlinger  mailto://gregor.karlinger@iaik.at  http://www.iaik.at  Phone +43 316 873 5541  Institute for Applied Information Processing and Communications  Austria  ---------------------------------------------------------------        

      Hi Lauren,    <lauren>  It is harmful to some documents and specifications, but not all  documents and applications. This doesn't mean that those applications  that do not need such a dependency are wrong, which is what the current  language implies. I don't want DOM applications that do treat the prefix  as syntactic sugar (since those authors read the Namespaces Rec and  implemented it, without regard to XPath etc) to be labelled as being  wrong. So my suggestion, again, is to come up with some language that is  neutral on this point.  </lauren>    <john>Fair enough.  I can change the language further to a kind of 'There  exist documents which are dependent...'.  However, note that since there exist XSLT and XPath transforms in DSig's  SignedInfo element, the DSig SignedInfo element is among those documents  that would be harmed by namespace rewriting.  </john>    > 2) relative to absolute URIs  >  > I will be *very* happy to see this as an erratum, but I cannot remove the  > statement from c14n until that erratum is published. I am hoping this  occurs  > before C14N goes to candidate rec.    That is probably something you should pass on to the XSL WG.    <john>Will do.</john>    Lauren        

      Sorry Peter, but that's not an accurate paraphrase.  It is quite important  to be able to exclude certain elements, but that one requires a great deal  of precision in identifying what must be excluded to ensure that you are  excluding what you meant to exclude.    Exclusion by id excludes an element based on the value of a single  attribute, and this is not enough in most cases to accurately identify the  information to be excluded, and to restrict one's exclusion to only that  information.    John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com      -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Peter Lipp  Sent: Tuesday, March 28, 2000 2:06 AM  Subject: AW: Enveloped signatures and XPath      Plonk - plonk - plonk    (....peter is trying hard to keep that discussion from popping up every once  in a while....... and fails....)    > Exclusion by id is bad because you identify an element whose content WILL  > NOT BE in the message digest, so if the identified element's content, tag,  > attributes, etc. are changed, then the message digest will not break.    Said in a generic way like you did just now, this is plain wrong.    You said - Simplified - it is bad to exclude X because it is not included.    Then - don't exclude it.    And if you need to control X - like you do in your application - put it into  your application logic and don't lay the burden on a generic signature  system.    Peter        

      Hi James,    Firstly I am curious how applications are even supposed to know that the  namespace name is a relative URI as opposed to a simple string.  For  example, in <e xmlns="string"/>, is the 'string' a simple string or does it  mean 'baseURI/string'?  According to rfc2396, a relativeURI can be a  rel_path, and a rel_path can consist solely of a rel_segment, and a  rel_segment can consist solely of one or more unreserved characters.  Perhaps there I've made a mistake, the plenary's suggestion is that, in the  future, every xmlns should be an absolute URI that includes a scheme.  Is  this correct?    Secondly, your point is well-taken on the fact that using the literal  contravenes the plenary's recommendation (in part because, if this is a  public document, it seems to have become so yesterday).    Nonetheless, I read it and I draw your attention first to section 4.1:    "As always, the final decision on what a WG does rests with the WG, not with  the Plenary: the Plenary decision is only advisory" [1]    In the case of c14n, we cannot simply fail to create an unambiguous  canonical form because this is equivalent to saying that, for the purposes  of dsig, the document is no different than if it were not well-formed.  I am  personally OK with this, but it does seem to contradict [1], answer 2, which  argues that the document is well-formed.  I also wonder how many existing  documents we will not be able to sign as a result.    Perhaps it would be better to focus on the essential message of [1], which  can be found in the answer to question 4 in [1]:    <quote>  Q4:OK, then, what's the namespace name of the root element in thatDoc?    A4:../foo, per the namespaces spec as written.    But be careful with terminology. The 'namespace name' is ../foo, but the  Namespaces Rec doesn't define a term 'Namespace URI'. According to section  4, URI References, in RFC 2396, "the URI" denoted by ../foo is  http://example.org/foo -- and terms like "namespace URI", which allude to  that mechanism, should be used with great caution  </quote>    Therefore, as long as we are careful to say that the serialization contains  the namespace name, not a namespace *URI*, then I think we will be adhering  to the plenary in the best way that is possible for c14n and dsig.    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>      -----Original Message-----  From: James Clark [mailto:jjc@jclark.com]  Sent: Monday, September 11, 2000 8:13 PM  Subject: Re: C14N: Non-absolutized URIs      John Boyer wrote:    > <john>Right, and as an application of XPath, we are choosing the behavior  > that is most appropriate to our application.  No matter how much the  plenary  > wants to force things on dsig, there is nothing they can do to change the  > behavior of a sha-1 hash.  We MUST have a single behavior, therefore we  MUST  > </john>    The decision of the plenary at:      http://www.w3.org/2000/09/xppa    concludes:      new specifications prepared by W3C Working Groups include statements    similar to the following:        This specification does not define an information set      [or whatever] for XML documents which use relative URIs      in namespace declarations."      or         The scope of this specification includes all well-formed       XML documents which use only absolute URI references in       namespace declarations. Documents which use relative       URI references are out of scope, and not addressed by       this specification.       or words to similar effect.    If you follow this, then you would simply say that you spec does not  apply to XML documents including relative namespace declarations, just  as it does not apply to ill-formed XML documents, nor to documents not  conforming to the Namespaces Rec.  If you do this, you don't need to  wait for any XPath errata.    > It is essential that a single behavior be defined for C14N, and the fact  > that XPath permits application-dependent behavior means that applications  > (such as C14N) are permitted to define the most appropriate behavior.    Having C14N define the behaviour of namespace URIs is not inconsistent  with XPath (per the proposed errata), but is most definitely  inconsistent with the XML Plenary decision.    James        

      Actually, the limitations of the XPath model should not necessarily be a  limitation of c14n, especially in such a simple case.    For starters, the current goal is to have a consistent way of writing XML  1.0, so for this version we could simply render the root node as <?xml  version="1.0"?>#xA rather than producing nothing as the result of the root  node. This seems like a good idea since we really don't know what's coming  in future versions of XML, so deciding how to canonicalize it now may not be  appropriate.  For example, it could happen that neither infoset nor xpath  have a data model that adequately captures the next version of XML.    However, even if you want to preserve the XML version, the fact that c14n  applies an xml processor to the input to produce a node-set does not change  the fact that c14n *has* the input and can therefore recover the version,  although an application function hook may be required to help with character  encoding issues for non-UTF.  Also, the absense of a version should be  construed as 1.0.    This seeming need for a character encoding function hook actually leads one  to a solution that might be more appropriate for something like DSig.  We  need c14n to do things like canonicalize SignedInfo.  If the SignedInfo is  coming from an XML document with version > 1.0, we would like to know that,  but the canonicalizer will only receive the SignedInfo text.  Somehow, the  version info either needs to be prepended to the SignedInfo, or the  surrounding document's version must simply be known by  "implementation-specific" means and provided to the canonicalizer as an  additional parameter (we already provide the input and an optional XPath  expression as parameters, so one more won't hurt).    So, if c14n received a version string of "anything", it could render the  following text for the root node of the node-set (if it is in the output  node-set):    <xml version="anything"?>    Finally, as you can see, there are lots of options for solving this problem,  and using XPath as a basis is not really causing a problem.  In fact the  only problem I do have is that the c14n issues list has not been provided to  me, so the current version has not accounted for things like this because I  didn't know about them.  With respect to the issue above, what do people  think is the best choice:    A) ignore version  B) use a version of 1.0  C) recover version from input document (kind of hard)  D) parameterize version, with default of 1.0    Obviously I like the last one best, and thanks David for bringing this up  again.    John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com      -----Original Message-----  From: John Cowan [mailto:cowan@locke.ccil.org]  Sent: Tuesday, June 06, 2000 2:48 PM  3rd; John Boyer  Subject: Re: Comment about C14N last draft      On Tue, 6 Jun 2000, David Blondeau wrote:    > The new draft specify that there is no XML declaration like the last c14n  > draft of the Core WG (01/19).    Naturally, since the new draft uses the XPath model, which has no  place for the XML version.    > Should a canonical XML document considered as an XML document and have an  > XML declaration?  Maybe, M Cowan could explain the position of the  XML Core WG when they decided this?    We basically felt it was a good idea with little cost.  No explicit  rationale for including the XML version number in Canonical XML was  ever given, except in the public announcement:    By encoding the XML version number in Canonical XML,  we ensure that no confusion can result between documents  that differ only in XML version number, and therefore  potentially in significance.    We wanted to make sure that two documents in different versions of  XML could not be canonicalized to the same byte-for-byte representation,  as their original forms might have had different interpretations.    --  John Cowan                                   cowan@ccil.org  "You need a change: try Canada"  "You need a change: try China"  --fortune cookies opened by a couple that I know        

      Hi Gregor,    -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Gregor Karlinger  Sent: Monday, March 27, 2000 3:14 AM  Subject: Comments on new XPath Filtering proposal      John,    please find my comments on your latest proposal for the XPath Filtering  section attached to the corresponding sections below. As I am not an  XPath expert, please be patient with some of my questions ;-)    <john>No sweat</john>    > -----Original Message-----  > From: w3c-ietf-xmldsig-request@w3.org  > [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of John Boyer  > Sent: Friday, March 24, 2000 1:15 AM  > To: IETF/W3C XML-DSig WG (E-mail)  > Cc: Martin J. Duerst; James Clark; Joseph Reagle; Eastlake  > Donald-LDE008; TAMURA Kent; Christopher R. Maden; Jonathan Marsh; Ed  > Simon  > Subject: RE: Enveloped signatures and XPath  > Executive overview  > ==================    [...]    > <p>Based on the expression evaluation requirements of the XPath function  > library,  > the <b>document order</b> position of each node must be available in the  > parse tree,    How can I achive this with a standard DOM parser?    <john>  The issue does not seem to be how you do this with a standard DOM parser.  The issue seems to be can you do it with the parser that is attached to any  working XPath engine.  The parser must construct a node-set capable of being  passed as part of the XPath evaluation context.  The XPath engine seems to  require certain things (like the maintenance of document order for the  position() function and the maintenance of namespace prefixes for lookup in  the initial namespace context).  Since XPath evaluation requires these things, any parser attached to an  XPath engine will support them.  </john>    [...]    > <h4>6.6.3.3 XPath Transform Functions</h4>  >  > <p>The function library of the XPath transform includes all functions  > defined  > by the XPath specification plus the serialize() function defined  > below.  For most XPath transforms, serialize() need not be called  > explicitly  > since it is called automatically if the expression result is a node-set.    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    Who makes this call? The XPath engine? How would the XPath engine    behave if the serialize function was not defined?    <john>  The XPath transform itself makes the call.  The pseudocode is something like  this:    char *XPathTransform(char *theInput, node* ExprNode)  {  nodeSet *theRoot = XPathEngine.Parse(theInput);  context *theContext = XPathEngine.MakeContext(ExprNode->namespace,  theRoot);    void *result;  int resultType;  String serializedResult;  char *theOutput;    result = XPathEngine.eval(theContext, ExprNode->text, &resultType);    switch (resultType)  {  case boolean:  case number : serializedResult = XPathEngine.f("string", result); break;  case nodeset: serializedResult = XPathEngine.f("serialize", result);  break;  }    theOutput = UTF8encode(serializedResult);  return theOutput;  }  </john>    [...]    > <h4 name="sec-XPathTransformOutput">6.6.3.4 XPath Transform Output</h4>  >  > <p>The result of the XPath expression is a string, boolean, number, or  > node-set.  > If the result of the XPath expression is a string, then the  > string converted  > to  > UTF-8 is the output of the XPath transform. If the result is a boolean or  > number,  > then the XPath transform output is computed by calling the XPath string()  > function  > on the boolean or number then converting to UTF-8.  > If the result of the XPath expression is a node-set, then the XPath  > transform  > result is computed by applying the serialize() function to the node-set,  > then  > converting the resulting string to UTF-8.</p>    Again, is this call to the serialize() function made automatically by the  XPath engine?    I deduce the following tasks for the output transformation  from the assertions made so far, depending on the XPath expression's result:    * If result is a string, convert it to UTF-8    * If result is boolean/number, explicitely call the XPath string() function    and then convert its result to UTF-8    * If result is a node set, the actual result of the XPath processing is    already a string, which must be finally converted to UTF-8    Am I right?    <john>  Almost.  As I pointed out above, if the XPath result is a node-set, then the  result is a node-set, not a string.  The XPath transform will convert it to  a string.  </john>    [...]    >The node test  > returns true for all  > nodes except the <code>SignatureValue</code> and  > <code>KeyInfo</code> child  > elements and the  > and the <code>DigestValue</code> descendants of <code>Signature</code> S1.    Why omitting KeyInfo? I think this is a little bit confusing here since  KeyInfo can be made available before computing the Reference's digest.    <john>  True that the KeyInfo 'can be' assigned before computing DigestValue.  However, I cannot recall anywhere in the spec  that says that  implementations must assign KeyInfo before computing DigestValue.  Perhaps I  missed it (please point it out as I would be happier if it were there), and  if it isn't there, then perhaps it should be.  Once it is, then you are  right that KeyInfo need not be omitted.    I omitted KeyInfo because of the possibility that DigestValue could be  computed beforehand.  By leaving it out, my example works regardless of how  the spec is written.  Note that it does no harm to leave out the KeyInfo  since it will be signed by the SignatureValue.    John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com    </john>    Regards, Gregor  ---------------------------------------------------------------  Gregor Karlinger  mailto://gregor.karlinger@iaik.at  http://www.iaik.at  Phone +43 316 873 5541  Institute for Applied Information Processing and Communications  Austria  ---------------------------------------------------------------        

      Hi Martin,    With respect to the I18N WG feedback on the XPath transform, the  recommendations stated in this letter have been made in the new version I  posted last week.  Could you please have a look and ensure that the changes  are satisfactory.    Thanks,  John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com      -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Martin J. Duerst  Sent: Friday, March 24, 2000 7:27 PM  Subject: I18N WG/IG last call comments      Dear XML Signature WG,    The W3C I18N WG and IG have reviewed your last call draft.  Below please find our comments. We look forward to collaborating  with you to resolve them.    With other last calls, we have made the experience that  cross-posting to both groups is most efficient. Unfortunately,  the different setup and anti-spam measures for both lists  do not allow this at the moment. To try to make communication  work nevertheless, the writer of this mail has subscribed to  the xmlsig list. Also, it will be crucial that a detailed  disposition of comments, and new versions of the spec or of  parts of it, are available from the XMLSig WG at an early  stage, and the I18N IG gets informed of them quickly, e.g.  through the XMLSig W3C team contact, to make sure there is  a chance for additional comments.      URIs  ----    For URIs and URI references, add a convention as in  http://www.w3.org/TR/charmod/#URIs. (all W3C specs  that use URIs in XML are doing this)      Negotiated content  ------------------    Signed objects are indicated using URIs. It is unclear  which object is to be signed in case the URI is content-  negotiated (e.g. language-negotiated). Either there must  be some mechanisms to provide negotiation parameters (difficult  to do in general), or some warnings at least that negotiated  resources should not be signed (which may be an undue  restriction). In any case, this has to be discussed in  the specification.  [It is often the case that each variant has its own specific URI  (e.g. http://www.w3.org/2000/02/ATAG-PressRelease.html vs.  http://www.w3.org/2000/02/ATAG-PressRelease.html.fr,  http://www.w3.org/2000/02/ATAG-PressRelease.html.en, and  http://www.w3.org/2000/02/ATAG-PressRelease.html.ja).  But this cannot be guaranteed.]        MimeType and Charset on Transform  ---------------------------------    The Transform element has optional MimeType and Charset  parameters. This raises several questions and problems:    - When obtaining a resource (via <Reference>), the resource     is supposed to come with its own Type/Charset information.     If this is not the case, then all kinds of operations     just cannot be performed. This information is certainly     available in http, and the 'charset' (encoding) information     is available for XML even on protocols that do not provide     meta-information. This raises the question of priority.    - The charset information provided as explained above may in     some cases be absent (e.g. in many cases for HTML over http),     and in some cases may be wrong. This MUST NOT provide a     reason for XMLSig to make the attributes on <Transform>     have higher priority than the information provided in the     protocol or in the resource itself. Otherwise, this would     deteriorate efforts to make absolutely sure this information     is present and available.    - Content negotiation is an additional reason for     why the 'charset' information should be taken from the     resource/protocol itself, rather than from the    - In any case, the priority of the various information sources     has to be clearly specified. It may also be possible to say     that an error occurs if the informations don't match.    - Type and charset seem to be on Transform because it is     unclear how this information would get from one transform     to the other. Because this information has to get from     the original resource to the first Transform, a processing     model that doesn't allow passing such information from one     Transform to another even if needed seems inappropriate.     [the spec currently doesn't say what the processing model      for the sequence of transforms is; making this clear would      help us a lot to check whether it is appropriate for i18n      or not [describing a processing model in the spec does not      mean that all implementations have to follow it; it's okay      if they do something else provided they produce the same      results]]     This should be changed so that these parameters are eliminated     on <Transform>, and the necessary information is passed from     transform to transform automatically. The parameters may     then be moved to <Reference>.    - Some transforms may need other parameters, while many     transforms won't need Type or charset. At the moment, for     example, there seems to be no proposed transform that     would need MimeType. Also, the result of most transforms     is of a very well defined type and in many cases also of     a defined 'charset', and having to add this information     on the next transform is error-prone. If the parameters     are kept on Transform, it should be stated clearly that     each transform definition has to define whether they are     actually used, and (in particular for MimeType) for what.    - We also discussed the question of whether it would be better     to have both Type and charset in a single attribute, but     we didn't reach a conclusion.      Character encoding and transcoding  ----------------------------------    [Transcoding is the conversion from one character encoding  (charset) to another.]    - 'minimal' canonicalization is required, but it should be made     very clear that this does not imply that conversion from all     'charset's to UTF-8 is required. A set of 'charset's for which     support is required should be defined exactly, e.g. as UTF-8     and UTF-16. This is the same for other transforms.    - There should be a clear and strong warning and an official     non-guarantee in the spec about conversions from legacy     'charset's (i.e. encodings not based on the UCS) into encodings     based on the UCS (i.e. UTF-8, UTF-16,...). The problem is     that while for most 'charset's, all transcoder implementations     produce the same result for almost all characters in these     'charset's, the number of 'charset's where all transcoding     implementations behave exactly the same is rather limited.     As an example, in "Shift_JIS", the 'charset' used on Japanese PCs,     about 10 to 15 special characters are transcoded differently     on Windows, on the Mac, and by Java.    - Part of the above warning should be to recommend UTF-8 and UTF-16     to be used for the original documents, and to recommend to use     numeric character references (e.g. ꯍ) for cases where     differences are known.    - We discussed the idea of having a transform that just does     transcoding. This would allow to separate various issues clearly.      Choice of Element names  -----------------------    There is a 'Transforms' element and a 'Transform' element.  This is difficult to distinguing even for English speakers.  For people used to languages without singular/plural distinctions,  it will create even more confusion. We ask you to change 'Transforms'  to something like 'TransformList'.      Individual Transforms  ---------------------    - Both Base64 and Quoted-Printable are provided as encoding transforms     (http://www.w3.org/TR/xmldsig-core/#sec-TransformAlg). For     Quoted-Printable, the only reason given is "Quoted-printable is     provided, in addition to base-64, in keeping with the XML support     of a roughly human readable final format.". We have serious     doubts that this is really useful in the context at hand;     if several transform steps are used, it should be enough     that the data before applying base64 is readable, and in     all the examples given, base64 is only applied to calculated     numbers/hex sequences, which are not very readable either way.     So we request to remove Quoted-Printable.    - XPath transform [Please note: there has already been discussion     on the list about this with the XSL WG. The comments below are     included to make sure they can be formally answered.]       The XMLSig draft contains some provisions to deal with the fact     that input and output infrastructure (e.g. the equivalent of     http://www.w3.org/TR/xslt#output) is missing in XPath.     In particular, the evaluation context includes two variables:     $exprEncoding: a string containing the character encoding                    of the XPath expression     $exprBOM: a string containing the byte order mark for the               XPath expression; set to the empty string if the document               containing the XPath expression has no byte order mark.     and makes these available to the XPath expression. The spec also says:     "The XPath implementation is expected to convert all strings      appearing in the XPath expression to the same encoding used by      the input string prior to making any comparisons."       This should be changed so that:     - The spec clearly says that all XPath operations have to       work as if they were implemented in UCS (to conform to       http://www.w3.org/TR/xpath#strings). Conversion from       the input encoding of the XPath expression and from the       input encoding of the actual object are assumed to occur       implicitly. This would also resolve the question of what       lexicographic ordering to use in the output.     - The encoding of the output be clearly specified as one of the  following:       - always, or by default, UTF-8       - always, or by default, the encoding of the input object       - specifiable as a parameter to the 'serialize()' function.       (We would prefer always UTF-8; this reduces implementation        effort)     - The above variables be scrapped. While the information is       relevant to the XPath engine, it is in no way relevant to       the XPath expression.      Canonicalization and Text Normalization  ---------------------------------------    This is a subject that we had quite some discussion about,  and gained new insights, but we are still not sure whether  we understand its implications, and the appropriate solutions,  in the context of digital signatures.    To make it easier for your side to understand our side, here  some background:    - Unicode/ISO 10646 encode a huge number of characters, some     of them purely for backwards compatibility (e.g. ANGSTROM     SIGN, U+212B, which is exactly the same as LATIN CAPITAL     LETTER A WITH RING ABOVE, U+212B)  - For many accented characters, there are two (or in some cases     more) ways to represent them (e.g. LATIN SMALL LETTER A WITH GRAVE,     U+00E0, can also be represented by the sequence of LATIN SMALL LETTER     A, U+0061, followed by COMBINING GRAVE ACCENT, U+0300)  - Depending on the application, one or the other representation     could be used, but this leads to problems for the user (because     both have to look the same) and the infrastructure (because e.g.     XML parsers, HTTP servers, DNS,... would get much too complicated     if they would all have to implement these conversions). This     was recognized as a problem, and the requirements for a solution     are described in http://www.w3.org/TR/WD-charreq, sections     2 and 3.  - The solution taken consists of specifying a normalization form     as close as possible to general current practice, called     Normalization Form C (NFC). See  http://www.unicode.org/unicode/reports/tr15/.     The second part of the solution is to require normalization     to happen early (ideally at the keyboard driver), so that     in practice unnormalized data should be very rare on the Web     and the Internet. See     http://www.w3.org/TR/1999/WD-charmod/#Normalization and     http://www.ietf.org/internet-drafts/draft-duerst-i18n-norm-03.txt.  - The benefits of the solution are that most applications do not     have to deal with this level of normalization. If their input     is normalized, things will work, if not, it is clear which side     is to be blamed.  - Signatures have to be more careful in a lot of ways, so the     above benefits may not apply to signatures; this has to be     carefully studied.  - For those not familiar with accented characters, it may be     possible to construct something similar from case equivalence.     Assume that:     - Users have no way to distinguish case.     - Internally, there are two cases (upper/lower).     - It's not that easy to do the conversion, in any way not that       easy to be worth bothering every piece of software on the       Internet with it.     - This is strengthened by the fact that the frequency of appearance       of letters (compared to numbers, which don't have this problem)       is quite low, and that most data around up to today uses lower       case anyway.     But please be careful that you understand this analogy fully,     and don't take the wrong conclusions.      The above background in a first round led us to the conclusion  that resources should be processed by NFC before being signed,  because this would make sure that accidental irrelevant (invisible  to the user) changes to a document wouldn't lead to a failure  of the signature. This, among else, led us to request that NFC  be defined as part of XML Canonicalization.    However, thanks to one of the members of our WG, Masahiro Sekiguchi,  we have discovered the following security problems:    - If NFC is applied before digesting, this gives a higher chance     that an attacker may find a document with the same digest by     chance, simply because a larger number of documents is ultimately     mapped to the same digest. While this potential should be mentioned     in the security section of your document, the low frequency     of accented and other relevant characters and the irregularity     of the transforms seem to make this a rather minor problem.    - Assume that a document contains XML with element names with     accented characters. Assume that this document is correctly     normalized. Assume that the signature includes NFC as a transform.     Now the following attack is possible: An intruder replaces the     normalized document by a document with some of the element     names unnormalized. The signature still works. However, an     XML/DOM processor or an XPath expression may (and in practice     will) work differently, because the unnormalized element is     assumed to be different from the normalized one.     As an example, using the above 'case' analogy, take a document     <root>      <amount>$10</amount>      <amount>$1000</amount>     <root>     which is modified by an intruder to look like     <root>      <Amount>$10</Amount>      <amount>$1000</amount>     <root>     and combine this with a DOM program that extracts the first     <amount> and pays somebody that much. After the change by     the intruder, the amount actually paid is $1000 instead of $10.      The above considerations have led us to the conclusions below.  We hope that you can help us with your experience on security  issues to check them.    - Make sure that the transforms defined do not *require* NFC.     (any XML processor, and any transforms based on it, are      always *allowed* to to do normalization, see the definition      of 'match' in the XML spec).    - Provide a transform that *checks* for NFC. The transform     fails if the input is not in NFC. If the transform succeds,     the output is exactly the same as the input. [this is a bit     different from the average transform, but fits very well     into the general model].    - Advise users (and provide examples) to use this transform     after e.g. Canonical XML, to avoid missing interactions     between numeric character references and NFC.    - Advise users to provide their data in NFC (just to reinforce     the general recommendation), and stress the importance     of this in the context of digital signatures.    - Provide a transform that actually does NFC, for cases     where this is desirable, but add the necessary warnings.        Various comments  ----------------    - In 7.1, second numbered list, item 2, characters not representable     in the encoding chosen should be mentioned.    - Section 4.3.3 The Reference Element, para 3           "pound symbol"       This term only has meaning if xml:lang="en-us", i.e.     it is not understood in places using British English     or derivations thereof.    - Section 6.6.3.3 Function Library Additions, para 2           "CDATA sections are replaced by their content"       This requires the processing to behave as if it uses the UCS.    - Section 6.6.3.3 Function Library Additions, definition of serialize     function           "an open angle bracket ... and a close angle bracket ...         an open double quote ... a close double quote"       In XML syntax, there is no such thing as an open (or close) double     quote. It's always the same double quote that is used.    - Section 6.6.3.3 Function Library Additions, definition of serialize     function           "replacing ... all illegal characters for the output character         encoding with hexadecimal character references (e.g. )"       What is the rule for leading zeros?    - Section 7.0 XML Canonicalization and Syntax Constraint     Considerations, para 5           "should yield output in a specific fixed character set."           "that character set is UTF-8."       The spec uses the term "character set" very loosely. Please     use the term 'character encoding' when speaking about the concept     identified by a 'charset' parameter value. 'character set' is     ambiguous (see http://www.w3.org/MarkUp/html-spec/charset-harmful).    - References       A reference to UTF-8 should be added (e.g. RFC 2279).     The spec should specifically warn about broken "UTF-8".      - General       The treatment of xml:lang, eg during transforms, is unclear.      ==================      Non-i18n comments that were raised by WG/IG members  ---------------------------------------------------    - The term 'Minimal' Canonicalization, and the fact that     it is required, is confusing. It suggests that this transform     has to be applied for every signature, which is not the case.     The really minimal transform that has to be applied is the     null transform.      - Throughout the spec,           "byte stream" (four occurrences),         "octet stream" (three occurrences),         "byte sequence" (one occurrence).       Decide on one of these?      - Section 2.0 Signature Overview and Examples, para 3           "XML Signatures are be applied ...".    - Section 3.2 Core Validation, para 2           "... side affects ..."    - Section 7.0 XML Canonicalization and Syntax Constraint      Considerations, para 5           "... all XML standards compliant processors ..."    - Section 8.2 Only What is "Seen" Should be Signed, para 2           "Those application ..."    - Section 8.2 Only What is "Seen" Should be Signed, para 2           "... name space ..."        All other instances use "namespace".    =================    For the I18N WG/IG,    Regards,   Martin.        

      Hi Jonathan,    OK, that makes some sense.  What you're saying is that we should have c14n  extend the Xpath data model by adding an xml:base to the top level element  of external entities.    This must be done by modifying the XML processor that generates the  node-set.  I wonder how easy this is for implementers.    I agree with you that trying to read between the lines on XML 1.0 is a waste  of time, but I disagree with the implication that this is what I'm doing.  There are quite specific lines that tell an XML processor developer that  they need not distinguish between content derived within the document versus  content derived externally.    So, TAMURA Kent, Kevin Regan and others: could you please let us know if you  can do this?  If so, then I'd like to do what you suggest Jonathan, then  place a note about the residual problem with base URI for top-level PIs.    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        

      My vote is for #2.    i) The algorithms being used by dsig are being specified by an absolute URI.  It cannot be the case that some later decision changes the behavior of  algorithms used by dsig because then signatures that once validated will  stop validating on implementations that conform to a decision, once one is  made, about what to do about URI.    ii) For this reason, I am suggesting that we say only that absolute URIs are  required, and support for relative URIs is RECOMMENDED, but that those who  support them MUST do so by providing the original string.  If the W3C later  decides to support relative URIs (and most other strings) in some way, then  that must correspond to an issuance of C14N v1.0.1 under a different URI  since, as I said before we cannot have C14N v1.0 change behavior without  breaking signatures created between now and when the W3C makes this  decision.    iii) The question is not whether people have a problem with relative URIs in  namespaces.  The question is whether it is inconvenient that documents  containing most of the reasonable namespace names that people would use,  other than actual absolute URIs, cannot be signed.  You made it clear in the  choice for 1 but not in the arguments for 2.    iv) This is not simply a question of whether c14n does this.  A consequence  of permitting c14n to retain the original string is that dsig must do the  same thing.  This is due to the existence of same document references,  including enveloped signatures.    I think that this poll should be reissued with these points made clear.  In  particular, the Poll should state that this decision must be made before  request for CR status of C14N and DSig-- the choice that people make should  be constrained so that it applies to both specs.    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>          -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Joseph M. Reagle  Jr.  Sent: Friday, September 15, 2000 2:12 PM  Duerst; Jonathan Marsh  Subject: Poll: Relative URIs and Strings in xmlns attributes      Before we request Candidate Rec status for Canonical XML there's one issue  that I've been trying to understand and come to closure on, and that's the  implications of the recent XML Plenary decision on Canonical XML: "to  deprecate the use of relative URI references in namespace declarations." [1]  What does that mean for the Canonical Form? We've had some discussion on  this over this week in this WG [2], some discussion in the XML Coordination  Group, and I also briefly discussed this with TimBL. I think the two options  we now face are below. Please post your preference -- and optionally  reason/rationale -- by end of day Wednesday September 30th. (Those cc:'d are  invited to make their choice known in an advisory capacity than can convince  others of their position, but in the end I'd like to say, "the XML Signature  WG feels $this-way about the issue, while others (agree|disagree)."    CHOICES    1. To state that the canonical form of a document containing a relative URI  in a namespace is undefined, and consequently such a document can not be  signed. (This includes namespaces like "../foo" as well as "bar"; only  documents with namespace declaration using absolute URIs are in scope --  just as only well formed documents are in scope.)  2. To state that the canonical form is URI unaware. In section 3.1 [4], we  already disclaim responsibility for resolving/normalizing other URIs, data  types, application semantics, etc. (The reason we made this distinction in  the first place is because XPath did. However, an errata of XPath might be  issued that would make the resulting the string-value  implementation-dependent, but we can't say till we see the errata.)  Consequently, not only is the issue of the "relative-URI-in-namespace" out  of scope, so is the plenary decision.    ARGUMENTS FOR CHOICE (1)    A. The XML Plenary decision recommends W3C specs say, "This specification  does not define an information set [or whatever] for XML documents which use  relative URIs in namespace declarations." [1]  B. In [3] DanC stated that, "if you specify how they work today, we won't be  able to make a different specification later." I'm very glad the XML Plenary  has come to a decision on this and I want to respect the spirit and intended  effect of that decision.  C. (1) seems to be the common interpretation of the plenary decision to  Canonical XML by the folks who were active in the Plenary discussion.    ARGUMENTS FOR CHOICE (2)    A. The XML Plenary decision, "Proposed: to deprecate the use of relative URI  references in namespace declarations; that is: to say that while they  conform to the Namespace Recommendation of January 1999, later  specifications such as DOM, XPath, etc. will define no interpretation for  them." However, I'm told that "no interpretation"  is not an argument in  favor "literal interpretation" which was specifically opted against.  B. However, it might permit us to make an argument that we are all-together  URI unaware.  (The only reason we know these might be URIs and not strings  is because of the XPath namespace-node and because of the syntactic sugar of  'xmlns:'.) Later, if consensus is reached on namespaces/URIs, someone can  easily write a URI-canonicalization specification and apply it prior to  Canonical XML.  C. Canonical XML is not in the set of specifications (DOM, XPath, etc.)  covered by the Plenary decision, but an application of them which is allowed  to do as it pleases. Canonical XML is an application of XPath that uses  namespace nodes as we choose as a contribution to a generated hash-value.  What we do today won't hinder others in the future.  D. There are documents out there that use relative URIs and need to be  signed. (Is this the case for anyone in the WG?)              [1] http://www.w3.org/2000/09/xppa.html  >4.2 Proposal  >  >Proposed: to deprecate the use of relative URI references  >in namespace declarations; that is: to say that while they  >conform to the Namespace Recommendation of January  >1999, later specifications such as DOM, XPath, etc. will  >define no interpretation for them. "  [2]  http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/2000JulSep/0467.html  [3] Forwarded Text ----  >Date: Thu, 14 Sep 2000 15:35:09 -0500  >From: Dan Connolly <connolly@w3.org>  >  > > 2. Our question is related to the question asked of by Clark [2], since  > the  > > XPath errata attempts to [3] implement the plenary decision [4]. Under  > XPath  > > errata [3] "XPath expressions can still be well-defined on a document  > > containing relative namespace URIs..." [2]  We also felt that there can  > be a  > > Canonical form of such documents. And our interpretation of [3] led us  to  > > believe it is up to xmldsig to decide how to represent it. We recently  > > decided to treat relative URIs in these instances as a non-absolutized  > > string in the Canonical form. However, this caused others to feel this  > > violated the plenary decision  >  >Hmm... yes... I might have told you differently in our  >earlier conversation, but I think that *any* specification  >of how a relative URI reference in an xml namespace  >declaration is to be interpreted is in conflict  >with the plenary decision; if you specify how they  >work today, we won't be able to make a different  >specification later. (Meanwhile, we're allowing  >implementations to do what they like, so the only  >chance we really have of specifying how they work  >later is if the market agrees on some way of  >interpreting them, and we adopt that way.)  [4] http://www.w3.org/TR/2000/WD-xml-c14n-20000907#Limitations  For example, in a digital signature application, a document is often  retrieved and processed prior to signature generation. The processing SHOULD  include the conversion of relative URIs to absolute URIs, thereby mitigating  any security risk.      __  Joseph Reagle Jr.  W3C Policy Analyst                mailto:reagle@w3.org  IETF/W3C XML-Signature Co-Chair   http://www.w3.org/People/Reagle/        

      Hi Joseph,    The conversation thread for this goes all the way back to [1,2,3].    [1]  http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/1999OctDec/0219.html  [2]  http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/1999OctDec/0222.html  [3]  http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/1999OctDec/0224.html  [4]  http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/1999OctDec/0228.html    As you may recall, I was a proponent of open content, but you and Don  preferred to wrap everything in parameter tags of some kind.  The decision  to go this route was finalized in DC (see [5] for minutes) as follows:    "Eastlake: There are various types of algorithms ... there is consensus that  parameters should be labeled for algorithms ... "    [5] http://www.w3.org/Signature/Minutes/DC-Minutes/Overview.html    The following arguments were subsequently made by Don at the DC face to  face.    a) Wrapping each parameter in an element allows us to say things about the  content that we may not be allowed to say about the content according to the  content model.  This is certainly true of XPath, where the extra element  gives us a convenient place to put the namespace declarations that the  expression may need (can't be done at the Transform level because transform  has an ATTLIST, so every possible namespace declaration would have to be  declared in the ATTLIST, which is unusable).    b) We achieve consistency in how parameters are expressed, regardless of how  many parameters there may be.  It doesn't make sense to say that  multi-parameter transform would have element wrappers around each parameter  whereas a single parameter transform should have open content.    I basically conceded the wisdom of these points, and life went on.  So,  requiring the XSLT element wrapper now is not a flip-flop.  It's how the WG  decided to do it last year.    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Joseph M. Reagle  Jr.  Sent: Thursday, September 07, 2000 5:41 PM  Subject: RE: Merged Copy      At 17:13 9/7/2000 -0700, John Boyer wrote:  Ok, I'll let other people way on the more substantive issues, but at the  surface level only:    >The content model for Transform is XPath, XSLT, or any sequence of  elements.  >The last part is only there to accommodate Transforms not defined by us.  I  >have no problem saying that the content model for Transform is (XPath |  >XSLT) because I don't really see why people would do non-standard  >transforms.    My point was I thought we didn't need the XSLT in our namespace at all, why  the extra wrapping? It's an open content model. Ed had a request that we  specify that if XSLT, the root should be <stylesheet>, but I don't recall if  that we wanted to re-wrap again. (If Ed can correct me that'd be cool, I  just want to make sure we aren't accidently flip-flopping.)    ><john>  >The processing model is that the input can be octets or a node-set.  >However, the transform only accepts octets, so if it gets a node-set, it  has  >to convert the node-set to octets.    My editorial question relates to what is the "it". If it (a transform) only  accepts octects, then if it received a node-set I'd expect the procedure  call to have an argument type failure.    >Signature applications already know, in principle at least, how to convert  >node-sets to octet streams because C14N is required.    Ok, so the clarity I'm seeking is to say, X transform accepts only octects,  if the Signature application has a node-set it will first have to  (implicitly?) canonicalize prior to handing it to that transform.    >3. I'm not sure if the 6th and 7th motivating paragraphs in the XPath  >section aren't needed. "The primary purpose ..." I'd propose to strike  them.  >  ><john>  >Many have felt and I still feel it is necessary for people to know why this  >transform exists.  It is important that we not try to shorten the spec so  >much that noone understands why we are doing what we are doing.  This is a  >major problem in other specs.  ></john>    Ok, curious for others' thoughts.      >4. XPath section, has (old) text that says, "The function definition for  >here() is consistent with its definition in XPointer. It is defined as  >follows:" However, this isn't the case, right?  >  ><john>  >It may not be the case at the moment, but I fully expect it will be the  case  >again soon.  Once the Xptr folks actually do discuss this, I'm sure they  >will find there is no reasonable alternative.  If they do go in a direction  >other than ours, we can change the text at that time to say "Note that it  is  >NOT the same as the XPointer here()".  ></john>    Well, If we don't here from Eve soon and we publish a new version, I'd  prefer the spec reflect reality and state in the STATUS that we hope things  will change.    _________________________________________________________  Joseph Reagle Jr.  W3C Policy Analyst                mailto:reagle@w3.org  IETF/W3C XML-Signature Co-Chair   http://www.w3.org/People/Reagle/        

      Hi Tom,    The proposal is only to exclude Signature elements that are ancestor to the  DigestValue element whose content is being calculated.  This does not impact  one's ability to sign someone else's signature.    However, I'm sure this has been asked and answered negatively in the past.    John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com      -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of tgindin@us.ibm.com  Sent: Wednesday, March 29, 2000 10:57 AM  Subject: RE: Enveloped signatures and XPath           Is the proposal here that all elements within a <Signature> should be  excluded unless they are the objects of a Reference?  If so, how would a  subsequent signer include the KeyInfo or SignatureValue from an enveloped  signature unless the original signer had attached an ID to them?              Tom Gindin        

      Hi Eric,    I'd be interested in a more specific version of your comments.  Although,  c14n is doing what is intended, there is some good food for thought (below)  if I've interpreted you correctly.  Also, please refer to the version of the  document you are reading.  My comments refer to [1].    [1] http://www.w3.org/TR/2000/WD-xml-c14n-20000907    Firstly, C14N is actually best-suited to standalone documents.  However, I  think you are using the term 'standalone document' to mean something  different than its definition in the XML 1.0 specification.  I believe you  mean that you want to canonicalize the file containing the root element, but  not include information that the document obtains from external sources.  See below for some advice on this.    In general, it is a good thing that the canonical form should change the  information value of the document changes by simply moving it to a different  box.  It is, at that point, a different XML document, and it is the stated  purpose of C14N to report a difference.  However, the term 'document' as it  appears in XML 1.0 is seemingly different from how you are using it.  By  document, you seem to mean 'file containing root element'.  Again, see below  for some advice on this.    As for the loss of DTD (as well as the loss of entity references), we're  aware that we're tossing out this information.  We're doing this so that  C14N can be implemented with baseline XML 1.0 processors.  For the most  part, the loss of information does not hurt the canonical form, but there  are a few limitations, which are given in [1] (as well as advice on how to  avoid or overcome these limitations).    However, I cannot tell for sure, but it sounds like you may be trying to use  canonical forms in the creation of a XML document development environment,  not an XML processing application.  I can imagine that your processing needs  would be far greater than those of an XML 1.0 processing application.  However, it also stands to reason that you would have much more  sophisticated tools at your disposal than we are assuming.    As such, may I recommend a simple round of pre-processing and  post-processing.  Firstly, the loss of entity references seems to be causing  difficulty.  However, in a development environment, your tool simply *must*  be able to track any and all entity references, so turning each reference  into character data before running the canonicalizer should be a piece of  cake.  Secondly, your tool simply must have access to the doctypedecl, so  prepending it to the canonical form as a post-processing step of  canonicalization should also be simple.    The results of these two easy steps should make the canonical forms of much  more value within your application.  In general, the core specification  cannot assume the implementer has access to such advanced tools, but perhaps  an additional paragraph in the limitations section spelling out the  information above wouldn't hurt.    Please let us know if this information works for you, or please feel free to  elaborate if I've gone down a path other than the one you intended...    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>            -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Eric van der Vlist  Sent: Saturday, September 09, 2000 8:51 AM  Subject: Newbie comments about Canonical XML      Hi,    After my first serious glance at the Canonical XML spec, I have a couple  of comments (I only hope they are not FAQs...):    This canonization seems to meet a very specific need.    I came to it to see if it could be used to compare XML documents and  find their differences before a CVS checkin and my first finding was  that Canonical XML is not meant to deal with standalone documents and  looses any document type information.    To say that 2 documents are identical based on the canonical output  seems pretty limitative in these conditions !    I reckon that it's meeting a need, but find that it might deserve a  mention in the abstract.    To elaborate on this point, I think that what is described here is not  so much "a physical representation, the canonical form, of an input XML  document", but rather a physical representation of an object model taken  at a given instant under given conditions (and at a given location).    Even if you have a tight control on the document you're canonizing,  since you are integrating data from external documents, you can't  guarantee that a next processing of the same document will give the same  canonical XML as these documents (or more exactly the answer to the  request for these documents) may vary.    It's may not be a problem for security applications which will require a  signature check processed on the object model (DOM or other) they are  working on, but here again, it might be worth mentioning this point  since it has an impact on the architecture to use: IMHO you can't safely  test the equivalence of two documents based on their canonical XML and  then reload the document in another tool assuming it's still  equivalent...    My 0,02 Euros    Eric  --  ------------------------------------------------------------------------  Eric van der Vlist       Dyomedea                    http://dyomedea.com  http://xmlfr.org         http://4xt.org              http://ducotede.com  ------------------------------------------------------------------------        

      Hi Gregor,    Yes, you are right.  The input document is not well-formed unless the  version number is added.  Once added, the output is correct.  Will fix.    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Gregor Karlinger  Sent: Wednesday, September 13, 2000 7:17 AM  Subject: Canonical XML comment (example 3.6)      Hi John,    In example 3.6 (UTF-8 Encoding) you forgot to include the  required version info into the XML declaration. So the input  document should be    <?xml version="1.0" encoding="ISO-8859-1"?>  <doc>©</doc>    instead of    <?xml encoding="ISO-8859-1"?>  <doc>©</doc>    Regards, Gregor  ---------------------------------------------------------------  Gregor Karlinger  mailto://gregor.karlinger@iaik.at  http://www.iaik.at  Phone +43 316 873 5541  Institute for Applied Information Processing and Communications  Austria  ---------------------------------------------------------------        

      Hi all,    Is there some reason why the serialization algorithm described in the latest  XPath Transform spec cannot be used to    1) Serialize SignedInfo without W3C c14n.  The serializer is essentially  like minimal c14n except that it takes into account the limitations of some  XML toolkits w.r.t. attribute order, assuming an XML processor has been  used, etc.    2) Describe how to serialize fragments of XML (if you have a fragment, where  did you get it from? And if you got it from somewhere, isn't it always  possible to think about it in terms of a parse tree (or rather a parse  forest, aka a node-set)?).    John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com      -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Ed Simon  Sent: Friday, April 07, 2000 12:25 PM  Subject: RE: XML Signature use of Canonical XML      Thanks Joseph for the summary,    I would like to make a clarification regarding the paragraph:      However, during last call (which ended yesterday) there's been substantive    call for removing minimal all together based on implementation experience    [1], though the security concerns associated with XML Canonical are still    raised [2]. I expressed my view that "We've been trying to play agnostic    between XML as XML, and XML as a character sequence, but I believe the  spec    should follow the implementations, which seem to be adopting the XML  toolkit    (XML as XML) route." [3] Consequently, the advancement of Canonical XML is    very important to us even though we still have our own difficult    consensus/balancing act between XML-as-XML and something some security  folks    are comfortable with.    I do not object to minimal canonicalization for the resources being  digested,  only for the <SignedInfo> element.  In my view, and I think Kent Tamura's  view  (Kent, please let us know if I am misrepresenting you), it is very difficult  to support the minimal canonicalization of the <SignedInfo> element for the  reasons I outlined in  "http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/2000JanMar/0226.html".    In response to that note, Phill has proposed  that XML parsers contain an interface to support minimal canonicalization.  From  "http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/2000JanMar/0246.html":      Briefly, one needs to code the XML parser with separate FSR    and parse tree building modules (a good idea in any case).    The initial FSR module needs to have a switch to divert code    through a hash algorithm when required. The switch needs to be    activated by the signature verifier at the appropriate point.      It is quite easy to write an integrated parsing / signature    verification module in C on this structure without the use of    any global variables. XML was designed to be very easy to    write parse tools for.    If XML parsers were coded that way, miminal canonicalization could be  supported for the <SignedInfo> element.  However, to my knowledge such  functionality is NOT part of most parsers meaning some recoding would  be necessary by either the parser maker or an XML Signature implementor  who has access to the source code.  I would like to hear others' opinions  on this, especially those who have written XML parsers.    We also need to address the concerns expressed (eg.  "http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/2000JanMar/0281.html")    of whether "Canonical XML" will stand up to a security analysis.  To fully understand the Canonical XML spec (as short as it is), does require  that one be very familiar with the XML spec, character models, and  namespaces.  I expect these topics will generally be new areas to  the cryptographic community and we need to consider that.  Generally, I  think that XML and XML applications (not just XML Signatures) open up  a whole new set of challenges to the security community (see  "http://www.xml.com/pub/2000/02/xtech/megginson.html" for a similar  view).  To paraphrase a 60s song, what the world needs now is people  who are good at both XML and security.    Regards, Ed  -----Original Message-----  From: Joseph M. Reagle Jr. [mailto:reagle@w3.org]  Sent: Thursday, April 06, 2000 6:57 PM  Subject: XML Signature use of Canonical XML (Was: Minutes for XML Core  WG telcon of 2000 Apr 5)      The Core WG has been trying to decide what to do with the Canonical XML spec  as they have many deliverables on their plate and presently we are the only  consumer (though I believe we are only the first, there will be many other  applications with requirements similar to our own.) I hope they will produce  another draft soon, and there is sometimes talk of them handing the spec off  to us, but nothing conlusive so far. However, I did try to update them on my  view of this WG's view of that spec. Any thoughts are appreciated.    Forwarded Text ----   Date: Thu, 06 Apr 2000 18:50:56 -0400   To: w3c-xml-core-wg@w3.org   From: "Joseph M. Reagle Jr." <reagle@w3.org>   Subject: XML Signature use of Canonical XML (Was: Minutes for XML Core WG  telcon of 2000 Apr 5)     [Note: I had an agreement with the Core's predessor (Syntax) for  cross-posting any c14n relevent information to the public list. I'm not  cc'ing this, but will make this information available in some way -- I'd  like to forward it if I could have a similar understanding with the Core WG.  Also, this is only my summary of the WG's position and likely direction, but  not a formal/endorsed statement.]     >...     The XML Signature WG's approach on the c14n issue has been mixed because of  a difference between those who planned to approach the processing of XML in  the Infoset/DOM manner (that requires node serialiazation and  canonicalization), and those that wanted to process it merely as characters  (that required some line feed and CR canonicalization at most.) Our  compromise was to require "minimal" and strongly recommend XML Canonical.     However, during last call (which ended yesterday) there's been substantive  call for removing minimal all together based on implementation experience  [1], though the security concerns associated with XML Canonical are still  raised [2]. I expressed my view that "We've been trying to play agnostic  between XML as XML, and XML as a character sequence, but I believe the spec  should follow the implementations, which seem to be adopting the XML toolkit  (XML as XML) route." [3] Consequently, the advancement of Canonical XML is  very important to us even though we still have our own difficult  consensus/balancing act between XML-as-XML and something some security folks  are comfortable with.     I'm looking forward to the next draft of the spec that resolves some of the  other comments sent during last call [4] (though I know the Core WG is very  busy). Also, the Signature WG identified in our comments  [5] that we're  going to have to figure out some way canonicalize XML fragments (i.e.  serialized returns of XPath), though I'm beginning to wonder if this would  be a useful feature to include in the Canonical XML spec itself? Gregor  Karlinger has suggested that the fragments be wrapped in a declaration and a  specific element from the Signature element type in our case, though that  could be generalized. [6]     [1]  http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/2000JanMar/0214.html   [2]  http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/2000JanMar/0246.html   [3]  http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/2000JanMar/0257.html   [4]  http://lists.w3.org/Archives/Public/www-xml-canonicalization-comments/2000Ma  r  /   [5]  http://lists.w3.org/Archives/Public/www-xml-canonicalization-comments/2000Fe  b  /0004.html   [6]  http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/2000JanMar/0156.html    End Forwarded Text ----    _________________________________________________________  Joseph Reagle Jr.  W3C Policy Analyst                mailto:reagle@w3.org  IETF/W3C XML-Signature Co-Chair   http://www.w3.org/People/Reagle/        

      So what you're saying, which is what I understood from before, is that if we  sort based on the character domain, then the result should be the same  regardless of encoding.    Martin, do you agree?    Thanks,  John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  jboyer@PureEdge.com      -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Christopher R.  Maden  Sent: Tuesday, March 21, 2000 1:08 AM  Subject: Re: Xpath transform changes and questions      [Martin D?rst]  >At 00/03/17 12:47 -0800, John Boyer wrote:  >iii) If everything else checks out, we can get rid of exact order and just  >>use lex order provided that lex ordering in UTF-16 results in the same  order  >>as lex ordering in UTF-8 (which is Christopher Maden's claim).  >  >This is not true. Surrogate pairs are the counterexample.  >And of course it is not true for any other character encoding,  >except in a very limited sense for iso-8859-1 and us-ascii.    I was referring to ordering on characters, not bytes.  It should be obvious  that bytewise sorting on a two-byte and a variable-byte encoding will be  different.    -Chris    --  Christopher R. Maden, Solutions Architect  Yomu (formerly Exemplary Technologies)  One Embarcadero Center, Ste. 2405  San Francisco, CA 94111        

      Hi Martin and Ed,    Actually, Martin, I do think DSig has some responsibility to document I18N  limitations of this transform, so we could really use your help on that.    However, I was more concerned with generic stuff like the fact that when I  set my XSLT processor to output text/html, it tends to rewrite some stuff on  me like line breaks and non-minimal minimalized attributes.  I don't  'serialize the result tree' tree directly as Ed recommends.    So, I'm fishing for some kind of statement that when an XSLT processor is  set to output text/xml, that these funny rewrite rules aren't applied to my  output.    As long as that's true, then a c14n transform after the XSLT should clean up  the mess; I just want some additional assurance as we approach CR that we  aren't messing this up. (And, again, thanks for your patience, Ed).    Sincerely,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Martin J. Duerst  Sent: Thursday, August 17, 2000 7:54 PM  Subject: Re: XSLT      At 00/08/17 12:30 -0700, John Boyer wrote:  >I've often wondered, how open-ended is XSLT regarding the output.  >  >Are there permissible implementation differences that are not covered off  >by throwing a c14n transform after (or before and after)?    There are definitely things that fall in this category, in particular  in the area of localization. For example you can say that you want  some items sorted, and can indicate that the sort order should  be according to e.g. Swedish practices, but you are not guaranteed  that your processor knows Swedish sorting, nor are you sure that  all processors do exactly the same for Swedish even if they know it.    This is I guess quite a bit away from your main problem.    Regards,   Martin.      >Or rather, is there an XSLT conformance mode that guarantees any  >implementation adhering to that mode produces the exact same output  >(except possibly for differences that can be corrected by c14n, and  >possibly only if the input is canonicalized)?  >  >Or is it the case, for example, that random extra whitespace may be added  >outside of start tags by some processors and not by others?  >        

      Hi Ed,    It was certainly the intent of the XSL Transform section to indicate that a  whole stylesheet be provided.  The language used was 'whose content MUST  conform to the XSL Transforms [XSLT] language syntax'.  It does not say that  the content of the parameter must conform to *any portion of* that syntax.  Therefore, I fully support whatever measures you think are necessary for the  schema to reflect our desire that an entire stylesheet be provided.    John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>    -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Ed Simon  Sent: Wednesday, July 26, 2000 9:28 AM  Subject: RE: XSL Transform      Joseph wrote:  If we wanted to do what you are speaking of we'd use a declaration below (I  think). However, XSLT [1] didn't provide a schema anyway and consequently  there might be some other tricks we could do, but seems too complicated for  the derived benefit...    Ed responds:  If we can enforce, to a reasonable degree, that XSLT <Transform>s indeed  have  a <stylesheet> root element, then I think the derived benefits of  interoperability more than outweigh the cost of two or three more lines in  the schema.  (It would certainly be nice is XSLT did provide a schema and  I hope they do in their next Recommendation version.)      -----Original Message-----  From: Joseph M. Reagle Jr. [mailto:reagle@w3.org]  Sent: Wednesday, July 26, 2000 11:24 AM  Subject: RE: XSL Transform      At 17:29 7/25/2000 -0400, Ed Simon wrote:   >4.  There is no reason why an XSLT transform in an XML Signature should  not   >have a root element of   ><stylesheet xmlns="http://www.w3.org/1999/XSL/Transform">   >and contain complete, valid XSLT stylesheets.   >   >5.  Schemas allow us to enforce point 4.  Enforcing point 4 will make it   >that   >much easier to achieve point 3.    As an aside, the use of ANY has the implied default of  processContents='strict'. This may be approriate in specific instances (like  XSLT) however I think it's a bit too strict for everything in general. So I  propose we move towards <any ...  processContents='lax' ...> in things like  Transorms, Object, PGPData, SPKIData, etc.     >The problem with the <any> element is that even if the namespace attribute   >is "http://www.w3.org/1999/XSL/Transform", it does not   >enforce that the child element is <stylesheet> so it could be quite  possible   >to have    That is true: "Any well-formed XML from any namespace (default)"    If we wanted to do what you are speaking of we'd use a declaration below (I  think). However, XSLT [1] didn't provide a schema anyway and consequently  there might be some other tricks we could do, but seems too complicated for  the derived benefit...    <schema targetNamespace='&dsig;'     version='0.1'     xmlns='http://www.w3.org/1999/XMLSchema'     xmlns:ds='&dsig;'     elementFormDefault='qualified'     xmlns:xsl="http://www.w3.org/1999/XSL/Transform"> <!--Simon-->   <import namespace='http://www.w3.org/1999/XSL/Transform'/> <!--Reagle-->    ...    <element name='Transform'>      <complexType content='mixed'>        <choice minOccurs='1' maxOccurs='unbounded'>          <any namespace='##other' minOccurs='0' maxOccurs='unbounded'/>          <element name='Xpath' type='string'/>          <element ref="xsl:stylesheet"/>    <!--  Simon-->        </choice>        <attribute name='Algorithm' type='uriReference' use='required'/>      </complexType>    </element>  __    [1] http://www.w3.org/TR/1999/REC-xslt-19991116    _________________________________________________________  Joseph Reagle Jr.  W3C Policy Analyst                mailto:reagle@w3.org  IETF/W3C XML-Signature Co-Chair   http://www.w3.org/People/Reagle/        

      Hi Don,    I did not mean to misquote you.  However, I haven't seen any W3C documents,  nor implementations based on them, that use the term 'qualify' as you are  using it.  It is not possible to 'qualify' an attribute with anything but a  namespace URI.    In other words, in the example    <x xmlns:n1="http://www.w3.org" xmlns="http://www.w3.org" >    <good a="1"     n1:a="2" />  </x>    There does not seem to be any basis in W3C work for the interpretation    1) that 'a' is qualified as (n1:good):a,  2) that 'a' is not qualified by a URI, and  3) that 'a' is qualified by elements, including any URI which may qualify  that element    Therefore, when you said that the attributes "are qualified by their  element", I assumed you meant 'qualify' in the sense defined by XML Names  [1, see the abstract], which associates elements and attributes with a  namespace identified by URI.  With this version of 'qualify', what you said  is equal to what I said you said.    Finally, ending most of our debate about this issue, Tim Bray states, "An  attribute whose name contains no prefix is not in any namespace".  This  means that in the first example of Section 5.2 of XML Names, the href in <a>  is not in the HTML namespace.    This means if I put an HTML island in the middle of some XML by adding  xmlns="http://www.w3.org/TR/REC-html40" to the html tag, then when I want  the href of some anchor, I cannot simply say  'get("http://www.w3.org/TR/REC-html40", href)'.  I must instead say    1) get("http://www.w3.org/TR/REC-html40", href)  2) if that fails, then get("", href)    Once again... Yikes!    John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Donald E. Eastlake  3rd  Sent: Friday, August 11, 2000 11:39 AM  Subject: Re: Determining attribute uniqueness seems to require namespace  prefix in Infoset        From:  "John Boyer" <jboyer@PureEdge.com>  Date:  Fri, 11 Aug 2000 10:15:32 -0700  Message-ID:  <BFEDKCINEPLBDLODCODKOEEKCEAA.jboyer@PureEdge.com>    >Dear Editors,  >  >Please see the first example of Section 5.2 and the sentence immediately  >above it, which says "Note that default namespaces do not apply directly to  >attributes" [1].  One chairman of the XML DSig group recently commented  that  >the word 'directly' may be intended to indicate that unqualified attributes  >inherit their namespace setting from the parent element.  This seems  >sensible to me as the href attribute should be in the same namespace as the  >parent element <a>.    No, I did not say that attributes "inherit their namespace setting  from the parent element".  I said that they are qualified by their  element.  That is, in    <b:a xmlns:b="foo:bar" c="xyz">    it is "as if" c were actually b:a:c except, of course, that this  syntax is illegal.    >[1] http://www.w3.org/TR/REC-xml-names/#defaulting  >  >However, now look at the last example of Section 5.3.  The second occurence  >of <good> has attributes a and n1:a.  This is declared as legal, but if 'a'  >inherits its namespace setting from good, then a and n1:a appear to be  >equal.    But n1:a and n1:good:a would be different.    >...  >  >Could you please advise us on the correct interpretation (and fix the error  >if indeed there is one)?  >  >  >     John Boyer  >      Development Team Leader,  >      Distributed Processing and XML  >      PureEdge Solutions Inc.  >      Creating Binding E-Commerce  >      v: 250-479-8334, ext. 143  f: 250-479-3772  >      1-888-517-2675   http://www.PureEdge.com    Donald        

      Hi John,    If I have the following markup,    <xyz:e xmlns:xyz="URI"></xyz:e>    How do I ask XPath for the xyz part of e?  I seem to be able to find out  that the element has a local name of e and a namespace uri of URI, but in  order to serialize the element, I need to have the xyz.  What function or  node tells me this?    John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com      -----Original Message-----  From: Jonathan Marsh [mailto:jmarsh@microsoft.com]  Sent: Monday, March 27, 2000 3:18 PM  Donald-LDE008; TAMURA Kent; Christopher R. Maden; Ed Simon  Subject: RE: Enveloped signatures and XPath      > -----Original Message-----  > From: John Boyer [mailto:jboyer@PureEdge.com]  >  > <john>  > Right.  The exact point I'm trying to make is that  > information needed for  > serialization (specifically, the namespace prefix) is not publically  > available.    Yes it is.  It's in the original document as attributes or namespace  information items, and is exposed through the XPath data model as namespace  nodes.  Since you own the document passed to XPath, there is nothing it  knows that can't be derived publicly.    >  However, we can deduce from the XPath  > specification that the  > required information (e.g. namespace prefix) is available  > privately to the  > XPath evaluator.  It must be available since otherwise the  > XPath evaluator  > would be unable to do anything with the initial namespace declarations  > created during evaluation context initialization.    It is available to the XPath evaluator because it is in the document.  It is  passed to the XPath evaluator through the context node.  You still have this  information outside XPath.    > Since the required information is available internally, AND  > certain existing  > XPath function must be able to access that information, we  > can deduce that  > the information is available to XPath functions.  Hence,  > since serialize()  > is defined as an XPath function, it must be able to access namespace  > prefixes and document order positions, whether or not they  > are in the public  > data model exposed to XPath expression authors.  > </john>    The serialize function has available what is passed into it as arguments.  If it is a nodelist, the function can follow these pointers back to the  original document, and get this information.    > > Also, I think that serialization is the one thing that you  > > would not expect  > > an XPath engine to provide (unlike parsing).  >  > I do not expect an XPath engine to provide parsing.  > Microsoft's doesn't, as  > an example.  >  > <john>Microsoft has an XPath engine.  Firstly, tell me where  > it is so I can  > look at it.    IE5 shipped with an "XSL Pattern" engine in MSXML - see the selectNodes and  selectSingleNode DOM extensions.  The latest MSXML technology updates this  to an almost complete subset of XPath.  Docs and downloads can be found at  http://msdn.microsoft.com/xml.    > Is it open source?  No.    > Second, regardless of whether it provides a  > parser in the concrete sense, it must be coupled with a parser in the  > abstract sense.    Indeed XPath evaluation is a service provided through DOM extensions,  specifically as methods on DOM Node objects.  The inverse would also be  possible - an XPath object that was given various context nodes.  Your spec  should not unduly constrain the use of either of these types of  implementation.    Which XPath processor are you using to evaluate this design?  I'm really  only familiar with a small class of processors - Microsoft, Oracle, and to a  lesser extent others within XSLT implementations.    >  You must initialize the evaluation context, you must  > provide a context node, position and size, the context node,  > position and  > size together form a node-set, and the XPath evaluator must be able to  > derive from that node-set the namespace prefixes and the  > document order  > positions.  Regardless of where you got the processor, you have had to  > create enough data structure SOMEHOW to support the described  > operations.</john>    Yes, which brings up a nasty point I hadn't realized before.  Our  implementation does not currently allow you to pass in any function bindings  (except when used within XSLT).  So I wouldn't be able to build a full  implementation of XPath transforms on MSXML without some pretty painful  hackery.  It would be much easier if no extension functions were needed.  I  wouldn't put too much weight on this, but it may be evidence of a class of  simple XPath processors that couldn't be used for XPath transforms.    > Likewise, my XML processor may indeed provide a serialization  > feature.  Microsoft's does, for example.  I'm not able to use  > the existing  > functionality that may be provided by a processor because a specific  > implementation strategy has been prescribed - the serialize()  > function.  > Now, I don't believe the Microsoft serializer IS quite  > adequate because your  > constraints are too severe - but that's a separate potential issue.  >  > <john>If your serialization function were adequate, then I  > wonder why you  > can't call it from your serialize() implementation?  > As to its adequacy, if the tool doesn't work, then don't use  > it.  You can  > only reuse code in  a new application if it fits the  > application.  However,  > the serialization described in the spec is QUITE easy to  > implement, so I  > cannot fathom why it would be a 'potential issue'.  > </john>    I will defer this to another thread.    > As I indicated previously, I would not expect an XPath  > implementation to be  > optimized for returning the huge strings that could result from the  > serialize() function.  And as I indicated previously, the  > necessity/danger  > of user intervention on the serialized string has not been  > justified.  Even  > the necessity of a two-step process of serializing and then  > converting to  > UTF-8 gives me pause for thought - it looks like I might need  > two separate  > serialize() functionalities to obtain maximum performance.  >  > <john>  > The need for serialize() has been justified on several  > levels.  Firstly,  > there is no security threat in allowing user intervention on  > the serialized  > node-set.    My term "dangerous" was clearly a poor one in this context :-)  I meant not  that a security risk was imposed, but that it would be quite easy to damage  the well-formedness of the XML document.  Manipulating XML through string  manipulation is unquestionably more prone to error than manipulating it  through structural methods.  You can tell the user "well, you're stupid and  you broke it" but unless there is a compelling reason to ALLOW him to break  it, it seems self-evident that it's best not to.    > For you to argue otherwise would require that you  > explain why it  > is significantly different from writing a different XPath  > expression. The  > XPath expression is signed, so its modification of the input follows a  > well-known behavior that we can prove is the correct behavior  > leading to the  > given message digest.  >  > Secondly, I've justified it from the specification  > standpoint.  By defining  > the behavior as a function library addition to XPath, the  > result of the DSig  > WG's work can continue to be viewed as an application of  > XPath, not as an  > extension of XPath.    XPath transforms is an application of XPath which is comprised of several  parts:  - parsing the document from a stream  - identifying the nodes to keep/trim using an XPath  - trimming the tree  - serialization of the result    Note that the last two are described as coincident by the serialize()  function.  This is a perfectly good application of XPath.  Providing  serialize() does not make it a better application of XPath, any more than  removing it would make it less of an appropriate XPath application.    If somehow it were shown that the serialize() function is necessary to make  XPath transforms an application, what about the case when it is performed  automatically?  Does somehow this use constitute an XPath extension?  The  logic of your assertion totally escapes me.    > Thirdly, I've justified it on technical grounds.  There is information  > required for serialization that is not available in the  > public information  > but which MUST be available to the implementations of certain XPath  > functions.    > Please have another look at how XPath handles the namespace  > declarations in  > the evaluation context.  If I have misread something, please  > let me know,  > but I did ask for clarification on this point, and noone  > (including James  > Clark) has refuted this point yet.  >  > As for two serializations, that's not happening.  The first act is a  > 'serialization' of the node-set.  The second action is a character  > transcoding to UTF-8.  My original assumption was that  > implementations would  > not lose track of the input document's encoding.  This was  > based on the fact  > that I specified a parse() that would do this.  You  > specifically along with  > others wanted to get rid of the parse().  The natural result  > is that I can  > no longer claim that the input document stays in the same  > encoding.  Since I  > also lose the BOM, UTF-8 is the only viable alternative.  >  > serialize(), however, cannot output UTF-8 because it is an  > XPath function,  > which must output a string.  The details of what that means  > are specific to  > the XPath implementation itself.  Transcoding to UTF-8 is not  > an action that  > fits within XPath.  > </john>    My concern here is that if serialize() is called automatically, I can  envision a single step in which the document is serialize directly to UTF-8  as a performance gain.  When serialize() is called explicitly, it looks like  a two-step process is needed - serialize into a string to be returned from  the XPath engine (presumeably Unicode) and then a conversion to UTF-8.  I'm  not sure if this is a real issue, but it does appear that there may be  difference in optimization potential and thus performance between the two  uses.  Users would need to be aware that explicit use of serialize() may be  slower than automatic use - another small argument against including it.    >  >  > >   So another  > > justification for  > > adding serialize() as a function is that we are adding DSig's key  > > functionality using the XPath-defined extension mechanism  > > (function library  > > modification).  This maintains the property that dsig is an  > > application of  > > XPath, not something different that happens to use the XPath  > > expression  > > syntax.  >  > I still don't understand this argument either.  If the  > serialize function  > can be called automatically for nodesets as you prescribe,  > this would seem  > to indicate that there is not a necessity to expose it to the  > user in all  > cases.  If you are not using the prescribed XPath extension  > mechanism in all  > cases, how does this contribute to maintaining "the property  > that dsig is an  > application of XPath"?  The output of the XPath processor is  > not the end  > result of the transform in all cases.  Doing more or less  > back-end work is a  > pretty abstract distinction.  >  > I feel that it is already an appropriate application of XPath  > to locate  > nodes in an XML document.  Going beyond this to serializing  > within the XPath  > expression itself doesn't contribute to the impression that  > dsig is an XPath  > application.  In fact, my gut feeling is that it is abuse  > because it appears  > to short-circuit the primary XPath return type of nodeset.  >  > <john>The specification very clearly points out that the  > XPath can return a  > node-set.  However, to run a digest algorithm, we need a  > string.</john>    This is true but doesn't address my point.  I think it's great that a user  can return a nodeset and it'll get serialized automatically.  In fact, it's  so great I can't see why anyone would ever need to bother with calling  serialize() explicitly.    > The redundancy argument still applies.  I can call the  > serialize() function,  > or not, with the same result.  Without some use cases  > justifying the need  > for the long form, the short form looks perfectly adquate to me.  >  > Note that there is no standard mechanism defined by XPath to "call"  > extension functions outside of the XPath expression.  The XSLT spec  > carefully uses descriptions like "the resulting object is  > converted to a  > string _as_if_ by a call to the string function" (emph  > added.)  A similar  > approach would be appropriate in describing XPath transforms.  >  > I don't see a concrete problem that serialize() solves.  I do see some  > concrete reasons not to have it - performance, implementation  > flexibility,  > eliminating redundancy, simplified syntax.  >  > <john>Sure, as long as you can guarantee that the moment we  > yank serialize,  > we aren't going to have half a dozen different people writing  > in to say that  > "my-favorite-XPath-engine doesn't have access to namespace  > prefixes" or  > "my-favorite-XPath-engine makes it really inefficient to do  > document order".    First of all, I can't guarantee people won't complain.  I can't even  guarantee their complaints won't be justified.  I only can state that I'm  not aware of any implementations that would have problems with this, and  it's hard to imagine how they could and still conform to namespace nodes in  the XPath data model.  You have not previously presented evidence of such  implementations or even their potential.  My goal is to enable a wider range  of XPath engines to be used, and I would welcome more details about  constraints on specific implementations.    > Also, I do like the idea of being able to tweak the data in  > certain ways  > once it has been serialized.  One could wrap a root element  > around a list of  > elements, one could prepend some simple material to make the  > result of the  > transform more usable to certain software.  > </john>    Structural manipulations like this should be left to XSLT, which is designed  to perform exactly this type of operation without damaging well-formedness  or the meaning of the document.    In summary, I still haven't found even one of your arguments for exposing  serialize() to the user compelling.  Since we aren't converging on  solutions, perhaps we should focus instead on converging on a clean  statement of our different positions?  There appears to be very little in  the way of hard technical arguments either way, so a win/loss outcome seems  unlikely.        

      Hi Petteri,    Please note the following sentence, which leads the fifth paragraph of  section 2.1:    "The input octet stream MUST contain a well-formed XML document, but the  input need not be validated. However, the attribute value normalization and  entity reference resolution MUST be performed in accordance with the  behaviors of a validating XML processor."    Example 3.5 is designed to ensure that implementations conform with this  requirement (so that validating and non-validating processors have the same  output).    Thanks,  John Boyer  PureEdge Solutions Inc.    -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Petteri Stenius  Sent: Wednesday, October 11, 2000 5:54 AM  Subject: RE: Tentative signature over C14N examples        Does not the "Entiry References" sample in chapter 3.5 of [1] require a  validating parser because of the external entity references?    The spec does not require a validating parser, should not the sample be  changed to not require a validating parser?    Petteri    [1] http://www.w3.org/TR/2000/WD-xml-c14n-20000907    > -----Original Message-----  > From: John Boyer [mailto:jboyer@PureEdge.com]  > Sent: Friday, October 06, 2000 9:53 PM  > To: merlin@baltimore.ie  > Cc: xmldsig-interop@pothole.com; XML DSig  > Subject: RE: Tentative signature over C14N examples  >  >  > Hi Merlin,  >  > Note that your message did not go to the DSig list.  >  > <merlin>  > <snip/>  > Note that I do not concur with the spec for example 4: I don't  > understand the subtlety of marking the attribute as an ID; my  > nonvalidating parser treats it no differently.  > </merlin>  >  > <john>  > Yes, your non-validating parser should have no trouble with  > the id attribute  > of normId.  A validating parser, however, should get a little  > choked up  > about the ID attribute because the attribute should conform  > to NmToken but  > doesn't.  > I also notice that your example 4 did not strip out the  > leading and trailing  > whitespace for that attribute's value.  The example in  > c14n-20000907 is  > wrong for not doing that.  > By saying that your non-validating parser treats it no  > differently, are you  > saying that your non-validating processor does not realize that the  > attribute is identified as an ID attribute?  > If so, please see Section 5.1 of the XML specification  > regarding conformance  > of non-validating processors.  >  > Though not applicable to this example, please also note the  > following from  > Section 2.1 of C14N:  > "The input octet stream MUST contain a well-formed XML  > document, but the  > input need not be validated. However, the attribute value  > normalization and  > entity reference resolution MUST be performed in accordance with the  > behaviors of a validating XML processor."  > This requirement means that a non-validating processor can be  > used, but the  > c14n implementation is required to augment the processor by  > reading the  > external DTD subset for the additional declarations.  > </john>  >  > <merlin>  > Neither do I concur with the spec for example 7: I do not see  > a justification for xmlns="".  > </merlin>  >  > <john>  > The justification is that e3 is not namespace qualified in  > the input, so it  > should not be namespace qualified in the output.  The problem is that,  > unfortunately, the XPath data model represents an empty  > default namespace  > with the absence of a node, not with the presence of a  > default namespace  > node having an empty value.  Thus, w.r.t. e3, we cannot tell  > the difference  > between <e2 xmlns=""><e3/></e2> versus <e2><e3  > xmlns=""/></e2>.  All we know  > is that e3 was not be namespace qualified on input, so we  > preserve this  > information on output.  > </john>  >  > <merlin>  > I tweaked the XPath on example 7 to suit signature processing.  > </merlin>  >  > <john>  > Perhaps you could provide the full XPath transform that  > you've used.  I'm  > pretty sure your tweak is fine, but I'd like to see the  > declaration of the  > ieft prefix.  BTW, is there some reason why you didn't use  > the subexpression  > inside the square brackets of example 7?  > </john>  >  > <merlin>  > John, I presume that xml:foo attributes are sorted using the  > standard value for xmlns:xml if none else is specified?  > </merlin>  >  > <john>  > Yes.  The default value for the xml prefix provides the  > namespace URI that  > functions as the primary key of attributes beginning with the  > xml: prefix.  > </john>  >  > <merlin>  > Also, the NOTATION needs a SYSTEM.  > </merlin>  >  > <john>  > Yikes! I will fix that immediately.  > Canonical form is unaffected-- unfortunately :(  > </john>  >  > Merlin  >        

      Hi Eve,    Some time ago, Kent TAMURA in our group asked, What should here() return  when it appears as follows:    <e> h<!-- yikes -->ere()/...</e>    I would like to add to that by asking, what should happen below:    <e>here()/... | <!-- yikes times two --> here()/...</e>    In the first case, I think the text node containing the 'h' should be  returned.  In the second case, we could have each instance of here() return  the text node containing it, but it's a bit weird that two calls to a  function in the same expression actually return different values.    This brings up still a third question about the XPath (and hence the  XPointer) data model.  I have always assumed that building an XPath  implementation requires an XML processor that retains comments since comment  nodes must be represented in the data model.  But, if I execute an XPath  expression that removes all comment nodes, do consecutive text nodes get  merged in the resultant node-set? The XPath spec indicates that they are  merged, but I thought that was only on input.  Now I wonder...    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>            -----Original Message-----  From: Eve L. Maler [mailto:Eve.Maler@east.sun.com]  Sent: Friday, June 02, 2000 3:31 PM  Subject: Re: XPath Serialization      John and Michael,    The XML Linking WG has discussed the issue of here(), and has agreed to  change the definition so that it returns the node that the XPointer is  actually in.  We hope this satisfies your concerns.    Best regards,    Eve  --  Eve Maler                                    +1 781 442 3190  Sun Microsystems XML Technology Center    elm @ east.sun.com        

      Hi Merlin,    Note that your message did not go to the DSig list.    <merlin>  <snip/>  Note that I do not concur with the spec for example 4: I don't  understand the subtlety of marking the attribute as an ID; my  nonvalidating parser treats it no differently.  </merlin>    <john>  Yes, your non-validating parser should have no trouble with the id attribute  of normId.  A validating parser, however, should get a little choked up  about the ID attribute because the attribute should conform to NmToken but  doesn't.  I also notice that your example 4 did not strip out the leading and trailing  whitespace for that attribute's value.  The example in c14n-20000907 is  wrong for not doing that.  By saying that your non-validating parser treats it no differently, are you  saying that your non-validating processor does not realize that the  attribute is identified as an ID attribute?  If so, please see Section 5.1 of the XML specification regarding conformance  of non-validating processors.    Though not applicable to this example, please also note the following from  Section 2.1 of C14N:  "The input octet stream MUST contain a well-formed XML document, but the  input need not be validated. However, the attribute value normalization and  entity reference resolution MUST be performed in accordance with the  behaviors of a validating XML processor."  This requirement means that a non-validating processor can be used, but the  c14n implementation is required to augment the processor by reading the  external DTD subset for the additional declarations.  </john>    <merlin>  Neither do I concur with the spec for example 7: I do not see  a justification for xmlns="".  </merlin>    <john>  The justification is that e3 is not namespace qualified in the input, so it  should not be namespace qualified in the output.  The problem is that,  unfortunately, the XPath data model represents an empty default namespace  with the absence of a node, not with the presence of a default namespace  node having an empty value.  Thus, w.r.t. e3, we cannot tell the difference  between <e2 xmlns=""><e3/></e2> versus <e2><e3 xmlns=""/></e2>.  All we know  is that e3 was not be namespace qualified on input, so we preserve this  information on output.  </john>    <merlin>  I tweaked the XPath on example 7 to suit signature processing.  </merlin>    <john>  Perhaps you could provide the full XPath transform that you've used.  I'm  pretty sure your tweak is fine, but I'd like to see the declaration of the  ieft prefix.  BTW, is there some reason why you didn't use the subexpression  inside the square brackets of example 7?  </john>    <merlin>  John, I presume that xml:foo attributes are sorted using the  standard value for xmlns:xml if none else is specified?  </merlin>    <john>  Yes.  The default value for the xml prefix provides the namespace URI that  functions as the primary key of attributes beginning with the xml: prefix.  </john>    <merlin>  Also, the NOTATION needs a SYSTEM.  </merlin>    <john>  Yikes! I will fix that immediately.  Canonical form is unaffected-- unfortunately :(  </john>    Merlin        

      Hi Joseph,    Attached is an updated copy of the c14n spec.  It has the following changes:    1) Encoding of > with > in text nodes.  2) Linefeeds for PIs and comments; slight difference from old spec.  3) Elimination of comments as default.  4) New way for document subsets to handle attributes in xml namespace.  5) Better description of node-set processing.  6) Additional note about node-set as set of nodes, not list of subtrees.  7) Tweaks to document date, Status, Resolutions and Acknowledgements.    The Resolutions section contains the few differences between the past c14n  and the current c14n.    I am away next Monday to Thursday, but on Friday I should be able to send an  updated XPath transform that simply refers to the c14n rather than repeating  the c14n material.    John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com          text/html attachment: xml-c14n.htm          

      Hi Gregor,    Answers within...    -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Gregor Karlinger  Sent: Tuesday, May 30, 2000 12:24 AM  Subject: RE: Alternative Canonicalization Draft      Hello John,    > [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Joseph M. Reagle  > Jr.    [...]    > John's alternative approach to C14N (in XPath instead of InfoSet context,  > though the results aren't that different aside from the changes we  > explicitly discussed) is at:  >  > http://www.w3.org/Signature/Drafts/WD-xml-c14n-20000601.html  >  > I think it would be best to get comments from folks in this WG before  > forewarding it to the attention of the larger community (though I'd like  > to do that ASAP).      following my comments and questions regarding your latest C14N draft.      * In section 4 you specify the text generation for the root node as    follows:      "Root Node- Nothing (no byte order mark, no XML declaration, no     document type declaration)."      XML 1.0 allows also comments and processing instructions to be child    nodes of the root. Why are these nodes eliminated?    <john>  They aren't eliminated.  The text, PI and comment node children of the root  are processed in accordance with the rules for that node type.  Each has a  document order, so it will be processed as a function of processing the  node-set.  </john>    * In section 4, in the specification for namespace and attribute node    text generation, I found the following sentence:      "[...] and all whitespace characters (#x9, #xA, #xD, and #x20) with     character references, except for #x20 characters with no preceding     #x20."      I am sorry I do not understand the last part of this sentence. Could    you please give an example?    <john>  Though the sentence technically works, I now realize that it attempts to fix  a problem that doesn't exist.  The sentence fragment can therefore be  replaced by:    "[...] and the whitespace characters #x9, #xA, and #xD with     character references."    The problem was simply that I wanted to retain any extra spaces that managed  to get included by character reference in the normalized value of non-CDATA  attributes.  I had thought that whitespace characters included by character  reference were not normalized out, but it is now clear to me that this is  true of most whitespace characters but not of actual space characters.  In  other words, sequences of #x9, #xA and #xD characters may appear but not  #x20 characters.  Therefore, in non-CDATA attributes, every #x20 character  has no preceding #x20 and so would be encoded as a #x20 character not as the    character reference.  This is why the short description works.    John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com    </john>    Regards, Gregor  ---------------------------------------------------------------  Gregor Karlinger  mailto://gregor.karlinger@iaik.at  http://www.iaik.at  Phone +43 316 873 5541  Institute for Applied Information Processing and Communications  Austria  ---------------------------------------------------------------        

      Hi Jonathan,    -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Jonathan Marsh  Sent: Monday, March 27, 2000 12:14 PM  Donald-LDE008; TAMURA Kent; Christopher R. Maden; Ed Simon  Subject: RE: Enveloped signatures and XPath      John Boyer wrote:  > At the very least, serialize() needs access to the namespace prefix.    I still don't understand.  In an XPath transform, the inputs are essentially  a resource and an XPath expression.  The resource is parsed into an XML  document, the XPath context initialize, and the XPath is evaluated.  Now you  have an XML document and a node list (temporarily treating other return  types as degenerate), which is simply a list of pointers into the XML  document.  Evaluation of the XPath doesn't (can't) provide any more  information than is already available in the document instance.  In fact the  opposite may be true, since the XML document may contain more information  than is exposed in the XPath data model.    <john>  Right.  The exact point I'm trying to make is that information needed for  serialization (specifically, the namespace prefix) is not publically  available.  However, we can deduce from the XPath specification that the  required information (e.g. namespace prefix) is available privately to the  XPath evaluator.  It must be available since otherwise the XPath evaluator  would be unable to do anything with the initial namespace declarations  created during evaluation context initialization.    Since the required information is available internally, AND certain existing  XPath function must be able to access that information, we can deduce that  the information is available to XPath functions.  Hence, since serialize()  is defined as an XPath function, it must be able to access namespace  prefixes and document order positions, whether or not they are in the public  data model exposed to XPath expression authors.  </john>      > Also, I think that serialization is the one thing that you  > would not expect  > an XPath engine to provide (unlike parsing).    I do not expect an XPath engine to provide parsing.  Microsoft's doesn't, as  an example.    <john>Microsoft has an XPath engine.  Firstly, tell me where it is so I can  look at it.  Is it open source?  Second, regardless of whether it provides a  parser in the concrete sense, it must be coupled with a parser in the  abstract sense.  You must initialize the evaluation context, you must  provide a context node, position and size, the context node, position and  size together form a node-set, and the XPath evaluator must be able to  derive from that node-set the namespace prefixes and the document order  positions.  Regardless of where you got the processor, you have had to  create enough data structure SOMEHOW to support the described  operations.</john>    Likewise, my XML processor may indeed provide a serialization  feature.  Microsoft's does, for example.  I'm not able to use the existing  functionality that may be provided by a processor because a specific  implementation strategy has been prescribed - the serialize() function.  Now, I don't believe the Microsoft serializer IS quite adequate because your  constraints are too severe - but that's a separate potential issue.    <john>If your serialization function were adequate, then I wonder why you  can't call it from your serialize() implementation?  As to its adequacy, if the tool doesn't work, then don't use it.  You can  only reuse code in  a new application if it fits the application.  However,  the serialization described in the spec is QUITE easy to implement, so I  cannot fathom why it would be a 'potential issue'.  </john>    As I indicated previously, I would not expect an XPath implementation to be  optimized for returning the huge strings that could result from the  serialize() function.  And as I indicated previously, the necessity/danger  of user intervention on the serialized string has not been justified.  Even  the necessity of a two-step process of serializing and then converting to  UTF-8 gives me pause for thought - it looks like I might need two separate  serialize() functionalities to obtain maximum performance.    <john>  The need for serialize() has been justified on several levels.  Firstly,  there is no security threat in allowing user intervention on the serialized  node-set.  For you to argue otherwise would require that you explain why it  is significantly different from writing a different XPath expression. The  XPath expression is signed, so its modification of the input follows a  well-known behavior that we can prove is the correct behavior leading to the  given message digest.    Secondly, I've justified it from the specification standpoint.  By defining  the behavior as a function library addition to XPath, the result of the DSig  WG's work can continue to be viewed as an application of XPath, not as an  extension of XPath.    Thirdly, I've justified it on technical grounds.  There is information  required for serialization that is not available in the public information  but which MUST be available to the implementations of certain XPath  functions.    Please have another look at how XPath handles the namespace declarations in  the evaluation context.  If I have misread something, please let me know,  but I did ask for clarification on this point, and noone (including James  Clark) has refuted this point yet.    As for two serializations, that's not happening.  The first act is a  'serialization' of the node-set.  The second action is a character  transcoding to UTF-8.  My original assumption was that implementations would  not lose track of the input document's encoding.  This was based on the fact  that I specified a parse() that would do this.  You specifically along with  others wanted to get rid of the parse().  The natural result is that I can  no longer claim that the input document stays in the same encoding.  Since I  also lose the BOM, UTF-8 is the only viable alternative.    serialize(), however, cannot output UTF-8 because it is an XPath function,  which must output a string.  The details of what that means are specific to  the XPath implementation itself.  Transcoding to UTF-8 is not an action that  fits within XPath.  </john>      >   So another  > justification for  > adding serialize() as a function is that we are adding DSig's key  > functionality using the XPath-defined extension mechanism  > (function library  > modification).  This maintains the property that dsig is an  > application of  > XPath, not something different that happens to use the XPath  > expression  > syntax.    I still don't understand this argument either.  If the serialize function  can be called automatically for nodesets as you prescribe, this would seem  to indicate that there is not a necessity to expose it to the user in all  cases.  If you are not using the prescribed XPath extension mechanism in all  cases, how does this contribute to maintaining "the property that dsig is an  application of XPath"?  The output of the XPath processor is not the end  result of the transform in all cases.  Doing more or less back-end work is a  pretty abstract distinction.    I feel that it is already an appropriate application of XPath to locate  nodes in an XML document.  Going beyond this to serializing within the XPath  expression itself doesn't contribute to the impression that dsig is an XPath  application.  In fact, my gut feeling is that it is abuse because it appears  to short-circuit the primary XPath return type of nodeset.    <john>The specification very clearly points out that the XPath can return a  node-set.  However, to run a digest algorithm, we need a string.</john>    The redundancy argument still applies.  I can call the serialize() function,  or not, with the same result.  Without some use cases justifying the need  for the long form, the short form looks perfectly adquate to me.    Note that there is no standard mechanism defined by XPath to "call"  extension functions outside of the XPath expression.  The XSLT spec  carefully uses descriptions like "the resulting object is converted to a  string _as_if_ by a call to the string function" (emph added.)  A similar  approach would be appropriate in describing XPath transforms.    I don't see a concrete problem that serialize() solves.  I do see some  concrete reasons not to have it - performance, implementation flexibility,  eliminating redundancy, simplified syntax.    <john>Sure, as long as you can guarantee that the moment we yank serialize,  we aren't going to have half a dozen different people writing in to say that  "my-favorite-XPath-engine doesn't have access to namespace prefixes" or  "my-favorite-XPath-engine makes it really inefficient to do document order".  Also, I do like the idea of being able to tweak the data in certain ways  once it has been serialized.  One could wrap a root element around a list of  elements, one could prepend some simple material to make the result of the  transform more usable to certain software.  </john>    > John Boyer  > Software Development Manager  > PureEdge Solutions, Inc. (formerly UWI.Com)  > Creating Binding E-Commerce  > jboyer@PureEdge.com  >  >  > -----Original Message-----  > From: Jonathan Marsh [mailto:jmarsh@microsoft.com]  > Sent: Monday, March 27, 2000 10:27 AM  > To: 'John Boyer'; IETF/W3C XML-DSig WG (E-mail)  > Cc: Martin J. Duerst; James Clark; Joseph Reagle; Eastlake  > Donald-LDE008; TAMURA Kent; Christopher R. Maden; Ed Simon  > Subject: RE: Enveloped signatures and XPath  >  >  > "However, serialization must be represented as an XPath  > function since it  > requires access to the internal representation of a node-set  > (see parsing  > requirements)."  >  > What does this mean?  >  > > -----Original Message-----  > > From: John Boyer [mailto:jboyer@PureEdge.com]  > > Sent: Thursday, March 23, 2000 4:15 PM  > > To: IETF/W3C XML-DSig WG (E-mail)  > > Cc: Martin J. Duerst; James Clark; Joseph Reagle; Eastlake  > > Donald-LDE008; TAMURA Kent; Christopher R. Maden; Jonathan Marsh; Ed  > > Simon  > > Subject: RE: Enveloped signatures and XPath  > >  > >  > > Attached and Pasted below is the HTML for a new version of the XPath  > > transform for your consideration.  If you are on the cc line,  > > it is because  > > you expressed a special interest and/or have provided  > > constructive and very  > > helpful feedback on the XPath transform in the recent past.  > >  > > Although I'm sure it's not the final draft, I am excited by  > > the possibility  > > that we as a group may be close to a sufficient and easy to  > > understand and  > > implement version of the XPath transform, so I am asking you  > > to please take  > > some time to review the new specification as it is a very  > > important part of  > > meeting our partial XML document signing requirement.  > >  > > Thanks,  > > John Boyer  > > Software Development Manager  > > PureEdge Solutions, Inc. (formerly UWI.Com)  > > jboyer@PureEdge.com  > >  > >  > > Executive overview  > > ==================  > >  > > In accordance with group feedback, the following issues have  > > been addressed  > >  > > 1) The parse() function and $input variable binding has been  > > eliminated.  > > Instead the root of the input XML document is provided as the  > > context node  > > of the initial evaluation context.  Certain assumptions about what  > > information the parser must retain have been expressed, but  > > all of these  > > assumptions seem to be necessary to support other  > > functionality of XPath.  > > Specifically, I assume that the QName of an element,  > > attribute or namespace  > > node can be created using the information available in the  > > parse tree of any  > > processor that is bundled with an XPath engine.  > >  > > 2) Exact order is eliminated; lex order on input is  > > eliminated; lex order of  > > attribute and namespace nodes in the output has been  > > specified in accordance  > > with group feedback.  > >  > > 3) The namespace declarations are initialized to those  > > available to the  > > XPath element containing the Xpath expression, as is done  > in XPointer.  > >  > > 4) Variable bindings for expression byte order mark and  > > encoding have been  > > eliminated.  Instead we have the assumption that the implementation  > > translates to the character domain before evaluating the  > > XPath expression,  > > which is in accordance with the XPath recommendation.  > >  > > 5) The serialize() function has been retained in part to simplify  > > specification and in part because it needs access to the internal  > > representation of a node-set.  However, note that it is  > automatically  > > applied to the XPath transform result, so a) it will almost  > > never need to be  > > called explicitly, and b) XPath transform expressions need  > > not start with a  > > function call, which seemed to be the source of some concern.  > >  > > 6) The output encoding has been standardized to UTF-8.  > There does not  > > appear to be a better option.  > >  > > 7) Someone mentioned a problem with namespace nodes.  There  > > was something  > > that we were not addressing, but I did not understand the  > > comment.  If you  > > are reading, and it was your comment, could you please reiterate and  > > elaborate.  > >  > > ================================================  > >  > > <h4>6.6.3 <a name="sec-XPath">XPath</a> Filtering </h4>  > >  > > <dl>  > >   <dt>Identifier: </dt>  > >   <dd>http://www.w3.org/TR/1999/REC-xpath-19991116 </dd>  > > </dl>  > >  > > <p>The <a href="#ref-XPath">XPath</a> transform output is the  > > result of  > > applying an  > > XPath expression to an input string. The XPath expression  > appears in a  > > parameter  > > element named <code>XPath</code>. The input string is  > > equivalent to the  > > result  > > of dereferencing the URI attribute of the  > > <code>Reference</code> element  > > containing the  > > XPath transform, then, in sequence, applying all transforms  > > that appear  > > before the XPath  > > transform in the <code>Reference</code> element's  > > <code>Transforms</code>.</p>  > >  > > <p>The primary purpose of this transform is to ensure that  > > only specifically  > > defined  > > changes to the input XML document are permitted after the  > signature is  > > affixed.  > > The XPath expression can created such that it includes all  > > elements except  > > those  > > meeting specific criteria.  It is the responsibility of the  > > XPath expression  > > author  > > to ensure that all necessary information has been included in  > > the output  > > such that  > > modification of the excluded information does not affect the  > > interpretation  > > of the  > > output in the application context.  One simple example of  > this is the  > > omission of an  > > enveloped signature's <code>SignatureValue</code> element.</p>  > >  > > <h4>6.6.3.1 Evaluation Context Initialization</h4>  > >  > > <p>The XPath transform establishes the following evaluation  > > context for the  > > XPath expression given in the <code>XPath</code> parameter  > > element:</p>  > >  > > <ul>  > > <li>A <b>context node</b>, initialized to the input XML  > > document's root  > > node.</LI>  > > <li>A <b>context position</b>, initialized to 1.</LI>  > > <li>A <b>context size</b>, initialized to 1.</LI>  > > <li>A <b>library of functions</b> equal to the function set  > > defined in <a  > > href="#ref-XPath">XPath</a>  > > plus the function <a  > href="#function-serialize">serialize()</a>.</li>  > > <li>A set of variable bindings. No means for initializing  > > these is defined.  > > Thus, the set of  > > variable bindings used when evaluating the XPath expression  > > is empty, and  > > use of a variable  > > reference in the XPath expression results in an error.</li>  > > <li>The set of namespace declarations in scope for the XPath  > > expression.</li>  > > </ul>  > >  > > <h4>6.6.3.2 Parsing Requirements for XPath Evaluation</h4>  > >  > > <p>An XML processor is used to read the input XML document  > > and produce a  > > parse  > > tree capable of being used as the initial context node for the XPath  > > evaluation, as described in the previous section.  If the  > > input is not a  > > well-formed XML document, then the XPath transform must throw an  > > exception.</p>  > >  > > <p>Validating and non-validating XML processors only behave  > > in the same way  > > (e.g. with  > > respect to attribute value normalization and entity reference  > > definition)  > > until an external  > > reference is encountered.  If the XPath transform  > > implementation uses a  > > non-validating processor,  > > and it encounters an external reference in the input  > document, then an  > > exception must  > > be thrown to indicate that the necessary algorithm is  > > unavailable (The XPath  > > transform cannot  > > simply generate incorrect output since many applications  > > distinguish an  > > unverifiable  > > signature from an invalid signature).</p>  > >  > > <p>As a result of reading the input with an XML processor,  > > linefeeds are  > > normalized,  > > attribute values are normalized, CDATA sections are  > replaced by their  > > content,  > > and entity references are recursively replaced by  > > substitution text.  In  > > addition,  > > consecutive characters are grouped into a single text node.</p>  > >  > > <p>The XPath implementation is expected to convert the  > > information in the  > > input XML  > > document and the XPath expression string to the character  > > domain prior to  > > making any  > > comparisons such that the result of evaluating the expression  > > is equivalent  > > regardless  > > of the initial encoding of the input XML document and XPath  > > expression.</p>  > >  > > <p>Based on the namespace processing rules of XPath, the  > > namespace prefix of  > > namespace-qualified nodes must be available in the parse tree.</p>  > >  > > <p>Based on the expression evaluation requirements of the  > > XPath function  > > library,  > > the <b>document order</b> position of each node must be  > > available in the  > > parse tree,  > > except for the attribute and namespace axes.  The XPath  > > transform imposes no  > > order  > > on attribute and namespace nodes during XPath expression  > > evaluation, and  > > expressions  > > based on attribute or namespace node position are not  > > interoperable.  The  > > XPath  > > transform does define an order for namespace and attribute  > > nodes during  > > <a href="#function-serialize">serialization</a>.</p>  > >  > > <h4>6.6.3.3 XPath Transform Functions</h4>  > >  > > <p>The function library of the XPath transform includes all  > functions  > > defined  > > by the XPath specification plus the serialize() function defined  > > below.  For most XPath transforms, serialize() need not be  > > called explicitly  > > since it  > > is called automatically if the expression result is a  > > node-set.  However,  > > serialization  > > must be represented as an XPath function since it requires  > > access to the  > > internal  > > representation of a node-set (see parsing requirements).</p>  > >  > > <p>  > > <a name="function-serialize"><b>Function: </b><i>string</i>  > > <b>serialize</b>(<i>node-set</i>)</a>  > > </p>  > >  > > <p>This function converts a node-set into a string by generating the  > > representative text  > > for each node in the node-set.  The nodes of a node-set are  > > processed in  > > ascending order  > > of the nodes' <b>document order</b> positions except for  > attribute and  > > namespace nodes,  > > which do not have document order positions.</p>  > >  > > <p>The nodes in the attribute and namespace axes will each be  > > processed in  > > lexicographic order,  > > with the namespace axis preceding the attribute axis.  Lexicographic  > > comparison is performed using  > > namespace URI as the primary key and local name as secondary  > > key (nodes with  > > no namespace  > > qualification have an empty namespace URI, which is defined to be  > > lexicographically least).  > > Lexicographic comparison is based on the UCS codepoint  > > values, which is  > > equivalent to lexical  > > ordering based on UTF-8.</p>  > >  > > <p>The method of text generation is dependent on the node  > > type and given in  > > the following list:</p>  > >  > > <ul>  > > <li><b>Root Node-</b> Nothing (no byte order mark, no XML  > > declaration, no  > > document  > > type declaration).</li>  > >  > > <li><b>Element Nodes-</b> An open angle bracket (<), the  > > element QName,  > > the nodes of the  > > namespace axis, the nodes of the attribute axis, a close  > > angle bracket (>),  > > the descendant  > > nodes of the element that are in the node-set (in document  > > order), an open  > > angle bracket, a  > > forward slash (/), the element QName, and a close angle bracket.  > > The element <a  > > href="http://www.w3.org/TR/REC-xml-names/#NT-QName">QName</a>  > > is either the  > > local name if the namespace prefix string is empty or the  > > namespace prefix  > > and a colon,  > > then the local name of the element.</li>  > >  > > <li><b>Namespace and Attribute Nodes-</b> a space, the node's  > > QName, an  > > equals sign,  > > an open double quote, the modified string value, and a close  > > double quote.  > > The string value of the node is modified by replacing all  > > ampersands (&)  > > with <code>&amp;</code>,  > > and all double quote characters with  > <code>&quot;</code>, and all  > > illegal characters for UTF-8  > > encoding with hexadecimal character references (e.g.  > > <code>&#x0D;</code>).</li>  > >  > > <li><b>Text Nodes-</b> the string value, except all  > > ampersands are replaced  > > by <code>&amp;</code>,  > > all open angle brackets (<) are replaced by  > > <code>&lt;</code>, and  > > all illegal characters  > > for UTF-8 encoding with hexadecimal character references (e.g.  > > <code>&#x0D;</code>).</li>  > >  > > <li><b>Processing Instruction Nodes-</b> an open angle  > > bracket, a question  > > mark, the PI target name  > > of the node, a space, the string value, the question mark,  > > and a close angle  > > bracket.</li>  > >  > > <li><b>Comment Nodes-</b> the open comment sequence  > > (<!--), the string  > > value of the node, and the close  > > comment sequence (-->).</li>  > > </ul>  > >  > > <h4 name="sec-XPathTransformOutput">6.6.3.4 XPath Transform  > > Output</h4>  > >  > > <p>The result of the XPath expression is a string, boolean,  > number, or  > > node-set.  > > If the result of the XPath expression is a string, then the  > > string converted  > > to  > > UTF-8 is the output of the XPath transform. If the result is  > > a boolean or  > > number,  > > then the XPath transform output is computed by calling the  > > XPath string()  > > function  > > on the boolean or number then converting to UTF-8.  > > If the result of the XPath expression is a node-set, then the XPath  > > transform  > > result is computed by applying the serialize() function to  > > the node-set,  > > then  > > converting the resulting string to UTF-8.</p>  > >  > > <p>For example, consider creating an enveloped signature S1 (a  > > <code>Signature</code> element  > > with an <code>id</code> attribute equal to "S1").  The  > signature S1 is  > > enveloped because its  > > <code>Reference</code> URI indicates some ancestor element of  > > S1. Since the  > > <code>DigestValue</code>  > > in the <code>Reference</code> is calculated before S1's  > > <code>SignatureValue</code>, the  > > <code>SignatureValue</code> must be omitted from the  > > <code>DigestValue</code> calculation.  > > This can be done with an XPath transform containing the  > > following XPath  > > expression in its  > > <code>XPath</code> parameter element:</p>  > >  > > <p> <code>  > > /descendant-or-self::node()[<br/>  > >      not(self::SignatureValue and  > > parent::Signature[@id="S1"]) and<br/>  > >      not(self::KeyInfo and  > > parent::Signature[@id="S1"]) and<br/>  > >      not(self::DigestValue and  > > ancestor::*[3 and  > > @id="S1"])]  > > </code> </p>  > >  > > <p>The '/descendant-or-self::node()' means that all nodes in  > > the entire  > > parse  > > tree starting at the root node are candidates for the result  > > node-set.  For  > > each node candidate,  > > the node is included in the resultant node-set if and only if  > > the node test  > > (the boolean expression  > > in the square brackets) evaluates to "true" for that node.  > > The node test  > > returns true for all  > > nodes except the <code>SignatureValue</code> and  > > <code>KeyInfo</code> child  > > elements and the  > > and the <code>DigestValue</code> descendants of  > > <code>Signature</code> S1.  > > Thus, serialize()  > > returns a string containing the entire input except for  > > omitting the parts  > > of S1 that must change  > > during core processing of S1, so these changes will not invalidate a  > > <code>DigestValue</code>  > > computed over the serialize() result.</p>  > >  > > <p>Note that this expression works even if the XPath transform is  > > implemented with a non-validating  > > processor because S1 is identified by comparison to the value of an  > > attribute named 'id' rather  > > than by using the XPath id() function.  Although the id()  > > function is useful  > > when the 'id'  > > attribute is not named 'id', the XPath expression author will  > > know the 'id'  > > attribute's name when  > > writing the expression.</p>  > >  > > <p>It is RECOMMENDED that the XPath be constructed such that  > > the result of  > > this operation  > > is a well-formed XML document. This should be the case if  > > root element of  > > the input  > > resource is included by the XPath (even if a number of its  > > descendant nodes  > > are omitted by the XPath expression). It is also RECOMMENDED  > > that nodes  > > should not be  > > omitted from the input if they affect the interpretation of  > > the output nodes  > > in the  > > application context.  The XPath expression author is  > > responsible for this  > > since the  > > XPath expression author knows the application context.</p>  > >  > >  >        

      To all: Joseph asked that we post this conversation to the list.  It  contains passages marked <john> which are from my original letter, passages  marked with <alex> are Alex Milowski's responses, and passages marked with  <johnresponse> are my responses.    By the way, Alex and I will be trying to work out the details of c14n so  that we can continue to use it within dsig.    John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com      <john>  > Hi Alex,  >  > Joseph Reagle wants a draft by May 25.  In that draft, I currently plan to  > not change much except resolve what appear to be the two outstanding  > differences between XPath serialization and c14n.  >  > My position for both of these resolutions stems from the belief that we  are  > trying to create a c14n for XML 1.0.  Two XML documents may be logically  > equivalent under some additional set of considerations, but canonicalizing  > documents under those circumstances should require a separate algorithm.  >  > Particularly under the requirements of digital signatures,  canonicalization  > helps ensure that XML applications don't corrupt a signature by doing  > logically equivalent things, but there is only so far we can take this.  To  > account for most existing applications, it should be sufficient to  > canonicalize XML 1.0 and have applications not make changes to documents  > based on logical equivalencies under considerations beyond the scope of  the  > XML 1.0 specification.  </john>    <alex>  This position will not work if you want to entertain logical equivalance  for XML namespaces and XML Schema aware documents.  </alex>    <johnresponse>  Yes, basically what I'm saying is that we should limit our exposure as much  as possible to canonicalizing XML 1.0.  Further canonicalization to account  for these other issues can be specified in the future.  Schema is not a  recommendation yet, and unless namespaces are change in some radical way, it  is impossible to canonicalize namespaces to the point where two documents  are equal if and only if their byte streams are equal.  The reason is that  XPath expressions bearing namespace references can appear in attribute  values (XSLT) or element content (DSIG).  Current c14n rewrites namespaces,  but it cannot know about references to namespaces appearing in XPath  expressions, so the two documents will still not be logically equivalent  despite namespace rewriting.  Furthermore, the rewriting actually breaks the  XPath expressions in the document.  </johnresponse>    <john>  > 1) Eliminate character model normalization. XML 1.0 is based on UCS.  An  > application should not change the UCS code point values used to represent  > characters.  Although differing UCS code point sequences may result in the  > same character visually, the knowledge of this equivalence resides outside  > of the XML 1.0 specification.  Further, those who actually have the  problem  > are likely to (and should) normalize characters during document creation.  </john>    <alex>  I think this is fine.  </alex>    <john>  > 2) Eliminate namespace prefix rewriting.  Namespaces are the most  difficult  > problem.  We will continue to propogate namespace context to descendants  > because  >  > a) namespace information would otherwise be lost when dealing with  fragments  > b) XPath and other tools have been specified to work in this way  </john>    <alex>  We can't do this.  Namespace information is *not* lost by re-writing the  prefix.  The prefix is meaningless for equivalance of namespaces.    XPath operates on namespace equivalance--the URI and local name--and not  the prefix.  Thus, when you rewrite the prefix, the same xpath expression  will work.    ...unless you are speaking to an Xpath specified in the document to which  C14N is being aplied to...  That is an interesting problem not solved by  C14N.  </alex>    <johnresponse>  Yes, this is one example of the problem I'm talking about.  C14N doesn't  solve it.  Furthermore, since C14N would also do irreparable damage to such  documents if we include namespace rewriting, it should not be included.  Namespaces need to be reformulated before we can canonicalize them without  damaging the document.    The details of what I mean by 'damage' the document are provided below in  response to another comment.  </johnresponse>    <alex>  Careful orchestration of the XPath can solve this problem.    For example:    <a:something xmlns:a="urn:x-lexica:something:en" xpath="a:foo">  <a:foo/>  </a:something>    would have problems after C14N while    <something xmlns="urn:x-lexica:something:en" xpath="foo">  <foo/>  </something>    would not because the default namespace is declared.    </alex>    <johnresponse>  What you're saying is that we shouldn't write documents that would break  c14n's ability to establish logical equivalence.  Here's another idea:  don't use different namespace prefixes in documents that are supposed to be  logically equivalent.  </johnresponse>    <john>  > However, rewriting of the namespace prefixes should not be performed.  > Namespace normalization was designed to be part of a scheme whereby the  > logical equivalence of two XML documents could be established by a  > byte-level comparison of the resulting c14n documents.  Unfortunately,  > namespace prefix rewriting does not achieve this end.  If a reference to a  > namespace appears in an attribute value or as element content (e.g. an  XPath  > in an XSL template), then it will not get normalized.  Therefore, two  > documents with one using ns1 as a prefix and the other using ns2 as a  prefix  > (both with the same URI assignment) are in fact logically equivalent but a  > byte comparison would not suffice if ns1 and ns2 appeared in attribute  > values or element character content.  >  > Most importantly, the definition of canonicalization is contradicted if  the  > c14n algorithm changes the meaning of the document.  With namespace  > rewriting, c14n(D) == c14n(c14n(D)), yet D is not logically equivalent to  > c14n(D).  >  > This is essentially a proof that it is not possible to perform byte level  > equivalence testing of namespace enhanced XML.  Therefore, we should stick  > to XML 1.0 and not try to normalize namespaces.  </john>    <alex>  I'm just not following this logic.  </alex>    <johnresponse>  You just did one of these in the first part of your example above.  Perhaps  these theorems will clarify the matter.    Theorem 1: With namespace rewriting, there exist two XML documents D1 and D2  that are logically equivalent yet c14n(D1)!=c14n(D2).    Proof: Let D1 be a document containing an XPath in an attribute value or  element content that refers to namespace prefixes used in D1.  Further  assume that the namespace prefixes in D1 will all be rewritten by c14n.  Let  D2 = D1, then modify the namespace prefixes in D2 and modify the XPath  expression's references to namespace prefixes such that D2 and D1 remain  logically equivalent.  Since c14n namespace rewriting does not include  occurences of namespace references in attribute values and element content,  c14n(D1) != c14n(D2). []    Remark: The same condition exists if we remove namespace rewriting. The  purpose of this theorem is simply to show that namespace rewriting does not  accomplish the goal for which it is intended.    Theorem 2: With namespace rewriting, there exist two XML documents D1 and D2  that have equivalent canonicalizations and yet are not logically equivalent.    Proof: Let D1 be a document containing an XPath in an attribute value or  element content that refers to namespace prefixes used in D1.  Further  assume that the namespace prefixes in D1 will all be rewritten by c14n.  Now  let D2=c14n(D1).  Clearly, c14n(D1)==c14n(D2) yet D1 and D2 are not  logically equivalent because the aforementioned XPath works in D1 and  doesn't work in D2. []    Remark: This is what I mean when I say that c14n namespace rewriting can  'damage' the document and is proof that namespace rewriting is harmful  rather than just ineffective.  </johnresponse>    <alex>  The namespace prefix rewriting in C14N  was put there to allow logical equivalance.  If you do not rewrite the  prefixes, you will never have logical equivalance.  </alex>    <johnresponse>  Yes, we will be able to establish the logical equivalence of two documents  whose namespace prefixes have not been altered.  For the purposes of  signatures this is certainly sufficient, and as I've established, you really  can't do better in the general sense.  </johnresponse>      For example:    <a:something xmlns:a="urn:x-lexica:something:en"/>    is equivalence to:    <b:something xmlns:b="urn:x-lexica:something:en"/>    and    <something xmlns="urn:x-lexica:something:en"/>    Is it necessary that XPath values that we depend on are inside what is  being signed?    <johnresponse>  Yes, the XPath transform absolutely, positively must be signed.    However, that really isn't the issue.  The issue is that whether its DSig or  any other application that might use XPaths (e.g. to express computational  relationships between elements in an electronic form), c14n cannot guarantee  equivalence with namespace rewriting.  Since I've further established that  namespace rewriting will damage these documents, it must be omitted.  </johnresponse>    <alex>  Another way to solve this is to force prefix normalization before  signatures if you want certain XPaths to work.  It isn't a great way to  solve this problem, but it certainly works.  </alex>    <johnresponse>  As I said before, it's no better a solution, has been shown to be worse.  Further, it will be worse for applications beyond DSig, such as the  expression of computational relationships.  </johnresponse>    <john>  > ===============================  >  > A third difference between XPath serialization and c14n is that the latter  > serializes an arbitrary fragment of XML.  I think we can address  fragmentary  > XML only by defining c14n input to be an XPath node-set.  Anything less,  and  > we would not have sufficient information to create the output.  However, I  > do not think there will be time to address this in the May 25 document.  </john>    <alex>  I don't really see this as an issue.  C14N specifies an algorithm for the  whole document.  There is an obvious way to scope it to a certain element.  </alex>    <johnresponse>  There are those who want to deal with fragments that have may have finer  granularity, and those that have holes. A great example would be a merge  between XPath serialization and XML canonicalization.  However, the only  real way I see of doing this is to provide the partial document to c14n as  an XPath node-set, not a byte stream.    John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com    </johnresponse>    R. Alexander Milowski           FAX: (707) 598-7649  alex@milowski.com    "The excellence of grammar as a guide is proportional to the paucity of the   inflexions, i.e. to the degree of analysis effected by the language   considered."     Bertrand Russell in a footnote of Principles of Mathematics        

      Hi Lauren,    1) namespace prefixes    Actually, the language around namespaces was already softened once to the  state it is in now from the state of saying it is flat out wrong.    In the former document, I actually presented a theorem/proof pair to show  how namespace rewriting was actively harmful to some documents.  Some felt  it was 'too serious' so we toned it down, but the argument remains in prose.    I would suggest that you consider the argument again because it is quite  irrefutable.  Taking the position that other specs are wrong if they do not  regard this information as syntax sugar seems to be an undefendable  position.  To wit, we would have to throw away, XSLT, XPointer and XPath.  I  really don't think that's going to happen at this point.    2) relative to absolute URIs    I will be *very* happy to see this as an erratum, but I cannot remove the  statement from c14n until that erratum is published. I am hoping this occurs  before C14N goes to candidate rec.    As far as I can tell, the XPath requirement to absolutize was always  misguided anyway since it has nothing to do with XPath but rather with  something that must be done by the XML processor that creates the input to  XPath.  If the input processor does not absolutize, it does not affect a  single thing in XPath.    As for signatures, I think that absolutizing would break signatures over  data that contains relative URIs in the namespace nodes.  Up to now, we have  been encumbered to simply recommend that people don't use relative URIs in  data they plan to sign, so obviously we will be quite happy if this gets  changed.    Until it does, though, our hands are tied...    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: Lauren Wood [mailto:lauren@sqwest.bc.ca]  Sent: Monday, September 11, 2000 10:27 AM  Subject: comments on the XML Canonical specification      On reading the XML Canonical spcification, I have some comments and  concerns, which I think should be addressed.    1) 'However, the statement in Namespaces in XML that "the prefix  functions only as a placeholder for a namespace name" is only true in  the limited context of the Namespaces in XML Recommendation.'    This is not true; although some specifications do not follow this,  others do. There are several DOM applications which treat the prefix as  "syntactic sugar"; it is only important for serialization and may be  changed at that stage. DOM Level 2 makes no attempt to make sure  prefixes match namespace URIs, for example, and there are DOM  applications which don't ever assign prefixes, because the XML is never  serialized. Several people are of the opinion that the Namespaces  Recommendation is correct in this regard, and those specifications which  differ are incorrect. So I would recommend that the language in the  canonicalization specification be chosen carefully.    2) 'The XPath data model expects the XML processor to convert relative  URIs to absolute URIs.'    This is an errata in the XPath specification, which will be fixed. See  the Hypertext Coordination Group archives.    Lauren Wood        

      Hi Merlin,    <merlin>  The C14N of e3 should ?not? have xmlns:w3c.  </merlin>    <john>  Actually, it should have the w3c namespace.  Each node receives namespace  nodes for its entire namespace context, including those derived from its  ancestors.  </john>    <merlin>  Also, I do not believe that the XPath tests for (self|parent)::e(1|2)  are correct. The default namespace for those nodes is non-null, and I  think that 2.3 of REC-xpath suggests that if you want to capture this  in an XPath you must use a namespace prefix in scope for the expression.  Hence ietf:e(1|2) in my earlier version of the XPath. Which was...      <Transform ...><XPath xmlns:ietf="http://www.ietf.org">...ietf:e1...    But I'm often wrong about namespaces, so I'm prepared again.  </merlin>    <john>  Drats!  In the example I did this morning, I forgot about that detail.  I  will tweak the document subset expression box as follows:    <!-- Evaluate with declaration xmlns:ietf="http://www.ietf.org" -->    (//. | //@* | //namespace::*)  [      self::ietf:e1 or (parent::ietf:e1 and not(self::text() or self::e2))      or      count(id("E3")|ancestor-or-self::node()) = count(ancestor-or-self::node())   ]     This should allow the intended output results to follow from the current input.  Nice work, Merlin!  </john>    <merlin>  I think that adding a regular attribute to e1 would be potentially  useful for this example (i.e., <e1 foo="bar">), just so the second  clause of your XPath can capture more than just namespace nodes  (which are probably treated differently to regular attributes).  </merlin>    <john>  This doesn't seem to matter.  Attributes and namespaces are equivalent with respect to the fact that they treat the containing element as parent.  So, I'd prefer not to change the example at this point.  </john>    <merlin>  Also, an example of C14N on the e3 element below would be interesting:    <e1 xmlns="http://foo" xmlns:bar="http://baz">    <e2 xmlns="" xmlns:bar="">      <e3 ID="E3" />    </e2>  </e1>    This captures that empty xmlns namespaces are not really inherited,  but empty xmlns:* are. At least, I think they are.  </merlin>    <john>  Again, I'd really rather not add that example at this stage.  The examples are primarily intended to show where changes will occur since this is primarily where misinterpretation of the rules will occur.  Your point is well-taken, but given how hard it is to read this document and mistakenly come to the conclusion that xmlns="" is inherited rather than generated under specific conditions, I'd prefer to cut off additions at this time.    Fixes, like the one above, seem to be the principal order of the day...    Thanks,  John Boyer  </john>    Merlin    r/jboyer@PureEdge.com/2000.10.10/11:31:44  >Hi Merlin,  >  >I've changed example 3.7 as given below, and I am hoping you can provide  >feedback ASAP on whether you concur with the new version:  >  >Input:  >  ><!DOCTYPE doc [  ><!ATTLIST e2 xml:space (default|preserve) 'preserve'>  ><!ATTLIST e3 id ID #IMPLIED>  >]>  ><doc xmlns="http://www.ietf.org" xmlns:w3c="http://www.w3.org">  >   <e1>  >      <e2 xmlns="">  >         <e3 id="E3"/>  >      </e2>  >   </e1>  ></doc>  >  >XPath:  >  >(//. | //@* | //namespace::*)  >[  >   self::e1 or (parent::e1 and not(self::text() or self::e2))  >   or  >   count(id("E3")|ancestor-or-self::node()) =  >count(ancestor-or-self::node())  >]  >  >Canonical Form:  >  ><e1 xmlns="http://www.ietf.org" xmlns:w3c="http://www.w3.org"><e3 xmlns=""  >xmlns:w3c="http://www.w3.org" id="E3" xml:space="preserve"></e3></e1>  >  >============================  >Thanks,  >John Boyer  >Development Team Leader,  >Distributed Processing and XML  >PureEdge Solutions Inc.  >Creating Binding E-Commerce  >v: 250-479-8334, ext. 143  f: 250-479-3772  >1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>  >  >  >  >-----Original Message-----  >From: merlin@baltimore.ie [mailto:merlin@baltimore.ie]  >Sent: Saturday, October 07, 2000 8:52 AM  >To: John Boyer  >Cc: xmldsig-interop@pothole.com; XML DSig  >Subject: Re: Tentative signatur  e over C14N examples  >  >  >Hi,  >  >Attached is a gzipped tarchive containing a signature over the  >seven C14N examples from the latest C14N draft, hopefully  >conforming to the latest signature draft. Included is also  >the raw C14N output. However, there is still one difference  >between my signature and the "correct" output so this should  >not yet be considered a valid test of canonicalization.  >  >r/jboyer@PureEdge.com/2000.10.06/11:52:54  >  >><john>  >>I also notice that your example 4 did not strip out the leading and  >trailing  >>whitespace for that attribute's value.  The example in c14n-20000907 is  >>wrong for not doing that.  >>By saying that your non-validating parser treats it no differently, are  you  >>saying that your non-validating processor does not realize that the  >>attribute is identified as an ID attribute?  >>If so, please see Section 5.1 of the XML specification regarding  >conformance  >>of non-validating processors.  >></john>  >  >All becomes clear. I have a patch for the Apache XML parser,  >I'll clean it up and submit it to their dev list.  >  >><merlin>  >>Neither do I concur with the spec for example 7: I do not see  >>a justification for xmlns="".  >></merlin>  >>  >><john>  >>The justification is that e3 is not namespace qualified in the input, so  it  >>should not be namespace qualified in the output.  The problem is that,  >>unfortunately, the XPath data model represents an empty default namespace  >>with the absence of a node, not with the presence of a default namespace  >>node having an empty value.  Thus, w.r.t. e3, we cannot tell the  difference  >>between <e2 xmlns=""><e3/></e2> versus <e2><e3 xmlns=""/></e2>.  All we  >know  >>is that e3 was not be namespace qualified on input, so we preserve this  >>information on output.  >></john>  >  >>From the spec, wrt element nodes, their namespace axis and emission of  >xmlns="" iff:  >  >1. Yhe element E that owns the axis is in the node-set  >  >Here, element E is in the node set.  >  >2. Element E has a parent element  >  >Here, element E has a parent element.  >  >3. The nearest ancestor element of E in the node-set has a default  namespace  >   node in the node-set (default namespace nodes always have non-empty  >values  >   in XPath)  >  >Here, element E has no ancestor element in the node set.  >  >Thus I do not see why this case qualifies for xmlns="".  >  >Incidentally, it would appear to me that condition 3 implies condition  >2 and thus condition 2 is redundant?  >  >><merlin>  >>I tweaked the XPath on example 7 to suit signature processing.  >></merlin>  >>  >><john>  >>Perhaps you could provide the full XPath transform that you've used.  I'm  >>pretty sure your tweak is fine, but I'd like to see the declaration of the  >>ieft prefix.  BTW, is there some reason why you didn't use the  >subexpression  >>inside the square brackets of example 7?  >></john>  >  >Yes, I was having ID problems. I've fixed them and attached a signature  >using the standard expression.  >  >I now only differ on example 7, as explained above.  >  >Merlin  >        

      Hi all,    The Xpath function normalize-space() seems to provide a fair bit of the  functionality needed to deal with this problem.    If desired, space normalization could be another boolean flag for C14N (like  comment vs. no comment).  We would probably want both as parameters  (currently, 'with comments' is triggered by a separate URI, but we'd want to  account for all combinations without an explosion of URIs).    The change would be that, when rendering a text node, render    normalize-space(string(textnode))    if the normalize space flag is true. It's a little trickier though because  we'd have to keep track of whether we are rendering the content of an  element for which xml:space="preserve" exists and is in the output node-set.    Question:  Do we want C14N to specify this additional functionality, and if  so should it be RECOMMENDED or REQUIRED to implement?    Note that the following simple XPath transform can do most of the work (use  currently posted new processing model):    <XPath>not(self::text()[normalize-space()=""])</XPath>    This expression eliminates all text nodes that contain only whitespace.  This gets rid of whitespace between one start tag and the next, one end tag  and the next and between start and end tags-- unless intervening character  data appears in the text.    Although the function normalizes spaces within such character data, there is  no way to change the string as it appears in the node-set/parse tree.  The  only way to turf that  kind of whitespace is to modify C14N.    Any votes in favour?  Chairs?    John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of John Boyer  Sent: Tuesday, August 29, 2000 12:52 PM  Subject: RE: Insignificant whitespace      Hi Petteri,    The upcoming C14N draft is quite a bit clearer about retention of all  whitespace in character content (except \r characters that disappear due to  line delimiter normalization).  It is both specified in the prose and shown  by example.  In other words, xml:space is an attribute needed by other  applications.    However, I like this as a transform, though I don't know whether the chairs  will approve of adding it at this time.  Chairs?    Seems to me that if you have a DTD, then you can decide what constitutes  insignificant whitespace, which is whitespace found in content models other  than mixed those containing #PCData.  This could get tricky in the second  case, since it's not the whole content model containing a #PCDATA, but just  the parts where #PCDATA is allowed.    However, we cannot count on having the DTD nor on being able to read it at  that level if it were.  Instead, it might make sense to define the transform  in terms of the XPath data model.  Any text node containing only whitespace  could be consider insignificant.    This rule could be constrained by xml:space="preserve" provided the  attribute is in the node-set and contained in an element ancestor of a  'whitespace' text node.    How does this sound to the WG?      John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Petteri Stenius  Sent: Monday, August 28, 2000 10:50 PM  Subject: Insignificant whitespace        Hello,    The issue with whitespace in XML element content has been very briefly  discussed during interop testing. I would like raise this issue on the list,  as I believe many people expect insignificant whitespace to be cleaned up by  the C14N algorithms.    The current specification provides no way for an application to skip or  cleanup insignificant whitespace from a signed XML document before  digesting. However, 'insignificant' comment elements are skipped by the  default C14N algorithm!    I think we could make use of a transformation algorithm that cleans up  insignificant whitespace, the algorithm should obviously detect xml:space  attributes.    Petteri    --  Petteri Stenius                          Petteri.Stenius@done360.com  Done Information, Ltd.                         Office +358-9-5259240                                                   Fax +358-9-52592411  http://www.doneinformation.com/               Mobile +358-50-5506161        

      Hi Merlin,    Actually, you can get the exact characters for each c14n example by  downloading the spec and opening it in a text editor.    Be careful to download it as a binary file.  For example, use IE and you go  to the c14n spec, then right click the link to the c14n spec and choose  'Save Target As...", note that you have to choose 'All files' in the 'Save  as type' popup so that IE will not rewrite the HTML for you as it comes  down.    Inside, there are comments containing the intended XML for each example  (except possibly the use of \r\n line delimiters).  As well, the actual HTML  for producing the examples contains <br/> commands to indicate line breaks  and nbsp; for the specific number of spaces whenever multiple consecutive  spaces are needed.    Finally, note that the input for ex.3.6 requires a version number, and  example 3.4 needs to have the leading and trailing space removed from the id  attribute in the normId element (both previously found by Gregor Karlinger,  and the latter reported more recently by Doug Bunting).  As well, note that  the normId element in 3.4 intentionally doesn't work on validating  processors.  When I tweak this example (soon), I will add a line that  demonstrates almost all the same functionality for validating processors.    Regards,  John Boyer    -----Original Message-----  From: merlin@baltimore.ie [mailto:merlin@baltimore.ie]  Sent: Wednesday, October 04, 2000 11:26 AM  Subject: Re: AW: Status of Implementations      Hi,    I've attached a gzipped tarchive containing the usual suspects:      signature-enveloped-dsa.xml    signature-enveloping-b64-dsa.xml    signature-enveloping-dsa.xml    signature-enveloping-hmac-sha1-40.xml    signature-enveloping-hmac-sha1.xml    signature-enveloping-rsa.xml    signature-external-b64-dsa.xml    signature-external-dsa.xml    Of minor interest is signature-enveloping-b64-dsa.xml which  performs a base 64 decode step over an Object containing some  base 64 data.    In addition, there is a subdirectory containing the c14n stages  of each signature. The largest change was in this aspect of the  spec so this is where I believe most problems will occur.    Major caveat: I've only managed to put a few hours into this,  and my c14n with namespace axis is not happy. Fortunately, my  greatest enemy is XPath and that is not represented here. So,  while I can't say that I think I've tracked the latest specs,  i don't think I'm too far off.    Gregor: I could not verify your examples. Can you fire against  mine and see if the problem is mutual? Perhaps we should compare  c14n offline?    Joseph: I'll try to produce a c14n stress signature. We also  need a bunch more tests of the implicit comment stripping,  etc.    John: Do you have a copy of the c14n examples outside of an  HTML document. I've had a hard time getting some of the weirder  ones to work..    Merlin    r/reagle@w3.org/2000.10.04/11:17:42  >At 16:32 10/4/2000 +0200, Gregor Karlinger wrote:  >> > 1. I never advertised the updated matrix[1], so if  {IBM, Done360, MS,  >> > Baltimore, and anyone else} are at a similar level where exchanging  >>Is there a more detailed test case description than the matrix you refer  in  >>[1]?  >  >Not yet, though I plan to put together a new version of the matrix today or  >tomorrow that references the latest specs. Of course, to fill in the matrix  >one of the implementors needs to send a batch of examples to the list (and  >are automatically archived by the list mechanism) that I can reference and  >others folks can test against and then tell me how to fill in the table for  >their implementation.  >  >>Are there any other interop examples available than those provided by  Merlin?  >  >Not yet. Just need someone who thinks they've tracked the latest specs to  >put their examples out there. If you want to respond and send your  examples,  >I think that'd be great. Kent mentioned he should have his new code by the  >end of the week.  >  >On the Canonicalization front, maybe we could take the examples from the  >spec and put them in a separate directory, then sign every one of them (X  >references for the X files/examples). This would be a really easy way to  >test that spec.  >  >  >__  >Joseph Reagle Jr.  >W3C Policy Analyst                mailto:reagle@w3.org  >IETF/W3C XML-Signature Co-Chair   http://www.w3.org/People/Reagle/  >        

      Yes, right, forgot about name().  I discarded that function a long time ago  because the spec does not say what I wanted it to say.  name() does not  return the QName, which is what I need for serialization.  The spec says  that implementations can allow name() to return the QName, or they can  return something other than the originating QName if there are multiple  namespace prefixes mapped to the same URI in the namespaces provided to the  evaluation context.    This is not a well-defined 'function', but I don't want to get into XPath  bashing right now since they most likely were forced into the same corner I  see the XPath transform being pushed into, which is that some have created  dumb (I mean DOM) parsers that forget the namespace prefix. Why? Why? Why!    This is a great part of why I specified our own parse() function.    So, the disappointing reality is that there remains no good reason to keep  serialize() as a function because there is no hope of obtaining the original  namespace prefix if the wrong input parser was used.    Moreover, this means that unless one carefully constructs one's signature  transforms so that multiple namespace prefixes do not resolve to the same  URI in the set of namespaces available to the XPath element, one will be  required to do a c14n post-processing to guarantee the same result from all  implementations.    Well, perhaps it's not the end of the world. If one is careful, one can  still avoid c14n.    I guess this warrants another write-up that describes the serialization but  omits the fact that it appears as a function.  This will clear up the  remaining objections expressed so far.  It is not a major change, so I  should be able to squeeze this into my Thursday schedule...    John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com            -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Jonathan Marsh  Sent: Monday, March 27, 2000 4:56 PM  Donald-LDE008; TAMURA Kent; Christopher R. Maden; Ed Simon  Subject: RE: Enveloped signatures and XPath      name() on an element or attribute gives you back a QName for the element.  The prefix can be extracted from that.  The local-name() or name() of a  namespace node gives you a prefix as well.  Since this information is  available through XPath, it is reasonable to assume that an XML parser able  to expose the XPath data model retains adequate prefix information to inform  the serializer.    > -----Original Message-----  > From: John Boyer [mailto:jboyer@PureEdge.com]  > Sent: Monday, March 27, 2000 4:37 PM  > To: Jonathan Marsh; IETF/W3C XML-DSig WG (E-mail)  > Cc: Martin J. Duerst; James Clark; Joseph Reagle; Eastlake  > Donald-LDE008; TAMURA Kent; Christopher R. Maden; Ed Simon  > Subject: RE: Enveloped signatures and XPath  >  >  > Hi John,  >  > If I have the following markup,  >  > <xyz:e xmlns:xyz="URI"></xyz:e>  >  > How do I ask XPath for the xyz part of e?  I seem to be able  > to find out  > that the element has a local name of e and a namespace uri of  > URI, but in  > order to serialize the element, I need to have the xyz.  What  > function or  > node tells me this?  >  > John Boyer  > Software Development Manager  > PureEdge Solutions, Inc. (formerly UWI.Com)  > Creating Binding E-Commerce  > jboyer@PureEdge.com  >  >  > -----Original Message-----  > From: Jonathan Marsh [mailto:jmarsh@microsoft.com]  > Sent: Monday, March 27, 2000 3:18 PM  > To: 'John Boyer'; IETF/W3C XML-DSig WG (E-mail)  > Cc: Martin J. Duerst; James Clark; Joseph Reagle; Eastlake  > Donald-LDE008; TAMURA Kent; Christopher R. Maden; Ed Simon  > Subject: RE: Enveloped signatures and XPath  >  >  > > -----Original Message-----  > > From: John Boyer [mailto:jboyer@PureEdge.com]  > >  > > <john>  > > Right.  The exact point I'm trying to make is that  > > information needed for  > > serialization (specifically, the namespace prefix) is not publically  > > available.  >  > Yes it is.  It's in the original document as attributes or namespace  > information items, and is exposed through the XPath data  > model as namespace  > nodes.  Since you own the document passed to XPath, there is  > nothing it  > knows that can't be derived publicly.  >  > >  However, we can deduce from the XPath  > > specification that the  > > required information (e.g. namespace prefix) is available  > > privately to the  > > XPath evaluator.  It must be available since otherwise the  > > XPath evaluator  > > would be unable to do anything with the initial namespace  > declarations  > > created during evaluation context initialization.  >  > It is available to the XPath evaluator because it is in the  > document.  It is  > passed to the XPath evaluator through the context node.  You  > still have this  > information outside XPath.  >  > > Since the required information is available internally, AND  > > certain existing  > > XPath function must be able to access that information, we  > > can deduce that  > > the information is available to XPath functions.  Hence,  > > since serialize()  > > is defined as an XPath function, it must be able to access namespace  > > prefixes and document order positions, whether or not they  > > are in the public  > > data model exposed to XPath expression authors.  > > </john>  >  > The serialize function has available what is passed into it  > as arguments.  > If it is a nodelist, the function can follow these pointers  > back to the  > original document, and get this information.  >  > > > Also, I think that serialization is the one thing that you  > > > would not expect  > > > an XPath engine to provide (unlike parsing).  > >  > > I do not expect an XPath engine to provide parsing.  > > Microsoft's doesn't, as  > > an example.  > >  > > <john>Microsoft has an XPath engine.  Firstly, tell me where  > > it is so I can  > > look at it.  >  > IE5 shipped with an "XSL Pattern" engine in MSXML - see the  > selectNodes and  > selectSingleNode DOM extensions.  The latest MSXML technology  > updates this  > to an almost complete subset of XPath.  Docs and downloads  > can be found at  > http://msdn.microsoft.com/xml.  >  > > Is it open source?  > No.  >  > > Second, regardless of whether it provides a  > > parser in the concrete sense, it must be coupled with a  > parser in the  > > abstract sense.  >  > Indeed XPath evaluation is a service provided through DOM extensions,  > specifically as methods on DOM Node objects.  The inverse  > would also be  > possible - an XPath object that was given various context  > nodes.  Your spec  > should not unduly constrain the use of either of these types of  > implementation.  >  > Which XPath processor are you using to evaluate this design?  > I'm really  > only familiar with a small class of processors - Microsoft,  > Oracle, and to a  > lesser extent others within XSLT implementations.  >  > >  You must initialize the evaluation context, you must  > > provide a context node, position and size, the context node,  > > position and  > > size together form a node-set, and the XPath evaluator must  > be able to  > > derive from that node-set the namespace prefixes and the  > > document order  > > positions.  Regardless of where you got the processor, you  > have had to  > > create enough data structure SOMEHOW to support the described  > > operations.</john>  >  > Yes, which brings up a nasty point I hadn't realized before.  Our  > implementation does not currently allow you to pass in any  > function bindings  > (except when used within XSLT).  So I wouldn't be able to build a full  > implementation of XPath transforms on MSXML without some  > pretty painful  > hackery.  It would be much easier if no extension functions  > were needed.  I  > wouldn't put too much weight on this, but it may be evidence  > of a class of  > simple XPath processors that couldn't be used for XPath transforms.  >  > > Likewise, my XML processor may indeed provide a serialization  > > feature.  Microsoft's does, for example.  I'm not able to use  > > the existing  > > functionality that may be provided by a processor because a specific  > > implementation strategy has been prescribed - the serialize()  > > function.  > > Now, I don't believe the Microsoft serializer IS quite  > > adequate because your  > > constraints are too severe - but that's a separate potential issue.  > >  > > <john>If your serialization function were adequate, then I  > > wonder why you  > > can't call it from your serialize() implementation?  > > As to its adequacy, if the tool doesn't work, then don't use  > > it.  You can  > > only reuse code in  a new application if it fits the  > > application.  However,  > > the serialization described in the spec is QUITE easy to  > > implement, so I  > > cannot fathom why it would be a 'potential issue'.  > > </john>  >  > I will defer this to another thread.  >  > > As I indicated previously, I would not expect an XPath  > > implementation to be  > > optimized for returning the huge strings that could result from the  > > serialize() function.  And as I indicated previously, the  > > necessity/danger  > > of user intervention on the serialized string has not been  > > justified.  Even  > > the necessity of a two-step process of serializing and then  > > converting to  > > UTF-8 gives me pause for thought - it looks like I might need  > > two separate  > > serialize() functionalities to obtain maximum performance.  > >  > > <john>  > > The need for serialize() has been justified on several  > > levels.  Firstly,  > > there is no security threat in allowing user intervention on  > > the serialized  > > node-set.  >  > My term "dangerous" was clearly a poor one in this context  > :-)  I meant not  > that a security risk was imposed, but that it would be quite  > easy to damage  > the well-formedness of the XML document.  Manipulating XML  > through string  > manipulation is unquestionably more prone to error than  > manipulating it  > through structural methods.  You can tell the user "well,  > you're stupid and  > you broke it" but unless there is a compelling reason to  > ALLOW him to break  > it, it seems self-evident that it's best not to.  >  > > For you to argue otherwise would require that you  > > explain why it  > > is significantly different from writing a different XPath  > > expression. The  > > XPath expression is signed, so its modification of the  > input follows a  > > well-known behavior that we can prove is the correct behavior  > > leading to the  > > given message digest.  > >  > > Secondly, I've justified it from the specification  > > standpoint.  By defining  > > the behavior as a function library addition to XPath, the  > > result of the DSig  > > WG's work can continue to be viewed as an application of  > > XPath, not as an  > > extension of XPath.  >  > XPath transforms is an application of XPath which is  > comprised of several  > parts:  > - parsing the document from a stream  > - identifying the nodes to keep/trim using an XPath  > - trimming the tree  > - serialization of the result  >  > Note that the last two are described as coincident by the serialize()  > function.  This is a perfectly good application of XPath.  Providing  > serialize() does not make it a better application of XPath,  > any more than  > removing it would make it less of an appropriate XPath application.  >  > If somehow it were shown that the serialize() function is  > necessary to make  > XPath transforms an application, what about the case when it  > is performed  > automatically?  Does somehow this use constitute an XPath  > extension?  The  > logic of your assertion totally escapes me.  >  > > Thirdly, I've justified it on technical grounds.  There is  > information  > > required for serialization that is not available in the  > > public information  > > but which MUST be available to the implementations of certain XPath  > > functions.  >  > > Please have another look at how XPath handles the namespace  > > declarations in  > > the evaluation context.  If I have misread something, please  > > let me know,  > > but I did ask for clarification on this point, and noone  > > (including James  > > Clark) has refuted this point yet.  > >  > > As for two serializations, that's not happening.  The first act is a  > > 'serialization' of the node-set.  The second action is a character  > > transcoding to UTF-8.  My original assumption was that  > > implementations would  > > not lose track of the input document's encoding.  This was  > > based on the fact  > > that I specified a parse() that would do this.  You  > > specifically along with  > > others wanted to get rid of the parse().  The natural result  > > is that I can  > > no longer claim that the input document stays in the same  > > encoding.  Since I  > > also lose the BOM, UTF-8 is the only viable alternative.  > >  > > serialize(), however, cannot output UTF-8 because it is an  > > XPath function,  > > which must output a string.  The details of what that means  > > are specific to  > > the XPath implementation itself.  Transcoding to UTF-8 is not  > > an action that  > > fits within XPath.  > > </john>  >  > My concern here is that if serialize() is called automatically, I can  > envision a single step in which the document is serialize  > directly to UTF-8  > as a performance gain.  When serialize() is called  > explicitly, it looks like  > a two-step process is needed - serialize into a string to be  > returned from  > the XPath engine (presumeably Unicode) and then a conversion  > to UTF-8.  I'm  > not sure if this is a real issue, but it does appear that there may be  > difference in optimization potential and thus performance  > between the two  > uses.  Users would need to be aware that explicit use of  > serialize() may be  > slower than automatic use - another small argument against  > including it.  >  > >  > >  > > >   So another  > > > justification for  > > > adding serialize() as a function is that we are adding DSig's key  > > > functionality using the XPath-defined extension mechanism  > > > (function library  > > > modification).  This maintains the property that dsig is an  > > > application of  > > > XPath, not something different that happens to use the XPath  > > > expression  > > > syntax.  > >  > > I still don't understand this argument either.  If the  > > serialize function  > > can be called automatically for nodesets as you prescribe,  > > this would seem  > > to indicate that there is not a necessity to expose it to the  > > user in all  > > cases.  If you are not using the prescribed XPath extension  > > mechanism in all  > > cases, how does this contribute to maintaining "the property  > > that dsig is an  > > application of XPath"?  The output of the XPath processor is  > > not the end  > > result of the transform in all cases.  Doing more or less  > > back-end work is a  > > pretty abstract distinction.  > >  > > I feel that it is already an appropriate application of XPath  > > to locate  > > nodes in an XML document.  Going beyond this to serializing  > > within the XPath  > > expression itself doesn't contribute to the impression that  > > dsig is an XPath  > > application.  In fact, my gut feeling is that it is abuse  > > because it appears  > > to short-circuit the primary XPath return type of nodeset.  > >  > > <john>The specification very clearly points out that the  > > XPath can return a  > > node-set.  However, to run a digest algorithm, we need a  > > string.</john>  >  > This is true but doesn't address my point.  I think it's  > great that a user  > can return a nodeset and it'll get serialized automatically.  > In fact, it's  > so great I can't see why anyone would ever need to bother with calling  > serialize() explicitly.  >  > > The redundancy argument still applies.  I can call the  > > serialize() function,  > > or not, with the same result.  Without some use cases  > > justifying the need  > > for the long form, the short form looks perfectly adquate to me.  > >  > > Note that there is no standard mechanism defined by XPath to "call"  > > extension functions outside of the XPath expression.  The XSLT spec  > > carefully uses descriptions like "the resulting object is  > > converted to a  > > string _as_if_ by a call to the string function" (emph  > > added.)  A similar  > > approach would be appropriate in describing XPath transforms.  > >  > > I don't see a concrete problem that serialize() solves.  I  > do see some  > > concrete reasons not to have it - performance, implementation  > > flexibility,  > > eliminating redundancy, simplified syntax.  > >  > > <john>Sure, as long as you can guarantee that the moment we  > > yank serialize,  > > we aren't going to have half a dozen different people writing  > > in to say that  > > "my-favorite-XPath-engine doesn't have access to namespace  > > prefixes" or  > > "my-favorite-XPath-engine makes it really inefficient to do  > > document order".  >  > First of all, I can't guarantee people won't complain.  I can't even  > guarantee their complaints won't be justified.  I only can  > state that I'm  > not aware of any implementations that would have problems  > with this, and  > it's hard to imagine how they could and still conform to  > namespace nodes in  > the XPath data model.  You have not previously presented  > evidence of such  > implementations or even their potential.  My goal is to  > enable a wider range  > of XPath engines to be used, and I would welcome more details about  > constraints on specific implementations.  >  > > Also, I do like the idea of being able to tweak the data in  > > certain ways  > > once it has been serialized.  One could wrap a root element  > > around a list of  > > elements, one could prepend some simple material to make the  > > result of the  > > transform more usable to certain software.  > > </john>  >  > Structural manipulations like this should be left to XSLT,  > which is designed  > to perform exactly this type of operation without damaging  > well-formedness  > or the meaning of the document.  >  > In summary, I still haven't found even one of your arguments  > for exposing  > serialize() to the user compelling.  Since we aren't converging on  > solutions, perhaps we should focus instead on converging on a clean  > statement of our different positions?  There appears to be  > very little in  > the way of hard technical arguments either way, so a win/loss  > outcome seems  > unlikely.  >        

      I actually think we need to remove the comment about BOM *and* not put in a  comment about surrogate pairs.    There does not seem to be any such thing as a need for a BOM for UTF-8.  As  for surrogate pairs...  RFC2279 [1] clearly states that    A) The only correct way to convert from UTF-16 to UTF-8 is through UCS-4  B) The only correct way to convert from UTF-16 to UCS-4 is to fix the  surrogate pairs.    Moreover, RFC2781 [2] clearly states how to fix the surrogate pairs.  It  does not seem necessary to add more text that tells the implementer how to  transcode.  This job has been done by these other RFCs [1,2], both of which  are referenced in the XML Dsig WD.    [1] www.ietf.org/rfc/rfc2279.txt  [2] www.ietf.org/rfc/rfc2781.txt    John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>          -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of tgindin@us.ibm.com  Sent: Wednesday, August 23, 2000 10:39 AM  Subject: Re: UTF-8 and BOM           If we retain wording excluding BOM's from UTF-8, as we currently have  it, I think that we should exclude surrogates as well.       The current text in section 6.5.1 reads "converts the character  encoding to UTF-8 (without any byte order mark (BOM)) ", and corresponding  text in section 7 reads "that coded character set is UTF-8 (without a byte  order mark (BOM))"  The new text should probably read "... UTF-8 (without a  byte order mark (BOM) and with surrogate pairs converted to UCS-4 before  conversion to UTF-8)" in both of these places.  I realize that RFC 2279  (not 2379) explicitly requires surrogate conversion while it fails to  mention BOM's for some reason, but the two issues are similar and many  implementors do not understand the surrogate issue.  The wording about  surrogates in versions 2.0 of the Unicode standard is actually somewhat  similar to the wording about the "reversed byte order mark" U+FFFE.              Tom Gindin        

      <martin>  Not necessarily, but that may well happen. We already see  in the DSig group that people want to use the DOM, and  don't want to keep around e.g. whether an attribute was  single-quoted or double-quoted. As we move up the semantic  ladder (well, it feels more like a very flat slope, but  that's a different issue), exactly the same will very  easily happen one step higher.  </martin>    <john>  Actually, I'm pretty sure we would argue that if you want to schema  normalize an XML document, then you would need another transform for that.  Whether we define such a transform in this version of the spec is a decision  of the chairs.    John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com  </john>      >I appreciate this might  >happen with character code mappings, but I tend to view schema's as  >constraints on permissible values, and not a processor (in the vein of  >infoset/C14N/DOM).    Constraints on permissible values is one function, and probably  the most important one the way the spec is written. But for datatypes,  the 'infoset' aspect is already there, and C14N is what we are  just discussing here, and would be very very easy to add at this  point in time compared to having to start another group,...  in a few months. Something like DOM is not done yet, but  conversion from data to XML streaming and back is an  important application of XML Schema, probably the most important  one.      >(For instance, just because a schema permits an  >unconstrained string, one wouldn't presume it would change the string ...?)    There is a clear difference between changing the value,  and producing a different lexical representation for the  same value. Changing from 0 to false is the later,  changing the string is the former.      >  >- If there is some way to express that elements of the same type  >  >   have to appear in a certain order (don't know whether this is in  >  >   the spec or not), this will also help to create schemata that can  >  >   be used to validate data and then feed that data into XML DSig  >  >   without any or without much processing.  >  >  >  >In other words, try to make sure that for appropriately designed  >  >XML Schemas, no additional 'data canonicalization' step is necessary  >  >to sign some data.  >  >I don't quite follow. Element of the same element type? Can you give an  >example?    Well, let's assume you have a list of students, with student id,  birthday, and a boolean for 'male' (gender). The task is to  produce a signable XML document from this data. In order for  the sign to be reproducable, the XML document has to be exactly  the same for the same data. Assuming that the structure looks  something like  <student><id>...</id><birthday>date</birthday><male>boolean</male></student>  ...  ...  and is described as an XML Schema, the 'missing pieces' for the  above task are to make sure the students are always in the same  order (e.g. by id) and that date and boolean are always in  a canonical form (and of course that the underlying XML is  in C14N).    Probably the above is not the most appropriate example, but I hope  you get the idea.      Regards,  Martin.        

      Hi Paul,    Good, I am glad we agree on so much.    It seems we agree XPath is currently missing the following requirements:    A) the parser that provides the XML document to XPath via the initial  context node must provide the document in the form defined by infoset.    B) the infoset must provide absolutized URIs.    My earlier assertion that applications were free to do or not to do URI  absolutization was based on the assumption that one could use any XML  processor to construct the initial context node-set (because the above  requirements are not stated in XPath).  Because, as we agree, the XPath  evaluator has no access to a base URI, it has no ability to enforce the  absolutization, which is why the implementations I've encountered (not from  my company) do not do it.    Most importantly, though, I am sure you are aware that the latest infoset  draft (20 dec 1999) does not require absolutized URIs to be available.  The  infoset is free to provide either the literal string or the absolutized URI.  Hopefully this will change because, as it stands, I prefer Xpath's choice to  always absolutize.  Every place in infoset where it says 'implementations  can do one thing or another and we won't nail down which' makes it that much  harder to create a canonical form that can be fed to a digest algorithm.    John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com      -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Paul Grosso  Sent: Thursday, June 08, 2000 5:08 PM  www-xml-linking-comments@w3.org; Daniel.Veillard@w3.org; connolly@w3.org  Subject: RE: XML Base and XPath absolutizing of URIs      [I removed xml-uri from the distribution.]    At 16:33 2000 06 08 -0700, John Boyer wrote:  >Yes, absolutely no problem with XBase. ...    >As for whether XPath defines a method for specifying a base URI, it does  >not.    You are right--I misread you to say that XPath doesn't specify  an absolutization algorithm, and I suggested it does by reference  to 2396.  Also by same reference, XPath assumes 2396 ways of  determining the base URI, but you are correct that it does not  specify any way to do so via the document content (per section  "5.1.1. Base URI within Document Content" of 2396).    >[XPath] says that a namespace declaration can be a URI reference, and  >that URI-references are defined by RFC2396.  The conversion from relative  to  >absolute URIs is claimed to occur during namespace processing. The  >namespaces spec does not define this!    You are right, it would be the Infoset that specifies this, and  the Infoset is stuck right now.    >Moreover, the problem with claiming  >that RFC 2396 defines how to do this is that RFC2396 only describes the  >rules for establishing a base URL for a document and how to convert from  >relative to absolute URI *given a base URL* (sections 5.1 and 5.2  >respectively).  There is nothing to say how an Xpath evaluation is supposed  >to receive the base URL.    I'm not sure what it means for XPath "to receive the base URL".  XPath works on a data model that was described within XPath  only because the Infoset wasn't yet ready, but it was supposed  to match that of the Infoset.  The right thing to happen is for  the absolutized URI to be in the infoset and for XPath to work  off the infoset.  Then XPath doesn't need to concern itself  with this issue at all.    >Put another way, consider the following quote from the XPath  Recommendation:  >  >"Expression evaluation occurs with respect to a context. XSLT and XPointer  >specify how the context is determined for XPath expressions used in XSLT  and  >XPointer respectively. The context consists of:  >  >a node (the context node)  >a pair of non-zero positive integers (the context position and the context  >size)  >a set of variable bindings  >a function library  >the set of namespace declarations in scope for the expression"  >  >Where is the base URL in this input specification?    No where.  It shouldn't be.  Rather, "the set of namespace declarations  in scope for the expression" should all be in already absolutized form.    >The only thing I can think of is that software external to an XPath  >implementation must know the base URL using the rules established by RFC  >2396.  Further, since there is no way to communicate the base URL to XPath,  >the external software must apply the relative-to-absolute conversion rules  >defined in RFC2396 to the data structures it creates in support of setting  >up the context node.  Therefore, by the time you get to code that is  >actually part of the XPath implementation, the namespace absolutization has  >already been done by the external code, and the XPath implementation just  >treats them like strings.    Precisely.    >Conclusion: Since there is no way defined by the XPath spec to provide the  >base URL as part of the initial evaluation context, there is no way for the  >XPath evaluation to enforce absolute URIs.  They're just strings to the  >XPath evaluator.    Correct.    >Thus, the external, application-dependent code that must  >absolutize can also choose not to do it.    Huh?  It's not application-dependent code, it would be the  underlying parser layer that generates the infoset, and it  can't choose how to do it, it has to do it however we decide  it gets done.    >Since XPath is in violation of the  >namespaces spec anyway for trying to absolutize URIs, the feature should be  >removed by an erratum.    This is the issue up for discussion on xml-uri.  What XPath is doing  wrong is assuming that it has anything to do with absolutization  instead of just relying on what's in the Infoset.  (But since XPath  was written before the Infoset, this isn't surprising.)    >Alternately, XPath could be modified by an erratum  >to indicate either that the base URL is provided by XBase or as an  >additional component of the evaluation context.    XPath should never need the base URI.    >One way or the other, something about XPath needs to be changed.    Once this namespace question is resolved, the Infoset can be  completed, and then XPath should probably be rewritten in terms  of the infoset.    paul        

      Hi Chris, Joseph and all,    Actually, I think both Chris and Joseph are right; they are coming from  different points of view that are not irreconcilable.    Chris is coming from a viewpoint of creating a signing ceremony that  includes capturing the intent of the signer.  To take one of Todd Vincent's  examples, Todd could communicate that despite what is said on the face of  the document, his intent in signing is only to achieve a certain level of  realism in a student training scenario and is not intended to legally  obligate him to pay anything.    Joseph's viewpoint is that it is the application that defines what  constitutes appropriate intent.  For example, a check may not be valid  unless signed by N signers.  A particular signer may intend to authorize a  check, but the application is aware of the need for authorization from  multiple parties in other roles.    It is helpful to consider this scenario from the relying party's viewpoint.  An application receives a signed check.  The application knows what  constitutes an authorized check, so it goes to the check element and finds  the 'pointers' to the requisite signatures.  The 'pointers' in Joseph's  example happen to carry the additional information of what 'intent' was  chosen by the signer (approval).  Since approval is what the application  requires, the application then calls upon core behavior to verify the  signature(s) before processing the transaction.    So, it is clear that 'pointers' are required to get from the document to the  signatures, though they may be implicit, esp. in the case of enveloped  signatures within a document.  It is also clear that the rules regarding the  semantic interpretation of intent (e.g. its sufficiency for proceeding with  a transaction) are application specific and belong in the document.  But the  location for storing the actual declaration of intent *depends on who is  providing the mechanism by which the signer's intent is specified*.    It is helpful to think about this from the standpoint of an application  (such as an e-check system) that integrates with a signature generation  engine.  The application provides the face of the document and the face of  the document may explicitly indicate what the signer is doing by signing  (e.g. "I agree to pay X").  Upon hitting the "Sign here" button, the  application turns control over to the signature generation engine, which may  then allow the signer to specify some intent (e.g. typing "Not really!" into  an edit field).    The signature generation engine is one application that is only aware of the  signature element.  It is designed to qualify that signature through  signature properties.  But to assert that a 'secure' application would  integrate with such an engine without taking its properties into account  would be ludicrous.  The application could    1) turn off the signature engine's generation of properties if the  application knows that it is providing the intent declarations, or    2) account for the signature engine's method for specifying signer intent  (which could get complicated if the signer is given a free-form text box to  type whatever they like).    In the latter case, the application is usually allowed to parameterize what  the signature engine's intent message will say and what the signer's options  are (e.g. the user can click OK or click Cancel in response to a specific  message, rather than being given the freedom to type any contradictory  message they like).    And if the application is already on the hook for parameterizing a given  signature engine, then the application can certainly deal with finding the  intent results of a signature in a signature property subelement.    John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com      2: Joseph's example, in which the signed data contain an <approved by  ="xxx"> element referring to the signature, has I think two drawbacks,  neither of them fatal.    2.1: It will be hard work to allow arbitrarily many signatures to be added  to a document using this approach. Subject to what John Boyer has to say,  it looks to me as if a document will need to be specially designed to allow  multiple signatures to be added.    2.2: Information about the signature logically belongs with the signature.  Forensic examination of signatures will be complicated by the need to  consult a plurality of resources in different locations in order to  reconstruct the evidence of a single historical event.    3: It is not the application which defines the meaning of a signature. The  application can only define whether the signature _can have_ any semantics.  It is the intent of the signatory which determines what a signature  actually means. (For more on application semantics, see e.g.  http://www.uniroma3.it/kant/field/chinese.html.)    For these reasons I think that Joseph's proposal is actually more untidy  than making use of the SignatureProperties. Perhaps he would like to point  out where I'm going wrong.    CPK Smithies  PenOp        

      Hi all,    The XML Link WG has decided that our definition of here() was useful since  it allows one to distinguish which attribute (or block of text) contained  the actual XPath being evaluated, which could've been a source of ambiguity  under the current XPointer draft [1].    [1] http://www.w3.org/TR/xptr    Therefore, our recent change in the XPath serialization spec to the function  name this() should be changed back to here().    Thanks,  John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com      -----Original Message-----  From: Eve L. Maler [mailto:Eve.Maler@east.sun.com]  Sent: Friday, June 02, 2000 3:31 PM  Subject: Re: XPath Serialization      John and Michael,    The XML Linking WG has discussed the issue of here(), and has agreed to  change the definition so that it returns the node that the XPointer is  actually in.  We hope this satisfies your concerns.    Best regards,    Eve  --  Eve Maler                                    +1 781 442 3190  Sun Microsystems XML Technology Center    elm @ east.sun.com        

      Hi Martin and group,    I received a letter today from Jeff Cochran (JCochran@docutouch.com)  regarding a tweak that would appear to be needed regarding c14n and xml  signature.    The I18N group asked us to include a sentence along the lines of "REQUIRED  to use Normalization Form C [NFC] when converting an XML document to the UCS  character domain from a non-Unicode encoding".    Apparently this is not exactly what is meant since UCS-4 character planes  outside of the BMP are technically non-Unicode.  The point Jeff makes is  that he doesn't know whether to apply NFC to UCS data that appears outside  of the BMP.    Question:  Should the statement be rewritten?  If so, how?    Thanks,  John Boyer  Team Leader, Software Development  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Martin J. Duerst  Sent: Friday, November 24, 2000 6:17 PM  Subject: Fwd: I18N problem in XML canonicalisation      Chris Lilley just pointed out the following problem  in C14N. I think this at least has to be explained  much more clearly in the notes.    >http://www.w3.org/TR/xml-c14n#Example-UTF8  >  >Demonstrates using *two* NCRs foa single UTF-8 character (because it uses  >two bytes in UTF8 !!!    It's not really NCRs. It's a special notation to stand in for byte values.      >I suspect you may have a problem with that..... given that even surrogates  >use a single NCR not two. Also, its not clear the result is even  >wellformed!    There needs to be a much better note to make very clear that (different  to the other examples), this example is not really intended to be XML  and cannot be used directly in a test. It would also be advisable  to provide an actual file that contains the real bytes, or to point  to it if that's already around.    Regards,    Martin.        

      Hi TAMURA-san,    Actually, you didn't misunderstand.  The intent of URI="#something" is to  render the element identified as 'something' plus all of its descendants, as  well as their namespace and attribute nodes.  However, the corresponding  XPath that creates the proper node-set is a little harder because we are  using absence from the node-set to indicate omission from the output.  I  have not found a way in XPath to constrain the evaluation to the nodes at or  below the identified element without losing the namespace and attribute  nodes.  I would like to say something like:    id("something")/all-descendants-or-self::node()    but there is no such axis.  Further, there are syntactic limitations on  where the subexpression (//. | //@* | //namespace::*), which means all nodes  at or below the context node, can be placed.  For example, the following  appears to be illegal:    id("something")/(//. | //@* | //namespace::*)    The only way I've come up with so far of doing this is to scan every node of  the parse tree looking for nodes with ancestry (or self) that includes the  identified element.  The resulting expression is quite inefficient, but it  does the job:    (//. | //@* |  //namespace::*)[count(ancestor-or-self::*)=count(id("something") |  ancestor-or-self::*)]    John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com      -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of TAMURA Kent  Sent: Thursday, May 25, 2000 1:02 AM  Subject: Re: XPath Serialization        In message "XPath Serialization"      on 00/05/23, "John Boyer" <jboyer@PureEdge.com> writes:  > 5) There was some confusion about how to process the node-set.  I fixed  this  > by commenting that nodes are not processed more than once.  As part of the  > processing of an element E, its namespace declarations, attributes, and  > descendants are processed, so they are not visited again when E is  finished  > processing.    I misunderstood as all descendants were rendered ;-)    XPath serialization is used to serialize an element pointed  "#id-name" (in 4.3.3 the third paragraph.)  So, the following  dsig:Reference element digests only '<purchase xmlns=""></purchase>'.  Is this right?      <SignedPurchase>    <purchase id="ORDER1">      <item>ThinkPad</item>      <price>195.00$</price>    </purchase>      <dsig:Signature xmlns:dsig="...">      ....    <dsig:Reference URI="#ORDER1">      <dsig:DigestMethod ..../>      <dsig:DigestValue>...</dsig:DigestValue>    </dsig:Reference>     ...    </dsig:Signature>  </purchase>    --  TAMURA Kent @ Tokyo Research Laboratory, IBM        

      Hi Petteri and David,    To be honest, my current acceptance of the namespace propagation as done by  XPath was not based on simply accepting default behavior.  I gave it a very  great deal of thought.  Moreover, in accepting the current behavior, I was  mindful of the desire to perform whole-document serialization in a one-pass  fashion, so I would be quite interested to know why you (Petteri) think the  XPath version of namespace context identification cannot be serialized in a  single pass.  To me, this seems to me to be as easy as following the  namespace rules in the January c14n spec, which you say can be serialized in  a single pass.  But before I get into that any further...    I would point out that, in David's statement about the January spec being  easier because it didn't care about prefixes in attribute values, I believe  he means easier than Petteri's suggestion, not easier than the current c14n.  The January spec did not care about prefixes in attribute values and did  things that sometimes broke them.  The new spec does not break them, but it  also does not really care about them, i.e. attempt to detect their  existence, which would be quite impossible without an application context.  In both the January spec and the current specs, namespace prefix references  that appear in attribute values or element character content are simply more  character data to be written out.    Also, Petteri, in the example you gave below, yes it is true that the expr  value both is valid XML and does make reference to an undefined namespace  prefix.  However, an Xpath with an undefined namespace prefix would generate  an error within the application attempting to use it.  More to the point,  though, the example does not seem to be a counterexample of David's point.  David's point is about namespaces that are in scope, yet there would be no  way to identify that its declaration is needed.  In other words, the point  is about attribute values that carry XPath expressions that used to work  before canonicalization and don't work after canonicalization.    It is a non-goal of the current c14n to say d1 and d2 are logically  equivalent if and only if c14n(d1)==c14n(d2).  However, it is the intent of  the current c14n is to say:  if c14n(d1)==c14n(d2), then d1 is logically  equivalent to d2.  Otherwise, there would be no point to c14n, especially  for dsig.  Let d1 be a document containing a working XPath that no longer  works in c14n(d1) because we omitted a namespace declaration that did not  appear to be used.  Let d2=c14n(d1).  Now, clearly c14n(d1) == c14n(d2), so  we expect that d1 and d2 are logically equivalent, but they aren't because  the Xpath works in d1 but not d2. This is the same argument against  namespace prefix rewriting.  I will add a section to the appendix to explain  why this change was made, too.    Despite this problem with your particular proposal, I am quite sympathetic  to your cause, Petteri, and thought about other alternatives that would  work.  Let's begin with just doing something that works for a whole document  (sans comments of course).  So, ignore the notion of document subsets for a  moment.  Also, ignore the default namespace declaration for the moment, and  let's focus on actual namespace declarations.  If a given element and its  parent both have the same namespace declared to be equal to the same URI,  then the namespace declaration could be omitted from the child.  Since we  perform a standard depth first descent of the parse tree, this means that we  could retain all relevant namespace declarations, but still only use local  operations-- we need only consider the namespace context of an element and  its parent.    The problem is not much harder when you add the complexity of the default  namespace declaration.  Whether it's empty or not, the namespace context  indicates its value in some way, so if the default namespace of an element  differs from its parent (whether empty or not), then render a default  namespace declaration for the element.    The case for document subsets is not much harder, except we would replace  the notion of parent with the notion of ancestor *in the node set* with  Finally, when dealing with document subsets, one is certainly using XPath,  and the problem is not really too hard.  For example, given a namespace node  N in the resultant node-set, we could do the following:    1) Find the element E that owns N (even if it is not in the node-set,  however weird that might be).    2) Find the nearest ancestor A of E that is in the node-set.  If A doesn't  exist, then output N.  If A exists in the node-set and it has a namespace  node N(A) *that is in the node-set* which declares the same namespace AND  assigns it to the same URI, then omit N from the output.  Otherwise, output  N.    So, as you can see, I've been trying to think about getting rid of  unnecessary namespace declarations.  However, there seems to be enough work  involved in trying to figure out whether to print a namespace node (esp. in  the document subset case) that it did not seem to worthwhile to complicate  the spec.  In particular, one must still maintain the whole namespace  context for each element as one passes through a document.  I will reassert  that this can be done in a one-pass fashion given space linear in the size  of the namespace context, which should not be a problem even for the most  rudimentary of devices capable of processing XML.  This is why I've retained  the default XPath namespace propagation feature.    This is not actually a complete account of my thinking on this issue, but  I'll end this now unless there is an expressed need for me to continue.    John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com      -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Petteri Stenius  Sent: Thursday, June 15, 2000 11:19 PM  Subject: RE: Updated c14n Spec        You assume that the XML document constructor has properly declared all  namespaces that appear in XML attribute values. Of course there is nothing  an XML processor can do to verify this. A short sample:    <doc>  <reference expr="foo:bar"/>  <foo:bar xmlns:foo="uri"/>  </doc>    This is completely valid XML and the namespaces axis of the 'reference'  element is empty even if the attribute value refers to a namespace. One does  not have to declare the namespace at the 'doc' element level, and if this  document was constructed using DOM then the above XML representation would  most likely be the result.      Petteri      > -----Original Message-----  > From: David Blondeau [mailto:blondeau@intalio.com]  > Sent: Thursday, June 15, 2000 12:06 AM  > To: w3c-ietf-xmldsig@w3.org  > Cc: XML DSig  > Subject: Re: Updated c14n Spec  >  >  > > I need to read the attributes of a element anyway, and I  > also need to sort  > > them using the attribute name and the namespace uri as sort  > keys. This is  > > the minimum requirement in all cases.  > I just wanted to show that your suggestion was worst than the  > one in the  > draft because you have to be carefull about namespace prefixes used in  > attributes values. Your suggestion was to put  namespaces  > only when they are  > used, my question is then: how do you know a prefix is used  > in an attribute  > value?  > For that, you need to know all the prefixes in scope so you  > need to walk on  > the tree to get the namespaces prefixes, and then do a really  > difficult  > parsing job...  > No matter how you are doing it, you need all the namespace  > declarations in  > scope for each element.  >  > The january draft of C14n was easier on this point since it  > didn't care  > about prefixes in attribute values.  >  > David  >  >        

      Hello,    I realize that we are past the official last call period for infoset, but as  the document has still not proceeded beyond working draft and as I am now  responsible for trying to produce a canonicalization specification that, at  a minimum, can be used by the digital signature working group to advance the  XML Digital Signature specification, I would like to request consideration  of a modification.    I would like to request that you add to the element and attribute properties  the namespace prefix that appeared in the input document.  It is erroneous  to assert that namespace prefixes do not carry information value within an  XML document in light of the W3C's XPath recommendation.  This is because  XPaths can A) appear in attribute values and element character content and  B) refer to namespace prefixes.  I have posted a detailed discussion of this  topic, including two theorems which show that namespace rewriting harms  documents containing such XPaths [1].  As a corollary to those theorem,  namespace prefixes carry information value, so the information set is not  completely represented.    [1]  http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/2000AprJun/0159.html    I need you to add this because I plan to remove namespace rewriting from  canonicalization (precisely because it can change the logical meaning of a  document, which contradicts the meaning of canonicalization).  Instead c14n  will write the prefix occuring in the originating document, so I cannot  continue to refer to the XML InfoSet document unless it is changed to  include this information.  The option at hand is to rewrite the  specification as an application of XPath, which allows the application to  decide whether the reported QName includes the original prefix.  Note that  this may occur anyway because I think it is a suitable way to deal with  canonicalizing partial XML documents.    By the way, I realize that writing the original namespace prefix means that  XML documents that are logically equivalent, but differ in the particular  namespace prefixes used will not be considered logically equivalent by  simple byte comparison of their canonical forms.  However, as explained in  [1], namespace rewriting does not fix this problem.  Moreover, it will  shortly be argued in the next draft of c14n that simple byte comparison for  logical equivalence is not a realistic goal.  Aside from  application-specific knowledge of insignificant whitespace and  application-specific equivalencies, there are other equivalencies that can  result from the rules of RDF, the meaning of XPath expressions, character  models, XML Schemas, and other specifications that have not even been  written yet.    In order to have a c14n spec in time for DSig to use it, we need to focus on  canonicalizing XML 1.0 because the logical equivalencies it allows represent  the largest set of changes that existing applications are likely to make  with the expectation of impunity.  Going forward, we need to impose stricter  guidelines on applications to ensure that information in the document is  preserved as it was given.  For example, character content of "0.10" should  not be changed to "0.1" by the argument that the numbers are equivalent.  As  far as XML is concerned, they aren't equal.  They are only equal due to some  rules beyond those given in XML 1.0.    As for namespaces, the c14n spec will recognize their existence, but it will  not try to formally canonicalize them because this cannot be done without  changes to either the Namespace recommendation or the XML 1.0  recommendation.    John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com        

      Hi Joseph,    1. In 4.3.3.1 I thought we said we didn't need the extra XSLT element,  instead a proper <stylesheet> element should be included? (Though I honestly  don't remember so I made the change and rewrapped it).    <john>  Actually, we've been going after the idea that any defined transforms  include 'parameter' elements that are defined within our namespace.  The  contents of those parameters is what is up in the air.  The content model for Transform is XPath, XSLT, or any sequence of elements.  The last part is only there to accommodate Transforms not defined by us.  I  have no problem saying that the content model for Transform is (XPath |  XSLT) because I don't really see why people would do non-standard  transforms.  If more transforms are required, then we should be collecting  those ideas and doing a rev to the spec at some later time.  Anyway, these thoughts are in addition to the fact that the XSLT content  MUST be an xsl:stylesheet (or equivalently an xsl:transform).  </john>    2. I'm less than comfortable with the Base64 [2] and Minimal [3] changes as  it adds a lot of text and introduces confusion with respect XPath and  comments. These are supposed to be the _simple_ transforms.  a. Minimal: "This algorithm requires as input the octet stream of the  resource to be processed. However, the actual input to this algorithm may be  an XPath node-set (or a sufficiently functional replacement implemented by  the application). " I don't understand, does it take octects only or not?  Are you saying a Signature application can (or MUST) convert nodesets to  octects?    <john>  The processing model is that the input can be octets or a node-set.  However, the transform only accepts octets, so if it gets a node-set, it has  to convert the node-set to octets.  Signature applications already know, in principle at least, how to convert  node-sets to octet streams because C14N is required.  </john>    b. Base64: Again, the algorithm takes octects. If nodesets are present, who  is doing the converting? Should it be restated to say, "If a Signature  Application has a nodeset and wishes to base64 its encoding it must first  ..." And now we have the Base64 doing XML processing by stripping away start  and end tags! I'd like to keep this transform clean and simple.    <john>  Actually, it is simpler.  Again, b64 wants octets.  If it gets a node-set, then obviously we have to  convert to octets.  However, consider the most typical usage case for  someone wanting to use this transform.  They have an element identified by  id as "CompanyLogo", which contains a base-64 encoding of an image in the  element's content.  They *want* to say    <Reference URI="#CompanyLogo">  <Transforms>  <Transform algorithm="&base64;"/>  </Transforms>  </Reference>    But they can't because the result of the URI includes the start and end tags  of the company logo element.  Instead, they have to throw in an XPath  transform to dig the text out of the element, as follows:  </john>    <Reference URI="#CompanyLogo">  <Transforms>  <Transform algorithm="&xpath;">  <XPath>self::text()</XPath>  </Transform>  <Transform algorithm="&base64;"/>  </Transforms>  </Reference>    The XPath is run against every node in the node-set result of the URI, and  it chooses just the text nodes.    I think the former is simpler and more natural.  </john>    I'm not sure what the solution is, but if other people would like to keep  these simple, we can give it more thought.    3. I'm not sure if the 6th and 7th motivating paragraphs in the XPath  section aren't needed. "The primary purpose ..." I'd propose to strike them.    <john>  Many have felt and I still feel it is necessary for people to know why this  transform exists.  It is important that we not try to shorten the spec so  much that noone understands why we are doing what we are doing.  This is a  major problem in other specs.  </john>    4. XPath section, has (old) text that says, "The function definition for  here() is consistent with its definition in XPointer. It is defined as  follows:" However, this isn't the case, right?    <john>  It may not be the case at the moment, but I fully expect it will be the case  again soon.  Once the Xptr folks actually do discuss this, I'm sure they  will find there is no reasonable alternative.  If they do go in a direction  other than ours, we can change the text at that time to say "Note that it is  NOT the same as the XPointer here()".  </john>        

      Hi Tom,    UTF-8 and UTF-16 are both encodings of UCS, whether UCS-2 or UCS-4.  If I  understand correctly, UCS-n is a character domain used during processing,  and UTF-n is used for input and output.    I am certain that UTF-8 character sequences can encode UCS-4, and I know  that UCS-2 is a two byte per char character domain for use in processing  scenarios where only the BMP is required.  This would be all scenarios right  now (according to the Unicode 3.0 manual) because nothing is yet defined  outside of the BMP, although ISO 10646-2 is likely to change that (again,  according to the Unicode 3.0 manual).    One thing I don't know for sure is whether Unicode == UCS-2?    If so, then our current sentence is certain wrong because I'm sure we don't  mean that NFC should be applied to UTF-8 and UTF-16 encodings of UCS-n.    If Unicode != UCS-2, then A) what's the difference, and B) it would be  helpful if someone would confirm whether UCS-n is ever used for  transportation of character data, or whether this is done solely by UTF-n  formats.  If so, will it continue in this fashion in the future?    Finally, I don't know whether anyone reads or writes UCS-n data directly,  but I do know that our intent was that UTF-n data would not have NFC applied  to it.    Thanks,  John Boyer  Team Leader, Software Development  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Tom Gindin  Sent: Tuesday, November 28, 2000 4:53 PM  Subject: Re: Character Encoding Question             Is what is meant "... from an encoding which is neither a UCS-n  encoding nor a UTF-n encoding"?  That would seem to cover UCS-2, UCS-4,  UTF-8, and UTF-16 (along with UTF-7 for good measure).  If UTF-8 is not  included, although the NFC transformation would seem to have no effect on  it, just replace "UTF-n" by "UTF-16" in the sentence above.              Tom Gindin    "John Boyer" <jboyer@PureEdge.com>@w3.org on 11/28/2000 05:39:27 PM    Sent by:  w3c-ietf-xmldsig-request@w3.org      Subject:  Character Encoding Question        Hi Martin and group,    I received a letter today from Jeff Cochran (JCochran@docutouch.com)  regarding a tweak that would appear to be needed regarding c14n and xml  signature.    The I18N group asked us to include a sentence along the lines of "REQUIRED  to use Normalization Form C [NFC] when converting an XML document to the  UCS  character domain from a non-Unicode encoding".    Apparently this is not exactly what is meant since UCS-4 character planes  outside of the BMP are technically non-Unicode.  The point Jeff makes is  that he doesn't know whether to apply NFC to UCS data that appears outside  of the BMP.    Question:  Should the statement be rewritten?  If so, how?    Thanks,  John Boyer  Team Leader, Software Development  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Martin J. Duerst  Sent: Friday, November 24, 2000 6:17 PM  Subject: Fwd: I18N problem in XML canonicalisation      Chris Lilley just pointed out the following problem  in C14N. I think this at least has to be explained  much more clearly in the notes.    >http://www.w3.org/TR/xml-c14n#Example-UTF8  >  >Demonstrates using *two* NCRs foa single UTF-8 character (because it uses  >two bytes in UTF8 !!!    It's not really NCRs. It's a special notation to stand in for byte values.      >I suspect you may have a problem with that..... given that even surrogates  >use a single NCR not two. Also, its not clear the result is even  >wellformed!    There needs to be a much better note to make very clear that (different  to the other examples), this example is not really intended to be XML  and cannot be used directly in a test. It would also be advisable  to provide an actual file that contains the real bytes, or to point  to it if that's already around.    Regards,    Martin.        

      Hi Jonathan,    Perhaps I've missed something huge here.  You said that node-sets are  automatically serialized.  Could you please point out where in the XPath  spec it says anything about this?    Thanks,  John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  jboyer@PureEdge.com      -----Original Message-----  From: Jonathan Marsh [mailto:jmarsh@microsoft.com]  Sent: Friday, March 17, 2000 3:06 PM  Subject: RE: Xpath transform changes and questions          > -----Original Message-----  > From: John Boyer [mailto:jboyer@PureEdge.com]  > Sent: Friday, March 17, 2000 12:48 PM  > To: TAMURA Kent; IETF/W3C XML-DSig WG  > Cc: Jonathan Marsh; Martin J. Duerst; Christopher R. Maden;  > James Clark  > Subject: Xpath transform changes and questions  >  >  > Hi,  >  > I have a few concerns that I think can be worked out, so I am  > requesting  > feedback on the information below.  If everything works out,  > then yes, we  > could remove parse() and exact order.  >  > 1) On parse(),  >  > I would be in favor of dumping parse() if we can solve ALL of the  > implementation problems it solves.  It  solved some  > interesting, but not too  > important problems for XPath transform users, but it also  > specified how  > implementers were to solve certain problems.  >  > Please have a closer look at the output expectations of  > serialize().  The  > serialize() function cannot operate without several features  > of parse().  In  > particular,  >  > i) Serialization of the root node requires that we output the  > byte order  > mark and xmldecl read by parse() on input.  If parse() is not  > under our  > control, we cannot specify that it retains this information.    It seems useful that the BOM and encoding are preserved through  re-serializing the document.  If these are inputs to the serialization  mechanism, this is added incentive not to expose the serialization mechanism  as a function.  Otherwise these would have to be passed through as variables  (as you are doing) and users must not forget to use them, and must use them  appropriately (e.g. not change them), if they want correct results.    If serialization is not exposed as a function, but is performed  automatically, these problems are avoided.  Since it seems that this  capability already exists (nodesets are automatically serialized), at least  the simple cases are already handled.  Thus an explicit serialize() and BOM  and encoding variables seems to be an advanced feature.  It's necessity in  solving important problems should be weighed against its potential for  abuse.  I haven't seen you justify your design yet.  Mainly I'm curious  here, not trying to kill serialize().  Of course, if you can't justify it,  drop it.    > This would  > seem to suggest that root node serialization should result in  > the empty  > string, which in turn suggests that serialize should output in UTF-8  > regardless of the input encoding.  That would be OK with me.  >  > ii) Attribute and namespace serialization require a namespace  > prefix.  Based  > on a new read of XPath I believe this information must be  > available, but I  > want to be sure.    Note in XPath that Namepace Nodes are different in quantity and position  than the attributes used to declare namespaces.  Your current serialization  does not take this into account.    On the other hand, serialization does not necessarily have to be limited to  the XPath Data Model.  This model of a document is used when locating the  nodes, but given a document and a set of locations, your serializer can  describe what to do on it's own terms.  Specifically, any namespace  attributes in the source are copied through unchanged, and namepace  attributes are added to elements taken out of scope (e.g. parents trimmed)  to represent the namespace nodes of that element.  Retain the prefixes in  all cases - otherwise QNames in content (e.g. XPaths) will break under the  transformation.  Maybe the experts will have some comments on this idea...    > iii) If everything else checks out, we can get rid of exact  > order and just  > use lex order provided that lex ordering in UTF-16 results in  > the same order  > as lex ordering in UTF-8 (which is Christopher Maden's claim).  >  > Also, parse() has an additional feature that would need to be  > dealt with in  > some other way:  >  > iv) If the parser used to implement parse() is  > non-validating, then parse()  > is required to throw an exception if it encounters an  > external reference  > that would cause it to interpret the document differently  > than a validating  > parser.  This exception is necessary since an unverifiable  > signature is  > different than an invalid signature.    I don't see that moving parsing out of parse() changes this.  The  restriction still applies, and needs to be stated.  An implementation would  either need to initialize their parser to provide such an exception during  parsing, or do some post-parsing pre-filtering checks.    > 2) On eliminating exprBOM and exprEncoding.  >  > Sounds fine.  Sounds like any difference of encoding between the Xpath  > expression and the transform input will be handled implicitly  > by the XPath  > transform implementation.  >  >  > 3) On automatic serialization,  >  > There was some concern that serialization should be automatic  > ("why call  > serialize() when that's always what we want to do").  Please  > see the first  > paragraph of section 6.6.3.4, which already includes this feature.    The question perhaps is better stated as "why do we need an explicit way to  serialize, instead of always relying on the default that nodesets are  serialized?    For one thing, this design deeply entwines serialization with pruning of the  tree, which makes it difficult to use off-the-shelf serialization components  in an implementation.    For another, I would not in general expect XPath implementations to handle  large strings such serialize() generates particularly efficiently, since  such strings are at this point pretty rare.  For example, I can't really  imagine returning strings from XPath asynchronously, which I would expect  from a serializing component.    > Thus if we remove parse(), then there is no *need* to start  > expressions with  > a function call.  >  >  > 4) On providing an initial namespace context  >  > We can provide an initial namespace context as is done in XPointer.  >  > I was reviewing how XPath handles namespaces, and realized that it is  > different than what I had previously understood, and it seems  > broken (so  > there must be some good reason why it is done the way its  > done, or maybe I'm  > just misreading the spec).  >  > Section 2.3 says "A QName in the node test is expanded into  > an expanded-name  > using the namespace declarations from the expression context.  > This is the  > same way expansion is done for element type names in start  > and end-tags  > except that the default namespace declared with xmlns is not  > used: if the  > QName does not have a prefix, then the namespace URI is null  > (this is the  > same way attribute names are expanded). It is an error if the  > QName has a  > prefix for which there is no namespace declaration in the expression  > context".  >  > This seems to indicate that the input XML document's  > namespace declarations  > are ignored and the expression context's namespace  > declarations are used  > solely.    Yes.  Prefixes are scoped, and can change throughout the document, so it is  not possible to use these declarations in a global context such as an XPath.  Also, the namespace rec implies that prefixes can be changed without  changing the underlying names.  Since XPath has it's own namespace  declarations, it is unaffected by prefix changes in the source document.    > When XPath claims to be XML namespace compliant, I thought  > that meant it  > would interpret a node's namespace in the context of the namespace  > declarations in the document, but that appears not to be  > true.  To clear  > this up, suppose I have an element x:E, and the document  > containing this  > element associates x with www.w3.org, but the expression  > context associates  > x with www.ietf.org, then which value will the  > namespace-uri() function  > applied to x:E return?    namespace-uri(x:E) will either return the namespace declared in the context  (www.ietf.org) or an empty string if no element {www.ietf.org : E) exists in  the document, which appears to be the case in your question.  In short,  XPath cannot talk about an element without knowing it's full name, including  the namespace uri.  This is an essential component to it's namespace  awareness.    > If it returns www.ieft.org, then although it seems weird to me that we  > aren't using the namespace declarations in the document, it  > would at least  > be good in the sense that it implies XPath implementations have the  > namespace prefix kicking around for serialize().  >  > It also would mean that Jonathan Marsh is correct in  > requiring an initial  > namespace context since we could not do ANY namespace  > comparisons without it  > (the XPath seems to say that it is an error to use a QName  > containing a  > namespace prefix in an expression if that namespace prefix is  > not defined in  > the expression context).    Yep.  This really isn't a problem for XPaths appearing in XML documents,  since there is a ready set of namespace declarations (and an existing syntax  for declaring them) to pass into XPath.  We couldn't actually make this part  of XPath because certain uses of XPath do not appear in an XML document  context - namely XPointers embedded in URIs.    I don't veiw this issue as a conceptual mistake, but as a cheap fix with  large author simplicity benefits.  It's virtually free (no new syntax  needed) - just add one line saying that the namespaces are initialized to  the namespaces in scope on the <xpath> element.    > I would appreciate your feedback, esp. from those who have  > sent prior emails  > and therefore seem to be most interested in how this turns  > out.  If you  > would please give this some extra priority, I will prepare an  > alternative  > document for consideration before or during the meeting in Adelaide (I  > regret that I will not be at that meeting, but I will be at  > the following  > one in Victoria ;-).  >  > John Boyer  > Software Development Manager  > PureEdge Solutions, Inc. (formerly UWI.Com)  > jboyer@PureEdge.com  >  >  > -----Original Message-----  > From: w3c-ietf-xmldsig-request@w3.org  > [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of TAMURA Kent  > Sent: Friday, March 17, 2000 12:59 AM  > To: IETF/W3C XML-DSig WG  > Subject: Re: XSL WG comments on XML Signatures  >  >  >  > > <John>  > > XPath filtering will not be substantially rewritten.  Based  > on Clark's  > > feedback, we can remove the parse function and instead  > simply assert that  > > the transform input is parsed and provided to XPath as a  > node set.  The  > > notions of lex and exact order will be removed (since we  > cannot directly  > > specify the parse).  >  > That's good!  It would be easy to understand, easy to implement,  > easy to use.  >  > --  > TAMURA Kent @ Tokyo Research Laboratory, IBM  >        

      Hello all,    I am writing to ask (esp. implementers) about the feasibility of a  behavioral tweak to c14n.    In the XPath data model, a non-empty default namespace is represented by a  namespace node, but an empty default namespace is represented by the absence  of a namespace node.    Therefore, when there is no default namespace node in a node-set, we cannot  tell whether that is so because it was excluded or because the namespace  declaration is actually empty.    To deal with this issue, I start out the namespace context of every element  by putting xmlns="" if the element has no default namespace.  Someone  expressed minor annoyance over the verbosity of this.    Question is, do you want it changed to the following:    If there is no default namespace node, then      if the parent is omitted from the node-set or if the parent's default  namespace is non-empty, then generate an xmlns=""    Thanks,         John Boyer        Development Team Leader,        Distributed Processing and XML        PureEdge Solutions Inc.        Creating Binding E-Commerce        v: 250-479-8334, ext. 143  f: 250-479-3772        1-888-517-2675   http://www.PureEdge.com                                

      Hi Kevin,    Good question.  #xD, #xA and #x9 can appear in a normalized attribute value  if they were created by character references.  This would not appear to be the case from the XML 1.0 spec (specifically the  passage you cited), but please see the XML errata [1,2].    [1] http://www.w3.org/XML/xml-19980210-errata#E24  [2] http://www.w3.org/XML/xml-19980210-errata#E61    Thanks,  ***************************************  John Boyer,  Software Development Manager    PureEdge Solutions (formerly UWI.Com)  Creating Binding E-Commerce    v:250-479-8334, ext. 143 f:250-479-3772  1-888-517-2675  http://www.PureEdge.com  ***************************************        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Kevin Regan  Sent: Friday, June 23, 2000 3:26 PM  Subject: Attribute normalization        I have a question on section 4 of the XML C14N spec.  In this section,  it mentions the normalization of attributes:    -------------------------------------------------------    Namespace and Attribute Nodes- a space, the node's QName, an equals  sign, an open double quote, the modified string value, and a close  double quote. The string value of the node is modified by replacing all  ampersands (&) with &, all double quote characters with ", and  the whitespace characters #x9, #xA, and #xD, with character references.  The character references are written in uppercase hexadecimal with no  leading zeroes (for example, #xD is represented by the character  reference).    --------------------------------------------------------    However, when an XML processor reads in and parses an XML document, it  should  do the following (from XML 1.0 spec, section 3.3.3):    ----------------------------------------------------    3.3.3 Attribute-Value Normalization  Before the value of an attribute is passed to the application or checked  for validity, the XML processor must normalize it as follows:    -- a character reference is processed by appending the referenced  character to the attribute value  -- an entity reference is processed by recursively processing the  replacement text of the entity  -- a whitespace character (#x20, #xD, #xA, #x9) is processed by  appending #x20 to the normalized value, except that only a single #x20  is appended for a "#xD#xA" sequence that is part of an external parsed  entity or the literal entity value of an internal parsed entity  --other characters are processed by appending them to the normalized  value    If the declared value is not CDATA, then the XML processor must further  process the normalized attribute value by discarding any leading and  trailing space (#x20) characters, and by replacing sequences of space  (#x20) characters by a single space (#x20) character.    All attributes for which no declaration has been read should be treated  by a non-validating parser as if declared CDATA    --------------------------------------------------------    So, it seems that only #x20 characters will be seen in attribute values.  Why does the  spec mention the other values (#xD, #xA, #x9)?    Thanks,  Kevin Regan    kevinr@valicert.com        

      I would like to reiterate that it seems to be easy to clear up the loggerjam  over the subtree() issue because XPath actually allows its applications to  add to the function library.  I just suggested the following function be  added to any future version of XPath, but in the meantime it can be an  addition to c14n and XPath transform serialization:    Function: node-set subtree(node-set)    Unions the argument node-set with all descendant element, text, PI, and  comment nodes of nodes in the argument node-set to create an intermediate  set, then it unions the intermediate set with namespace and attribute nodes  of all elements in the intermediate set to produce the resulting node-set.  If the argument is omitted, it defaults to a node-set with the context node  as its only member.    This trivially solves all of the problems.  For example, the barename  xpointer given by URI="#E" could be represented by the expression    subtree(id("E"))    Further, my own scenarios that involve applying a filter expression to every  node in the entire document is trivially solved by    subtree()[filterexpression]    (This utilizes rule 14 for Expr, reducing to rule 20 with FilterExpr being a  PrimaryExpr followed by a Predicate.)    Naturally, there would be a few more legal XPath expressions if subtree were  an axis, but this seems to suffice for every scenario I've actually run  across.    John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com        

      Hi Joseph and Gregor,    I was pretty sure we covered off the correctness of Example 3.7 last time.  There is no justification in any of the recommendations for ignoring the ID  type of e3's attribute when using a non-validating parser.    Though the change is simple, I would prefer not to change the example at  this time since it would also require a revalidation effort among the other  implementers who had no problem with this.    As well, your assertion that the Xerces DOM parser cannot select by id  unless using validation seems, on the surface, to contradict IBM's  interoperability report since they are most certainly using Xerces and yet  were able to complete example 3.7.    Moreover, if the id() function is something you have to implement, it is not  actually very hard to implement as long as 1) the parser correctly types the  id attribute when not validating, and 2) it is easy to hook your resulting  id() function into the Xpath implementation that evaluates the expression  given in example 3.7.  Are you saying that one of these two things isn't  working.    And again, if you are, then perhaps we should talk to Kent to find out how  IBM got it to work-- because it is certainly a legal example.    Thanks,  John Boyer    -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Gregor Karlinger  Sent: Thursday, November 09, 2000 11:52 PM  Subject: AW: AW: Call for Implementation: Canonical XML Becomes a W3C  Candidate Recommendation      Hi Joseph,    > At 11:22 11/3/2000 +0100, Gregor Karlinger wrote:  > >Please fill in a "Y" in all fields of the matrix,  >  > Ok, have done [1]    Thanks.    > >* Example 4 does not result in the expected canonicalization, since the  > >   XML parser used does not correctly normalize an attribute of type ID.  >  > Ok, I presume the parser will be fixed or tweaked. (Note I  > believe both of  > these problems were encountered by Petteri as well [2].)    Yes, I have heard that there will be a fix in the Xerces parser we are  using in the next update.    > >* Example 7 only results in the expected canonicalization, if the test  > >   file is modified in a way, that the example can be parsed using a  > >   validating parser. Otherwise the id function in the document subset  > >   selector XPath will not return any element.  > >John,  > >a question regarding example 7: Can I really expect from a non validating  > >parser, that it recognizes the types of attributes, especially the type  > >of ID attributes? If not, then an XPath using the id() function cannot be  > >used for selecting a document subset to be canonicalized.  >  > I'm not sure how this thread ended, did John's response [3] close  > the issue,  > are we still thinking, or actually disagreeing about adding "the  > remaining  > parts of the DTD, and additionally provide some textual description about  > this problem of using the id() function. [4]    Good question. Having read [3], I also thought John would like to close the  issue.    I am not very happy with the current situation, since I do not want to build  the functionality for the XML id() mechanism for my own, but want to utilize  existing parsers.    For the Xerces DOM parser I can state, that selecting a  DOM element by specifying the value of its ID attribute is only possible if  the DOM model has been built using validating parsing.    Regards, Gregor  ---------------------------------------------------------------  Gregor Karlinger  mailto:gregor.karlinger@iaik.at  http://www.iaik.at  Phone +43 316 873 5541  Institute for Applied Information Processing and Communications  Austria  ---------------------------------------------------------------        

      Hi Martin,    XPointer is not a recommendation at this point, so it may be that they will  see our definition of here() as better for the reasons I mentioned.    John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com      -----Original Message-----  From: Martin J. Duerst [mailto:duerst@w3.org]  Sent: Thursday, May 25, 2000 11:44 PM  Subject: Re: XPath Serialization      At 00/05/23 11:04 -0700, John Boyer wrote:  >Hello all,  >  >Attached is the latest version of the XPath serialization spec.  The  >following changes were made:  >  >1) Changed character reference rendering to be uppercase hexadecimal with  no  >leading zeroes (e.g.  instead of ).  This was decided at the  >Victoria FTF.  >  >2) Added the function here() to the XPath function library based on  requests  >by the group at and after the Victoria FTF.  You want to have a look at it,  >though, because it is defined slightly differently than in the current  >XPointer draft.  Basically, they define it to return the element containing  >the attribute or text node that bears the Xpath expression.  I changed that  >to returning the actuall attribute, text or other node (if you want the  >element, you can get the parent, but if you are given an element, but it  has  >more than one attribute bearing an Xpath, then there is room for ambiguity.  >  >I need feedback on this function, esp. from other implementers.    I'm not an implementer, but it is very clear that defining a function  with the same name but different behaviour is a very bad idea.  Either (preferred) just do what XPointer does, or rename your  function.      Regards,   Martin.        

      Hi Gregor,    Actually, I understood your question a little better shortly after the last  email, though I wouldn't change anything in it at this time.    You are asking about the difference between what an XML processor must do  versus what information it must export to the application.    I don't recall anything that permits an XML processor to report less  information than it derives from the input.  In particular, I don't recall  anything that binds this concept to validating vs. non-validating  processors.    The closest we come to it is in the Conformance section of [XML], where  there is a reiteration of the idea that non-validating processors may vary  in their information output "depending on whether the processor reads  parameter and external entities".  But this is an instance of the processor  reporting less information because it has derived less from the possible  input (because it didn't read the input).    That in mind, I haven't gone looking through the spec for evidence to  support what you're thinking either, so I'd be happy to think about any  passage of the spec you may have come across that would substantiate a  behavioral difference.    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Gregor Karlinger  Sent: Sunday, November 05, 2000 11:20 PM  Subject: AW: Call for Implementation: Canonical XML Becomes a W3C  Candidate Recommendation      Hi John,    > Yes, non-validating parsers are supposed to recognize the types of  > attributes, unless they have been unable to read the declaration (e.g. due  > to external declaration), but c14n covers this too by requiring  > that such a  > processor be augmented to read the attribute types so that it can  > normalize  > attributes as if it were a validating processor.    That a non validating parser is required to normalize the attribute  values is ok. This is explicitley mentioned in XML 1.0 (Second Edition).    What I am not so sure about is, if a non-validating parser must support  structures which enable the application to select elements by the values  of ID attributes.    Regards, Gregor  ---------------------------------------------------------------  Gregor Karlinger  mailto:gregor.karlinger@iaik.at  http://www.iaik.at  Phone +43 316 873 5541  Institute for Applied Information Processing and Communications  Austria  ---------------------------------------------------------------        

      Hi Kevin,    The reason is signature interoperability with non-validating processors.    I empathize, though :)    Thanks,  John Boyer      -----Original Message-----  From: Kevin Regan [mailto:kevinr@valicert.com]  Sent: Wednesday, November 15, 2000 1:50 PM  Subject: RE: question on latest spec        What is the reason for doing this?  Isn't the exclusion of insignificant  white space one of the key forms of equivalence?  XML documents can be  displayed and handled in many different ways, with white space being  added  or removed from element content at various steps.  In general, this is  not a problem if a DTD is being used.  The meaning of the document  is clear.  However, this form of equivalence is eliminated in the XML  C14N  specification.  Why?    Sincerely,  Kevin Regan       -----Original Message-----  From: John Boyer [mailto:jboyer@PureEdge.com]  Sent: Wednesday, November 15, 2000 1:12 PM  Subject: RE: question on latest spec      Hi Kevin,    Actually, Section 2.10 of the XML spec makes it quite clear that all XML  processors must be capable of providing to the application ALL  whitespace  within the document element.  Validating processors must further be  capable  of telling the application whether a given whitespace character appeared  in  element content, i.e. was insignificant.    Many implementers of validating processors allow the application  developer  to configure whether the whitespace should simply be discarded.    The statement you've come across in Section 2.1 is telling you how to  configure your validating parser.  You MUST set it so that all  whitespace is  reported to the canonicalizer.    NOTE: I don't see any harm in throwing out insignificant whitespace  *before*  the document is signed.  In other words, the original document accessed  by  the user from the web may have insignificant whitespace that your  application strips out before even presenting the information content to  the  end-user.  Once the end user affixes a signature, though, any  insignificant  whitespace that gets added to the signed document will break the  signature.    John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Kevin Regan  Sent: Sunday, November 12, 2000 6:20 PM  Subject: question on latest spec        I've been a way on other activities for a while, and have just recently  gotten back to  the XML C14N specification.  I came across the following in section 2.1:    "All whitespace within the root document element MUST be preserved  (except for any #xD characters deleted by line delimiter normalization).  This includes all whitespace in external entities. Whitespace outside of  the root document element MUST be discarded."    I'm assuming that this means white space that is presented after the  document is processed  by the XML processor.  When a validating XML processor reads in a  document against a DTD,  insignificant white space is removed.  This is not the white space that  the specification is  referring to, is it?    Sincerely,  Kevin Regan        

      Actually, it seems it was a no-brainer, as Joseph pointed out to me this  morning (I was rushing out of the door yesterday when someone asked me this  question; that's my excuse and I'm sticking by it!)    If you want to sign it, just add a Reference to it in the SignedInfo.  No  need to cover it with the SignatureValue when we can cover it with a  DigestValue.    John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Ed Simon  Sent: Tuesday, August 29, 2000 1:47 PM  Subject: RE: Why isn't KeyInfo inside SignedInfo [Attn: Brian L.]      There has been some discussion on this in the past, see  the threads starting at  "http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/2000JanMar/0174.html"  and  "http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/2000JanMar/0193.html"  for example.    I think though it would be timely if Brian summarized the answer  to the question again.  There has been a lot of traffic on the XML  Encryption  list wondering why KeyInfo isn't signed.    Brian, could you cross-post your answer to XML Encryption please.  If anyone  else would like to respond who's delved into the issue, that would be fine  too.    Ed  ----------------------------------------------------------------------------  ----------  Ed Simon  Software Engineer, Entrust Technologies  email:  ed.simon@entrust.com  ph: (613) 247-2583  ----------------------------------------------------------------------------  ----------      -----Original Message-----  From: John Boyer [mailto:jboyer@PureEdge.com]  Sent: Monday, August 28, 2000 8:04 PM  Subject: Why isn't KeyInfo inside SignedInfo      This might be a no-brainer at this point, but I just noticed that KeyInfo is  not inside SignedInfo.    Why is this?    It seems that during signature generation, all data within KeyInfo can be  filled in prior to generating the SignatureValue.  The signer chooses his  identity before the SignatureValue is created.    Otherwise, the material in KeyInfo would seem to be largely untrustworthy  even if our signatures validate.  After validation, we would have to dig up  the real information from the actual certificates just to be sure that all  of this identity information wasn't substituted on us by an attacker.    On the other hand, perhaps it is done this way to force application  developers to obtain the information (like subject name) from the  certificate to avoid attacks from those who would generate a faulty  signature.    In which case, why bother breaking this information out into XML?    Thanks,     John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675    <http://www.pureedge.com/> http://www.PureEdge.com        

      Hi Gregor,    The role of a parser is only to crack a file into tokens and to identify  what those tokens are.  Optionally, a parse tree can be built. A  non-validating XML parser must identify ID attributes as being ID attributes  (whenever it can), in such a parse tree (or in the input token stream if a  parse tree is not built).    An application that uses an XML parser may choose to discard that  information if the application requirements do not identify a need for the  information, but this is outside of the scope of the XML parser  specification.  The information is provided by the parser should it be  needed.    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: Gregor Karlinger [mailto:gregor.karlinger@iaik.at]  Sent: Sunday, November 05, 2000 11:20 PM  Subject: AW: Call for Implementation: Canonical XML Becomes a W3C  Candidate Recommendation      Hi John,    > Yes, non-validating parsers are supposed to recognize the types of  > attributes, unless they have been unable to read the declaration (e.g. due  > to external declaration), but c14n covers this too by requiring  > that such a  > processor be augmented to read the attribute types so that it can  > normalize  > attributes as if it were a validating processor.    That a non validating parser is required to normalize the attribute  values is ok. This is explicitley mentioned in XML 1.0 (Second Edition).    What I am not so sure about is, if a non-validating parser must support  structures which enable the application to select elements by the values  of ID attributes.    Regards, Gregor  ---------------------------------------------------------------  Gregor Karlinger  mailto:gregor.karlinger@iaik.at  http://www.iaik.at  Phone +43 316 873 5541  Institute for Applied Information Processing and Communications  Austria  ---------------------------------------------------------------        

      Hi Gregor,    The result should be [3].  The duplicated attribute in this case doesn't  hurt anything, and therefore seemed superior to defining a more elaborate  set of rules, which would likely include requirement to omit duplicate xml  namespace declarations.    That seemed like a patently bad idea.    Regards,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: Gregor Karlinger [mailto:gregor.karlinger@iaik.at]  Sent: Wednesday, September 13, 2000 9:42 AM  Subject: Canonical XML comment (attributes in xml namespace)      Hi John,    I have read section 2.4 about document subsets, and I am wondering  how the propagation for attributes in xml namespace should actually  work.    1. Should the method for processing the attribute axis be enhanced     only in the case that the parent element is omitted from the     node set?    2. What happens if an xml attribute (which is in scope for the     current element) has already been output in the attribute     axis of an ancestor? Consider the example [1]: The mother     element is omitted by a fitting XPath expression. So, should     the c14n output be [2] or [3]?    [1]    <grandmother xml:space="preserve">  <mother>  <child>  </mother>  </grandmother>    [2]    <grandmother xml:space="preserve">  <child>  </grandmother>    [3]    <grandmother xml:space="preserve">  <child xml:space="preserve">  </grandmother>    Regards, Gregor  ---------------------------------------------------------------  Gregor Karlinger  mailto://gregor.karlinger@iaik.at  http://www.iaik.at  Phone +43 316 873 5541  Institute for Applied Information Processing and Communications  Austria  ---------------------------------------------------------------        

      Hi Merlin,    Oh! Did it again didn't I.  Yes we did make that change.    As you and Petteri have asserted, the correct output should be what is shown  less the xmlns:w3c in e3.  So the spec will change from    [suggested c14n]    <e1 xmlns="http://www.ietf.org" xmlns:w3c="http://www.w3.org"><e3 xmlns=""  xmlns:w3c="http://www.w3.org" id="E3" xml:space="preserve"></e3></e1>    to    [correct c14n from you and Petteri]    <e1 xmlns="http://www.ietf.org" xmlns:w3c="http://www.w3.org"><e3 xmlns=""  id="E3" xml:space="preserve"></e3></e1>    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of merlin  Sent: Wednesday, October 11, 2000 8:50 AM  Subject: Re: Tentative signature over C14N examples        Hi,    It is present in the node set, yes, but is it not omitted by C14N?    http://www.w3.org/TR/2000/WD-xml-c14n-20000907#2.3      A namespace node N is ignored if the nearest ancestor element of    the node's parent element that is in the node-set has a namespace    node in the node-set with the same local name and value as N.    Merlin    r/jboyer@PureEdge.com/2000.10.11/08:45:20  >Hi Merlin,  >  >No, a namespace node is not omitted if the element's parent contains the  >same namespace declaration.  Please see [1]  >  >[1] http://www.w3.org/TR/xpath#namespace-nodes  >  >which says,  >  >"This means that an element will have a namespace node:  >  >for every attribute on the element whose name starts with xmlns:;  >  >for every attribute on an ancestor element whose name starts xmlns: unless  >the element itself or a nearer ancestor redeclares the prefix;  >  >for an xmlns attribute, if the element or some ancestor has an xmlns  >attribute, and the value of the xmlns attribute for the nearest such  element  >is non-empty  >"  >  >Thanks,  >John Boyer  >PureEdge Solutions Inc.  >  >-----Original Message-----  >From: merlin@baltimore.ie [mailto:merlin@baltimore.ie]  >Sent: Wednesday, October 11, 2000 2:13 AM  >To: John Boyer  >Cc: XML DSig  >Subject: Re: Tentative signature over C14N examples  >  >  >  >Hi,  >  >r/jboyer@PureEdge.com/2000.10.10/16:19:06  >><merlin>  >>The C14N of e3 should ?not? have xmlns:w3c.  >></merlin>  >>  >><john>  >>Actually, it should have the w3c namespace.  Each node receives namespace  >>nodes for its entire namespace context, including those derived from its  >>ancestors.  >></john>  >  >But are they not emitted from C14N if they are in scope and set for  >the nearest parent in the node set?  >  >Merlin  >  >[new xpath]  >  ><!-- Evaluate with declaration xmlns:ietf="http://www.ietf.org" -->  >  >(//. | //@* | //namespace::*)  >[  >   self::ietf:e1 or (parent::ietf:e1 and not(self::text() or self::e2))  >   or  >   count(id("E3")|ancestor-or-self::node()) =  >count(ancestor-or-self::node())  >]  >  >[document]  >  ><!DOCTYPE doc [  ><!ATTLIST e2 xml:space (default|preserve) 'preserve'>  ><!ATTLIST e3 id ID #IMPLIED>  >]>  ><doc xmlns="http://www.ietf.org" xmlns:w3c="http://www.w3.org">  >   <e1>  >      <e2 xmlns="">  >         <e3 id="E3"/>  >      </e2>  >   </e1>  ></doc>  >  >[suggested c14n]  >  ><e1 xmlns="http://www.ietf.org" xmlns:w3c="http://www.w3.org"><e3 xmlns=""  >xmlns:w3c="http://www.w3.org" id="E3" xml:space="preserve"></e3></e1>  >  >[my c14n]  >  ><e1 xmlns="http://www.ietf.org" xmlns:w3c="http://www.w3.org"><e3 xmlns=""  >id="E3" xml:space="preserve"></e3></e1>  >        

      I was just reading through the XPath spec for the umpteenth time when I  realized that although the node() function matches any time of node, it can  only match any type of node available on the given axis.  Furthermore, the  descendant and descendant-or-self axes of XPath exclude attribute and  namespace nodes (for some completely unfathomable reason).    Although the whole idea of having special axes for namespaces and attributes  is flawed and unnecessary (rather than simply leaving them as children of  the element and letting the fact that they have a *TYPE* of namespace or  attribute carry the information), we have to live with the recommendation.  Therefore, in places where I have in the past used the subexpression  "/descendant-or-self::node()" to mean ALL of the nodes in the parse tree  INCLUDING namespace and attribute nodes, it is necessary to substitute the  following subexpression: (//. | //@* | //namespace::*)    The union operator | combines the results of the three sets.  The first  subexpression (//.) is the abbreviated syntax for obtaining the root  document node and all of its descendants (which unfortunately includes only  elements, text nodes, processing instructions and comments).  The second  subexpression obtains all of the attributes in the entire parse tree, and  the third obtains all of the namespace nodes in the entire parse tree. The  union of the three sets contains all of the nodes in the parse tree.    Do you think there is any possibility that this might get fixed at some  point in the future?   It seems terribly tedious to have to go through such  hoops to simply say "give me a set containing all nodes in the whole parse  tree".  If not, I suppose we can be content that at least there is *some*  way to indicate what we want.    John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com        

      Hi Gregor,    Yes, we also felt it necessary to make this clear, but we felt the need to  make it clear right up front.  Rather than tweaking the fourth paragraph of  2.1, we devote the entire first paragraph of 2.1 to making this clear:    "The data model defined in the XPath 1.0 Recommendation [XPath] is used to  represent the input XML document or document subset. Implementations SHOULD  but need not be based on an XPath implementation. XML canonicalization is  defined in terms of the XPath definition of a node-set, and implementations  MUST produce equivalent results."    Does this suffice?    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: Gregor Karlinger [mailto:gregor.karlinger@iaik.at]  Sent: Wednesday, September 13, 2000 9:57 AM  Subject: AW: Canonical XML Comment (CDATA)      Hi John,    I agree with you, but maybe you could tweak the fourth paragraph of  section 2.1, so that it gets clear that the XML parser described there  is only a hypothetical model.    Regards, Gregor  ---------------------------------------------------------------  Gregor Karlinger  mailto://gregor.karlinger@iaik.at  http://www.iaik.at  Phone +43 316 873 5541  Institute for Applied Information Processing and Communications  Austria  ---------------------------------------------------------------        > -----Urspr?ngliche Nachricht-----  > Von: John Boyer [mailto:jboyer@PureEdge.com]  > Gesendet: Mittwoch, 13. September 2000 18:33  > An: Gregor Karlinger; XMLSigWG  > Betreff: RE: Canonical XML Comment (CDATA)  >  >  > Hi Gregor,  >  > Thanks for writing.  Please respond to this letter even if you agree with  > its content since Joseph has asked that we document positive  > acknowledgement  > of the resolution of issues raised by the WG (esp. if we intend the  > resolution to be not to change anything).  >  > First, note that there is no requirement to use XPath to build  > the required  > part of C14N.  One's implementation must only behave in the same  > way, which  > includes replacing the CDATA sections with their character content.  The  > section about text nodes that you cited [XPath, Section 5.7]  > mentions CDATA  > sections in the discussion of text nodes, but it is in order to say  > *exactly* the same thing we are saying:  >  > "Character data is grouped into text nodes. As much character data as  > possible is grouped into each text node: a text node never has an  > immediately following or preceding sibling that is a text node."  >  > "Each character within a CDATA section is treated as character data."  >  > I believe it is best to make it clear up front that CDATA sections will be  > replaced rather than burying it in text node processing because  > it is easier  > for people who don't implement with XPath to see what must be  > done to make a  > logically equivalent structure appropriate to their purposes.  >  > My opinion is that the discussion of the processing model should  > be based on  > the data model, unencumbered by details of how to create the data  > model.  To  > me, this is esp. important given that some may choose to actually  > implement  > based on XPath (e.g. in order to perform document subsetting), and such  > people want to read the processing model to figure out how to process the  > data structure they have.  >  > As to your point about whether this concatenation is a common  > feature of XML  > processors, hopefully it is clear that it doesn't matter.  > Concatenation of  > successive blocks of character data is a trivial task.  Implementers can  > either choose to do it in their data structure, or they can  > acknowledge that  > since they are consecutive in the input, simply outputing the text as  > encountered suffices.  >  > It is important to note that while many processors may report separate  > character blocks for CDATA sections, they are not required (and  > some do not)  > distinguish that the text came from a CDATA section because:  >  > "CDATA sections may occur anywhere character data may occur; they are used  > to escape blocks of text containing characters which would otherwise be  > recognized as markup."  > [XML, Section 2.7]  >  > (In other words, CDATA sections are a simple escaping mechanism).  >  > [XML] http://www.w3.org/TR/1998/REC-xml-1998021  > [XPath] http://www.w3.org/TR/1999/REC-xpath-19991116  >  > John Boyer  > Development Team Leader,  > Distributed Processing and XML  > PureEdge Solutions Inc.  > Creating Binding E-Commerce  > v: 250-479-8334, ext. 143  f: 250-479-3772  > 1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>  >  >  >  > -----Original Message-----  > From: w3c-ietf-xmldsig-request@w3.org  > [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Gregor Karlinger  > Sent: Wednesday, September 13, 2000 5:58 AM  > To: XMLSigWG; John Boyer  > Subject: Canonical XML Comment (CDATA)  >  >  > Hi John,  >  > In section 2.1 there are listed the requirements for an XML  > processor to be used to create a node set:  >  >  3. replace CDATA sections with their character content  >  > I am not sure, but I don't think this is standard behaviour of  > the widespread XML parser implementations.  >  > Wouldn't it be better to skip this requirement and instead  > add a sencence to the explanation how to serialize Text nodes  > in section 2.2?  >  > The XPath data model also mentions CDATA sections in the  > explanation of the data model [1].  >  > [1] http://www.w3.org/TR/xpath#section-Text-Nodes  >  > Regards, Gregor  > ---------------------------------------------------------------  > Gregor Karlinger  > mailto://gregor.karlinger@iaik.at  > http://www.iaik.at  > Phone +43 316 873 5541  > Institute for Applied Information Processing and Communications  > Austria  > ---------------------------------------------------------------  >  >  >  >        

      Hi Jonathan,    <john>  > It is essential that a single behavior be defined for C14N,  > and the fact  > that XPath permits application-dependent behavior means that  > applications  > (such as C14N) are permitted to define the most appropriate behavior.  > Retaining the 'raw value' is most appropriate for C14N, esp. for the  > purposes of DSig.  </john>    <jonathan>  No, the fact that XPath permits application-dependent behavior means only  that the plenary has forced it (along with all other groups) to accept  application-depedent behavior.  </jonathan>    <john>Right, and as an application of XPath, we are choosing the behavior  that is most appropriate to our application.  No matter how much the plenary  wants to force things on dsig, there is nothing they can do to change the  behavior of a sha-1 hash.  We MUST have a single behavior, therefore we MUST  </john>    <jonathan>  I'm concerned.  It looks like you are defining it a certain way - to be  "literal".  If W3C groups are free to do this, then why don't we just drop  the plan for the XPath erratum and kill two birds with one stone?  <snip/>  </jonathan>    <john>Yes, we are choosing the literal value.  The reason that Xpath must  have the erratum is that some applications may need URI absolutization.  In  those cases    <jonathan>  I agree that you are in a tough spot.  I think a clever solution might be  found to work around (not change) XPath's undefined behavior (like retaining  the "literal" value and using this in the serialization algorithm), but I  can only imagine how to do this for c14n.  </jonathan>    <john>I do not think this is a tough spot for C14N since retaining the  literal value is *precisely* what we are saying should be done.  Furthermore, the XPath data model is really dependent on the application to  do, or not to do, the absolutizing.  Since it is also not part of core XML  1.0 processing, it should be a trivial task to omit the absolutizing  behavior.</john>    <jonathan>  I don't think you'll be so lucky  with DSig as a whole, as the erratum also affects XPath filtering, and XSLT  transformations.  <snip/>  </jonathan>    <john>  Actually, I think that DSig will have to follow suit with C14N and REQUIRE  the maintenance  of the string literals.  As an application, DSig is  critically dependent on C14N for generating the message to be digested.  To  the extent that C14N is, conceptually at least, an application of XPath, so  is DSig.  If the C14N application requires the literals, then the  requirement to maintain them flows into DSig conformant applications.    Frankly, I don't see the big deal; in all the software I've tried so far, I  haven't found one that can't give me this string, so the inconvenience is  likely to be low.  Further, I believe that this approach eliminates the  problems you describe for both the C14N transform and the XPath transform.    I agree that this will be a problem for the XSLT transform.  I haven't  considered it before now, which is OK I think considering I just got word  today that XPath was going to change (it's won't even be on the public  errata yet).    The answer could be as simple as dropping XSLT as a transform, though I do  love XSLT and would hate to see that happen.  No matter what though, we  should probably address future concerns in this regard as concerns over the  impact of this erratum on the XSLT transform, not on C14N or the Xpath  transform.    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>    </john>        

      Hi,    I think the gremlin got you.  Please see [1].    [1]  http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/2000AprJun/0292.html    ***************************************  John Boyer,  Software Development Manager    PureEdge Solutions (formerly UWI.Com)  Creating Binding E-Commerce    v:250-479-8334, ext. 143 f:250-479-3772  1-888-517-2675  http://www.PureEdge.com  ***************************************        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Khaja E. Ahmed  Sent: Friday, June 23, 2000 3:27 PM  Subject: Re: No Character Normalization?      I did not get this informative and authoritative response.  Not sure if the  group was not copied on it or if the mail gremlin got to my inbox.  Could  this  possibly be mailed out to the group.   Thanks.    Khaja    John Boyer wrote:    > Hi Kevin,  >  > I appreciated your email, however, I did not get it (due to a meeting)  until  > after it was already answered.  Full credit for the informative and  > authoritative answer belongs to John Cowan.  >  > Sincerely,  > ***************************************  > John Boyer,  > Software Development Manager  >  > PureEdge Solutions (formerly UWI.Com)  > Creating Binding E-Commerce  >  > v:250-479-8334, ext. 143 f:250-479-3772  > 1-888-517-2675  http://www.PureEdge.com  > ***************************************  >  > -----Original Message-----  > From: Kevin Regan [mailto:kevinr@valicert.com]  > Sent: Friday, June 23, 2000 2:58 PM  > To: jboyer@PureEdge.com; w3c-ietf-xmldsig@w3.org  > Subject: RE: No Character Normalization?  >  > John,  >  > Thanks for the information.  >  > My greatest concern is to not have to tell my customer that "No, I  > can't sign that.  How did you create that document anyway?"  >  > If it is the usual case that documents are created in the normalized  > form, then it does not seem like a big issue.  What would happen  > in the case of an editor or application written in Java (Unicode)?  > It seems that this is the most important case given the close  > coupling of Java and XML.  >  > Another concern is whether a document can become "de-normalized" during  > transmission.  My previous question was not specific enough. I understand  > that documents can be converted to other character formats. However, I'm  > wondering if a document can leave one application in a normalized form, go  > through various character encodings, and enter another application  > with the characters no longer normalized (e.g.  A Java application to Java  > application might go from Unicode, to UTF-8 for transmission, and then  > back to Unicode in the other application).  >  > Finally, you mention that the detection of a non-normalized document  > would aid in the discovery of forgery.  My question is: should similar  > documents with different character models be equivalent?  > What would most people expect?  I don't really understand the usage  > enough to have an opinion on this...  >  > --Kevin        

      <TomParaphrase>  Must we strip all zero width no break spaces (U+FEFF = EF, BB, BF in UTF-8)  from our data  </TomParaphrase>    <john>  At last we see where our understated comment gets us into some  interoperability trouble.    For starters, the BOM and its UTF-8 encoding are considered to be at the  very beginning of the file (see http://www.cl.cam.ac.uk/~mgk25/unicode.html  by Marcus Kuhn).    Moreover, according to XML 1.0, the UTF-16 BOM is considered to be *outside  of* the data and used to qualify how to take the UTF-16 data and convert it  to UCS.  It is 'metadata' that XML does not retain.    In other words, the UTF-16 BOM is not U+FEFF or U+FFFE.  It is not intended  to represent a Unicode character of data, so it's just a 16-bit binary value  of FEFF or FFFE, the latter of which is illegal under Unicode anyway.    What I think we are saying is that we will not encode the UTF-16 BOM when  converting to UTF-8 because the BOM is not part of the data. However, I  think we are not clear in saying what will happen to our UTF-8 data if  U+FEFF appeared in the UTF-16 data stream *after* the BOM.    When translating from UTF-16 to UTF-8, I would think that the UTF-16 BOM  would be used solely to convert to UCS, but then if U+FEFF appears in the  actual data, then the corresponding UTF-8 sequence would appear in our UTF-8  data stream.    Indeed, the rationale for prepending of the UTF-8 for U+FEFF is at best  confusingly stated by the Unicode 3.0 standard on p.324 (this reference was  provided by Phillip H. Griffin of Griffin Consulting (http://asn-1.com)):    "In UTF-8 the BOM corresponds to the byte sequence EF(16)BB(16)BF(16).  Although there are never any questions of byte order with UTF-8 text,  this sequence can serve as a signature for UTF-8 encoded text where  the character set is unmarked."    How is this a 'signature' for UTF-8?  Isn't this also a valid string prefix  for a stream of ISO-8859-1 characters?    As well, what if the UTF-16 BOM is FFFE, which is not a valid UCS character?  Are we to conclude that UTF-8 encoded text is unidentifiable on machines  that would start a UTF-16 encoding with a BOM of FFFE?    Finally, in trying to use a unicode character normally associated with a BOM  as an ineffective signature, it is clearly not being used as a byte order  mark.  This is at least in part because it does not make sense to impose a  BOM on the actual UTF-8 data; a machine will represent the UCS characters  corresponding to the UTF-8 in the byte order of the machine, not the byte  order dictated by the UTF-8 encoding.    I believe this is why we don't understand the application of a BOM to UTF-8  data, neverminding actually putting U+FEFF *inside* the UTF-8 encoded data.    John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>    </john>      -----Original Message-----  From: tgindin@us.ibm.com [mailto:tgindin@us.ibm.com]  Sent: Friday, August 25, 2000 12:26 PM  Subject: RE: UTF-8 and BOM           I have only one disagreement with this.  Of course, BOM is not a legal  UTF-8 byte sequence - and neither is the UCS-2 representation of any  character in the Latin-1 supplemental set such as u-umlaut, which appears  in Martin's last name.  However, if you convert a UCS-2 string containing a  BOM into UTF-8, the BOM will be converted into the triple-byte sequence  xEF,xBB,xBF which is legal UTF-8, and converting it back to UCS-2 yields a  BOM or a zero-width no break space.  So, are we supposed to strip all  occurrences of "zero-width no break space" or not?              Tom Gindin    "John Boyer" <jboyer@PureEdge.com> on 08/25/2000 02:45:41 PM          <reagle@w3.org>, <w3c-ietf-xmldsig@w3.org>  Subject:  RE: UTF-8 and BOM        <Tom>       Actually, John, a UCS-2 BOM in big-endian order (U+FEFF) is a valid  UCS character known as "zero width no break space".  One in little-endian  order is not.  This is documented, among other places, in section 3.8  (Special Character Properties) of version 2.0 of the Unicode standard.       If you follow the table at the top of page 3 of RFC 2279, you will  always encode a character in the minimal number of bytes.  This table  appears on the same page as the surrogate pair warning, so if there is no  need to warn implementors about surrogate pairs in our spec there is also  no need to warn them about overlong character encodings.              Tom Gindin  </Tom>  <john>  Obviously I agree about the surrogate pair and overlong character warnings.  1) Martin's message didn't specify the overlong stuff, so I'm curious if he  has other warnings that *don't* come across in RFC2279.  Like you, I feel  that we have referred to RFC2279, so things that are clear in that RFC need  not be repeated.  2) The BOM may be a valid UCS character, but it is not a valid UTF-8 byte  sequence.  Martin's message asserted that it was valid UTF-8, which is what  I disagreed with.  Indeed, everything between 0 and 7FFFFFFF is a valid UCS  character (even if most have not been assigned to symbols yet).    John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>  </john>    "John Boyer" <jboyer@PureEdge.com> on 08/25/2000 02:13:37 PM          "Joseph M. Reagle Jr." <reagle@w3.org>  Subject:  RE: UTF-8 and BOM        Hi Martin,    At the last teleconference, Joseph decided we would leave it as is (comment  about BOM but not surrogates) because there was not consensus to change it  either way.    Although I am still not convinced of its necessity, I really don't mind one  way or the other, and will most likely be adding the BOM comment to the  next  C14N draft just because it doesn't seem to hurt anything.    Could you point me to some source I can cite which implies that a BOM at  the  front of UTF-8 is actually legal UTF-8? (e.g. an URL to ISO 10646 Annex R,  and a paragraph would help).  I ask because, according to RFC2279, a BOM  does not legally decode into a UCS character, so a conformant  implementation  would seemingly never generate a BOM, and it would throw an exception if  asked to decode one.  This is why I believe, in the absence of evidence to  the contrary, that the BOM comment is superfluous (but also why I don't  think it hurts to keep it).    On your last point about using too many bytes, are you referring to cases  such as having the eleven x bits of a two byte sequence containing  something  less than 80 (e.g. C0 80 in place of 00)?  That type of error came across  pretty clearly in RFC2279, so I don't think another RFC would be necessary,  but are there other cases that don't come across in RFC2279?    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Martin J. Duerst  Sent: Friday, August 25, 2000 2:09 AM  Subject: RE: UTF-8 and BOM      At 00/08/23 11:47 -0700, John Boyer wrote:  >I actually think we need to remove the comment about BOM *and* not put in  a  >comment about surrogate pairs.    No. You have to keep the comment about the BOM, because both  with and without a bom is legal UTF-8.    You better remove the comment about surrogates, because encoding  individual surrogates in UTF-8 is illegal. There are other things  that are illegal and still are sometimes done (e.g. using more  than the necessary number of bytes), and if we wanted to list  all of them, we would write another RFC for UTF-8, I guess.      Regards,    Martin.            >There does not seem to be any such thing as a need for a BOM for UTF-8.  As  >for surrogate pairs...  RFC2279 [1] clearly states that  >  >A) The only correct way to convert from UTF-16 to UTF-8 is through UCS-4  >B) The only correct way to convert from UTF-16 to UCS-4 is to fix the  >surrogate pairs.  >  >Moreover, RFC2781 [2] clearly states how to fix the surrogate pairs.  It  >does not seem necessary to add more text that tells the implementer how to  >transcode.  This job has been done by these other RFCs [1,2], both of  which  >are referenced in the XML Dsig WD.  >  >[1] www.ietf.org/rfc/rfc2279.txt  >[2] www.ietf.org/rfc/rfc2781.txt  >  >John Boyer  >Development Team Leader,  >Distributed Processing and XML  >PureEdge Solutions Inc.  >Creating Binding E-Commerce  >v: 250-479-8334, ext. 143  f: 250-479-3772  >1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>  >  >  >  >  >-----Original Message-----  >From: w3c-ietf-xmldsig-request@w3.org  >[mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of tgindin@us.ibm.com  >Sent: Wednesday, August 23, 2000 10:39 AM  >To: Joseph M. Reagle Jr.  >Cc: w3c-ietf-xmldsig@w3.org; duerst@w3.org  >Subject: Re: UTF-8 and BOM  >  >  >      If we retain wording excluding BOM's from UTF-8, as we currently  have  >it, I think that we should exclude surrogates as well.  >      The current text in section 6.5.1 reads "converts the character  >encoding to UTF-8 (without any byte order mark (BOM)) ", and corresponding  >text in section 7 reads "that coded character set is UTF-8 (without a byte  >order mark (BOM))"  The new text should probably read "... UTF-8 (without  a  >byte order mark (BOM) and with surrogate pairs converted to UCS-4 before  >conversion to UTF-8)" in both of these places.  I realize that RFC 2279  >(not 2379) explicitly requires surrogate conversion while it fails to  >mention BOM's for some reason, but the two issues are similar and many  >implementors do not understand the surrogate issue.  The wording about  >surrogates in versions 2.0 of the Unicode standard is actually somewhat  >similar to the wording about the "reversed byte order mark" U+FFFE.  >  >           Tom Gindin        

      This might be a no-brainer at this point, but I just noticed that KeyInfo is  not inside SignedInfo.    Why is this?    It seems that during signature generation, all data within KeyInfo can be  filled in prior to generating the SignatureValue.  The signer chooses his  identity before the SignatureValue is created.    Otherwise, the material in KeyInfo would seem to be largely untrustworthy  even if our signatures validate.  After validation, we would have to dig up  the real information from the actual certificates just to be sure that all  of this identity information wasn't substituted on us by an attacker.    On the other hand, perhaps it is done this way to force application  developers to obtain the information (like subject name) from the  certificate to avoid attacks from those who would generate a faulty  signature.    In which case, why bother breaking this information out into XML?    Thanks,         John Boyer        Development Team Leader,        Distributed Processing and XML        PureEdge Solutions Inc.        Creating Binding E-Commerce        v: 250-479-8334, ext. 143  f: 250-479-3772        1-888-517-2675   http://www.PureEdge.com                                

      Please visit the following site for further information about the Victoria  Face-To-Face    http://www.pureedge.com/about/dsig/index.htm    Also, please email the chairs (Joseph Reagle and Donald Eastlake) and myself  regarding your intent to attend this meeting so that we can attempt to make  changes if more than the expected number of people attend.    Thanks,  John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  jboyer@PureEdge.com        

      Based on your comments below, it is clear that we will have to tweak the  XPath serialization description.  The problem is that your sample output for  the XPath serialization is not what was intended.  The sample output you  show for c14n is the output I expect to see from Xpath serialization.    The section is called XPath 'filtering' because we view the XML document as  a single tree.  The mental model is that of performing a standard, ordinary  depth first tree traversal, rendering only those nodes that are in the  node-set.  We are trying to regenerate the actual document minus the parts  that are excluded by the XPath expression.  Your implementation duplicates  the subtrees in each tree of the forest and generally creates an enormous  result.    Obviously, I will have to make some changes so that this is clear, but  obviously agree on how the XPath serialization should generate most of its  output.  The serialization algorithm is quite similar to c14n, except in the  following ways:    1) The XPath serializer assumes a forest, so it handles fragmentary XML  documents.  2) The XPath serializer doesn't rewrite namespaces.  3) The XPath serializer doesn't do character model normalization.    Furthermore, the XML core WG just dropped C14N.  Since we need it to be  finished, they've handed it off to us, and we have the ability to change it  as necessary so that we finish.  When we are finished, there will be no  difference between c14n and XPath serialization, although I predict that  your current c14n code will be obsoleted.  Specifically, namespace rewriting  and character model normalization will be eliminated.    John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Petteri Stenius  Sent: Monday, May 15, 2000 12:16 PM  Subject: RE: Enveloped signatures          I think it would be good if the XPath serialization and c14n were closer to  each other, or even equal!      I'm not saying I need a c14n after a XPath transform, I'm saying that the  whole process of doing an XPath transform is not possible in one pass.    A simple example should clarify:    <A>  <B>text</B>  <Signature Id="S1">  </Signature>  </A>    The result node-set from the XPath expression for excluding the Signature  element is a list with the nodes:    A  B  text    The serialized output from the XPath expression is:    <A><B>text</B></A><B>text</B>text    Output from the combination of exclude-signature transform + C14N  serialization is simply:    <A><B>text</B></A>      Petteri      > -----Original Message-----  > From: John Boyer [mailto:jboyer@PureEdge.com]  > Sent: Thursday, May 11, 2000 10:17 PM  > To: Petteri Stenius; 'Joseph M. Reagle Jr.'  > Cc: IETF/W3C XML-DSig WG (E-mail)  > Subject: RE: Enveloped signatures  >  >  > I would be interested in knowing exactly why you feel you  > need c14n after an  > XPath transform.  After running the XPath expression, the result of  > serialization is quite similar to c14n in most respects and  > was written so  > that there would be no output ambiguities that did not result  > from changing  > the input document.  You should not need c14n, so one pass should be  > sufficient.  >  > Moreover, it seems that we are inheriting the c14n spec, and the two  > principal differences between the XPath serialization and  > c14n, which are  > namespace normalization and composed character normalization,  > are quite  > likely to be deleted (for reasons that will be discussed  > later).  Assuming  > this is true, though, means that the XPath serialization  > will, in essence,  > be equal to c14n.  >  > Thus, the only area of awkwardness that we are trying to  > overcome is the  > 'political' awkwardness of having applications provide support for a  > specific XPath exclusion transform without providing full  > XPath support.  >  > I don't mind if we want to do this, but the WG has avoided  > doing this in the  > past because it has, up to now, meant that we would have to repeat the  > definition of 'how to write' the result.  It's one thing to  > say 'I just want  > to exclude the Signature being created while calculating this  > DigestValue'  > but it's another thing entirely to recognize that you must  > still create a  > byte stream that can be digested.  >  > In other words, the enveloped-signature-transform still needs  > something like  > the XPath serialization to fit our current processing model.  >  > John Boyer  > Software Development Manager  > PureEdge Solutions Inc. (formerly UWI.Com)  > Creating Binding E-Commerce  > jboyer@PureEdge.com  >        

      Hi all,    My understanding was that transforms were required to include all parameters  in elements, so mixed content of the Transform element is not required.    It used to be required because we were just including whatever data was  necessary (XSLT or an XPath expression), so I think the MIXED setting is  legacy.    However, I think the idea behind transforms is that they be extensible in  the future.  In the past, Ed pointed out that ANY means any element defined  in the DTD.  However, if you omit the Transform <!ELEMENT declaration, I  think you can put whatever you want inside it with a maximum of a warning  from validating processors.  I believe we could still include the <!ATTLIST  without trouble.    John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Joseph M. Reagle  Jr.  Sent: Friday, September 01, 2000 6:53 AM  Subject: Re: AW: AW: Mixed Content Model for Transform?      My preference is for element only as well for Transforms. Does anyone oppose  this. Ed/John, is the mixed content for Transforms even relevant to the  types of transforms we'd expect people to write now?      At 15:40 9/1/2000 +0200, Gregor Karlinger wrote:  > > At 08:29 9/1/2000 +0200, Gregor Karlinger wrote:  > > >Yes, I think it would be fine to have the same structure for all kind  of  > > >algorithms.  > >  > > But are you arguing for consistency or for mixed? I could make them all  > > element only.  >  >I am arguing mainly for consistency. I personally would feel better with  >element only; if somebody wants to have mixed content, he can define a  >parameter element which allows this mixed content.        _________________________________________________________  Joseph Reagle Jr.  W3C Policy Analyst                mailto:reagle@w3.org  IETF/W3C XML-Signature Co-Chair   http://www.w3.org/People/Reagle/        

      Hi Merlin,    <merlin>  I meant to bring this up on the last teleconf but forgot..    1)    " 3. replace any element node E with E plus all descendants of E (text,    comment, PI, element) and all namespace and attribute nodes of E and its    descendant elements. "    " To retain comments while selecting the entire document, use the following    full XPointer: URI='#xpointer(//. | //@* | //namespace::*) "    I'm not sure if there is a subtlety that is lost on me, but would not  '#xpointer(/)' select the whole document? '/' returns the root node  which, by 3, is automatically expanded to include all descendants.  </merlin>    <john>The subtlety is that to root node is not an element.  However, it is  probably better to use #xpointer(/) and add a line before 3 that says that a  root node is replaced by its element, PI, comment children such that 3  (which would then be 4) would expand the node-set to cover the whole  document.    Any detractors to this change?  </john>    2)    " 1.Initialize an XPath evaluation context by setting the initial    node equal to the input XML document's root node, and set the    context position and size to 1. "    By "initial node" I presume you mean "context node"?    This is troublesome: If I do an XPath on URI='#foo' then the XPath  expresion '.' is not 'id("foo")' but '/'. In other words, XPath  and fragmentary URIs are incompatible. See 5) below.    <john>  Saw 5.  Don't understand the problem.  At its most basic level, set  membership is indicated by a boolean (1 or 0).  The URI="#foo" should result  in a node-set that is representative of the entire document (i.e. the  underlying tree is of the whole document)but only foo and its descendants  are in the set (marked with 1).  The fact that a node-set must, under the  covers, still maintain a tree structure is evident in the processing rules  for XPath expression evaluation.  There is no way to process the axes for  things like ancestor and child without retaining a parse tree.  As well, the result is not id("foo") which only returns foo, not  foo+descendants.  Finally, I don't understand how . becomes /.  The new XPath write-up  encumbers the implementer with the need to iterate the node-set, using each  node as the context node and evaluating the XPath expression given.  This  was done to make our xpaths look like xsl:template xpaths as well as to  optimize our process by allowing a node-set to pass through a number of  node-set-aware transforms without being serialized.  See comments below for  more info.  </john>    This is particularly important because, although an XPath can reflect  the position of the node at signing time, if it is moved into another  document then it will not verify.    <john>I don't fully understand this, but I'm guessing it comes from a  different understanding about the new processing model</john>    3)    Namespace attributes, C14N, XPaths and XPointers. I'll write this  shortly.    4)    An XSLT is applied to an XML document, so why a binary input type?    I have no strong opinion on this, it is just an observation.    <john>Our transform processing model allows us to move one of two things  into a transform: octet stream or XPath node-set (or sufficiently functional  alternative).  The typical XSLT implementation expects to read the XML  document from a source file (octet stream).  A number of XSLT processors  have advanced features that allow reading from an 'extended' input source  that, under the covers, contains the XML document in a DOM tree.  However,  this is not, strictly speaking, an XPath node-set.  Particularly, it is not  a node-set with some of the nodes omitted.  Finally, even if an XSLT  implementation were to accept an XPath node-set, it seems likely that it  would be looking for a node-set with the root or a single element  identified, and it would use the occurences of xsl-applytemplates to descend  into the document or element.  So, I chose octet stream to avoid ambiguities  and possible conflicts of processing models.</john>    5)    The current content distinction of "binary" or "node set" does not  seem sufficient to me. I should I have raised this earlier, but...    In my implementation, and I think this might be reflected in others,  I distinguish three content types: "binary", "node set" and "node  tree". A tree being a limited set.    The output of a fragment or empty URI is a tree. The output of an  XPath, XSLT or full XPointer is a set which may be a tree.    <john>  It seems impossible to me to do most of what XPath requires without having  an underlying tree representation that maintains ancestor, sibling and other  informational relationships between the nodes.  Therefore, I view a node-set  output as including a tree at all times.  The node-set just says which parts  of the underlying tree are included and which are omitted should the tree  ever be serialized.  </john>    The input to an XPath or XSLT is a tree. More importantly, the  context node is the root of the tree. This is why a set is invalid.  But a set which is a tree is okay.    <john>  The input to XPath is, for all intents and purposes, a node-set with the  root node of the parse tree identified.  I believe we are thinking of the  same thing.  </john>    Also, a complexity arises in whether an expression should be  allowed to go above the context node '..' / '/; or not.    <john>It absolutely MUST be able to go above the context node.  The context  node is just an initializer, but there must be a parse tree behind the  scenes.  It is impossible to process the ancestor axis otherwise, and this  would violate the XPath specification.  If implementers are having trouble with this, we need to know ASAP.  I can  rewrite the sections to account for this, although this results in more  processing at run-time.  </john>    My suggestion would be that we should mandate that the context  node should be treated as the document root node during XPath  processing (and it should inherit appopriate attributes). In  other words, our transform should operate indistinguishably were  a C14N/parse step present.    <john>This would be the way I would fix the problem, but it is also a step  we were trying to avoid.  Before we do this, could you identify a  non-obscure implementation of Xpath that has this problem?  I ask because  such an XPath implementation would seem to be unusable in an XSLT  implementation, which is part of the stated raison d'etre for XPath.</john>    This can be implemented efficiently with a slightly customized  XPath processor, and on a standard XPath processor by simply  performing the explict C14N/parse step.    Things don't seem to be coming together terribly cleanly, whatever  we do.    <john>Actually, I thought it was cleaner in the following ways:    1) We addressed the fact that we actually did not have a spec that would  have resulted in interoperable signatures for something as simple as  URI="#foo".    2) We finally have an enveloped signature transform that works.    3) We have a processing model that does not require conversion to an octet  stream at the end of every transform if successive transforms can take pass  through a node-set.    4) The Xpath expressions are now simpler (not containing that awful (../ |  //@* | //namespace::*) as a prefix).  Further, they now look exactly like  the Xpath expressions that one would write if one were creating an  xsl:template match expression.    Sure the current stuff is longer, but that is because we MUST eliminate the  ambiguities and because there seems to be substantial interest in providing  an enveloped signature transform.    John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>    </john>    Merlin        

      Hi Martin,    At the last teleconference, Joseph decided we would leave it as is (comment  about BOM but not surrogates) because there was not consensus to change it  either way.    Although I am still not convinced of its necessity, I really don't mind one  way or the other, and will most likely be adding the BOM comment to the next  C14N draft just because it doesn't seem to hurt anything.    Could you point me to some source I can cite which implies that a BOM at the  front of UTF-8 is actually legal UTF-8? (e.g. an URL to ISO 10646 Annex R,  and a paragraph would help).  I ask because, according to RFC2279, a BOM  does not legally decode into a UCS character, so a conformant implementation  would seemingly never generate a BOM, and it would throw an exception if  asked to decode one.  This is why I believe, in the absence of evidence to  the contrary, that the BOM comment is superfluous (but also why I don't  think it hurts to keep it).    On your last point about using too many bytes, are you referring to cases  such as having the eleven x bits of a two byte sequence containing something  less than 80 (e.g. C0 80 in place of 00)?  That type of error came across  pretty clearly in RFC2279, so I don't think another RFC would be necessary,  but are there other cases that don't come across in RFC2279?    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Martin J. Duerst  Sent: Friday, August 25, 2000 2:09 AM  Subject: RE: UTF-8 and BOM      At 00/08/23 11:47 -0700, John Boyer wrote:  >I actually think we need to remove the comment about BOM *and* not put in a  >comment about surrogate pairs.    No. You have to keep the comment about the BOM, because both  with and without a bom is legal UTF-8.    You better remove the comment about surrogates, because encoding  individual surrogates in UTF-8 is illegal. There are other things  that are illegal and still are sometimes done (e.g. using more  than the necessary number of bytes), and if we wanted to list  all of them, we would write another RFC for UTF-8, I guess.      Regards,    Martin.            >There does not seem to be any such thing as a need for a BOM for UTF-8.  As  >for surrogate pairs...  RFC2279 [1] clearly states that  >  >A) The only correct way to convert from UTF-16 to UTF-8 is through UCS-4  >B) The only correct way to convert from UTF-16 to UCS-4 is to fix the  >surrogate pairs.  >  >Moreover, RFC2781 [2] clearly states how to fix the surrogate pairs.  It  >does not seem necessary to add more text that tells the implementer how to  >transcode.  This job has been done by these other RFCs [1,2], both of which  >are referenced in the XML Dsig WD.  >  >[1] www.ietf.org/rfc/rfc2279.txt  >[2] www.ietf.org/rfc/rfc2781.txt  >  >John Boyer  >Development Team Leader,  >Distributed Processing and XML  >PureEdge Solutions Inc.  >Creating Binding E-Commerce  >v: 250-479-8334, ext. 143  f: 250-479-3772  >1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>  >  >  >  >  >-----Original Message-----  >From: w3c-ietf-xmldsig-request@w3.org  >[mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of tgindin@us.ibm.com  >Sent: Wednesday, August 23, 2000 10:39 AM  >To: Joseph M. Reagle Jr.  >Cc: w3c-ietf-xmldsig@w3.org; duerst@w3.org  >Subject: Re: UTF-8 and BOM  >  >  >      If we retain wording excluding BOM's from UTF-8, as we currently have  >it, I think that we should exclude surrogates as well.  >      The current text in section 6.5.1 reads "converts the character  >encoding to UTF-8 (without any byte order mark (BOM)) ", and corresponding  >text in section 7 reads "that coded character set is UTF-8 (without a byte  >order mark (BOM))"  The new text should probably read "... UTF-8 (without a  >byte order mark (BOM) and with surrogate pairs converted to UCS-4 before  >conversion to UTF-8)" in both of these places.  I realize that RFC 2279  >(not 2379) explicitly requires surrogate conversion while it fails to  >mention BOM's for some reason, but the two issues are similar and many  >implementors do not understand the surrogate issue.  The wording about  >surrogates in versions 2.0 of the Unicode standard is actually somewhat  >similar to the wording about the "reversed byte order mark" U+FFFE.  >  >           Tom Gindin  >        

      Hi Gregor,    As I said in a prior email, I personally agree with automatic exclusion from  the DigestValue calculation of any signature element that will be ancestor  of the DigestValue.  This is what we did in XFDL since there seemed to be  little point in making everyone write the exclusion logic every time (all  signatures in XFDL are enveloped because the form is always the root).    The group previously discussed this, albeit briefly, and decided against.  There may be some minutes or archive feedback reflecting this, or it may not  have been recorded.    However, I am not willing to take a strong position on this because I think  that it is not hard for one's application to recognize a specific expression  *constructed by the application designer* to exclude the signature element  from the DigestValue calculation.  Thus, the application will function  without full XPath support, and will express its signatures in a way that  can be understood by other applications.  But if you want write a generic  piece of code that understands everyone's signatures, you are pretty much  required to implement the XPath transform, in which case the specific  expressions used by various applications will be supported by your generic  program.    I believe this is the reason why the group did not want to make th exception  you are recommending.    John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com    <Peter>    A question here: Why can't we simply exclude the entire Signature element?    That's what Gregor and I have been discussing today. I would strongly  prefer    that! I'd like to know if anything spoke against it.....  </Peter>    <John>    > Sorry Peter, but that's not an accurate paraphrase.  It is quite  important    > to be able to exclude certain elements, but that one requires a great  deal    > of precision in identifying what must be excluded to ensure that you are    > excluding what you meant to exclude.    >    > Exclusion by id excludes an element based on the value of a single    > attribute, and this is not enough in most cases to accurately identify  the    > information to be excluded, and to restrict one's exclusion to only that    > information.  </John>    I will try to phrase more accurately than Peter ;-):    If an enveloped signature is to be constructed, then there obviously the  following problem occurs: One has to take care that (at least) tholse parts  of the Signature element are omitted which are not available at the time of  computing the reference's digest, which are the SignatureValue and the  DigestValue of the reference currently worked on.    The main point of my discussion with Peter yesterday was: What important  case  could be out there in the world that one cannot simply omit the Signature  element as a whole in such a case of an enveloped signature?    If there exist important data entities inside the Signature element that  should also be signed, why not simply add another references directly to  that items?    Neither Peter nor I are argueing against the XPath transform in general, but  I  feel that the spec should be kept as simple as possible if we don't buy  severe restrictions with such simplicity. And in my opinion omitting the  whole  Signature element does not lead to any restrictions.    Regards, Gregor  ---------------------------------------------------------------  Gregor Karlinger  mailto://gregor.karlinger@iaik.at  http://www.iaik.at  Phone +43 316 873 5541  Institute for Applied Information Processing and Communications  Austria  ---------------------------------------------------------------        

      Hello all,    As Merlin suggested, I changed the full xpointer URI for selecting the whole  document including comments to #xpointer(/), which also required that I add  a line explaining that the root node should be expanded to its children.    I also tweaked the here() function to address concerns raised by Kent Tamura  and I, as well as to make it easier to implement.    Finally I added the warning to the XPath transform about matching text  separated by comment nodes even when those comments were excluded from the  input node-set.    The changes are marked in orange.    It was not necessary to make comments about a non-node-set return for the  XPath transform since its new construction no longer allows this to occur  (yet another reason to prefer the new design!).    I did not attempt to make any changes to account for the Limitations stated  in the latest C14N draft (which is in Joseph's hands at the moment and  should be released to the group next week).  The limitations are neither  many nor drastic, but should result in requirements on dsig implementation  developers.    Thanks,  John Boyer                text/html attachment: Overview.html          

      -----Original Message-----  From: Martin J. Duerst [mailto:duerst@w3.org]  Sent: Wednesday, March 15, 2000 7:22 PM  Subject: RE: XSL WG comments on XML Signatures      I'm glad to see that the XSL experts are helping the XML  signature group to improve their use of XPath.    <John>Yes, their luminance leaves us in awe. How can we ever achieve such  greatness?</John>    I'm adding a few comments below so that when XPath  filtering is rewritten, these issues can  be cleaned up at the same time.    <John>  XPath filtering will not be substantially rewritten.  Based on Clark's  feedback, we can remove the parse function and instead simply assert that  the transform input is parsed and provided to XPath as a node set.  The  notions of lex and exact order will be removed (since we cannot directly  specify the parse).  The serialize function will stay since we must now  modify it to say that it will lex order the attributes as part of its  natural behavior.  I'm sure we can also say that it gets called automatically if the expression  results in a node-set.  </John>    The i18n WG/IG was also rather lost on seeing $exprEncoding and $exprBOM.    The XPath engine of course has to know in which encoding the XPath  expression was in. But that's the XPath engine, not the XPath expression.  It would be extremely strange to include some switch in an XPath  expression saying something like     If the XPath expression came in as Shift_JIS, then do A, else do B.    <John>  The problem that this lowly piece of dark matter saw was simply that the  transform input could be in a different encoding than the document  containing the signature (and hence the XPath expression).    Suppose a signature in a UTF-16 document contains a URI to an XML document  that is encoded in UTF-8.  The result of the URI dereference is a UTF-8  document, whose tag names, attributes, etc. are incomparable to the  conditions set forth in the XPath expression.  Unless you convert the XPath  expression to the same encoding as the XML document, or convert the XML  document to the same encoding as the expression, then you will not be able  to evaluate the expression.    At a minimum, a particular implementation could throw an exception if it  couldn't handle the conversion.    The alternative to this solution is to standardize on a particular encoding,  which would imply that every XML document would have to be converted before  running XPath, which is not a very efficient solution.  </John>    As for the BOM, the same arguments apply. In addition, the XPath  expression is element (or attribute?) content, so there is never  a BOM in front of it. To distinguish between BE and LE, just use  UTF-16-BE and UTF-16-LE if needed.    <John>  The XML document we receive as input to the transform MUST have a BOM in  front of it if it is UTF-16, according to the XML spec.  So, obviously  exprBOM doesn't refer to that.    You are exactly right that there is no BOM in front of the XPath expression  string, which is exactly why the context needed to be told what the BOM  should be (unless you weren't planning to solve the encoding problem).    The problem is that if one application reads a UTF-8 document and leaves it  in UTF-8, then the output will be UTF-8, which implies one digest value.  If  another tool reads the UTF-8 then converts to UTF-16 because of some  limitation on their XPath expression engine, then the output will be UTF-16  (unless they take the special effort of converting back to UTF-8 (???) to  overcome the limitation of their toolset).  So, a signature created by the  first product would not verify in the second product.    John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  jboyer@PureEdge.com    </John>    Regards,   Martin.        #-#-#  Martin J. Du"rst, I18N Activity Lead, World Wide Web Consortium  #-#-#  mailto:duerst@w3.org   http://www.w3.org/People/D%C3%BCrst        

      Hi Joseph,    -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Joseph M. Reagle  Jr.  Sent: Monday, March 27, 2000 12:17 AM  Subject: RE: Enveloped signatures and XPath      [woops, didn't finish]  http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/2000JanMar/att-0250/01-  transforms2.htm    It would probably be useful to show the example in 6.6.3.4 in the context  of the transform and Xpath element.    <john>True.</john>    >SignatureValue and KeyInfo child elements and the and the DigestValu    (typo)    In the SignatureValue example I might be confused (these small screens at  the IETF make it hard for me to think <smile>) but why eliminate  DigestValue? That element type is reserved for the reference digests,  which do not change during actual signature generation. The digest value  of the SignedInfo does change, but that is not explicitly represented so  it need not be eliminated. Also, eliminating KeyInfo (and any  objects) seems odd. This is at the signers option, but if I were signing  the Signature, I'd want to sign that info as well.    <john>  The expression is written to filter the data that will be digested by  DigestValue (as evidenced by the fact that it omits DigestValue). The  KeyInfo 'can be' assigned before computing DigestValue.  However, I cannot  recall anywhere in the spec  that says that implementations must assign  KeyInfo before computing DigestValue.  Perhaps I missed it (please point it  out as I would be happier if it were there), and if it isn't there, then  perhaps it should be.  Once it is, then you are right that KeyInfo need not  be omitted.    I omitted KeyInfo because of the possibility that DigestValue could be  computed beforehand.  By leaving it out, my example works regardless of how  the spec is written.  Note that it does no harm to leave out the KeyInfo  since it will be signed by the SignatureValue (right?), and there is no  mechanism for omitting material from that which SignatureValue signs.  </john>    Also, would it be  better to set the context node to the the closest ancestor Signature  element (instead of at the document root)?    <john>  Actually, no.  An enveloped signature is a signature is enveloped by some  larger document that we would like to sign.  The desired root of the  document was indicated to us and should not be changed by us since we would  be leaving out information that the user wants to sign.    Furthermore, in general there is no condition under which the transform  should change the context node to be other than how it is specified now.  The transform is assumed to have no special knowledge about the input, nor  its place within that input.  The transform only knows that it has received  some input from a previous transform and that it must apply the expression  to that data.    John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com    </john>        

      Hi Henry,    Yes, what is very much at issue is how to interpret a node in a node-set.  However, the assertion that a node in a node-set is meant to indicate "point  at everything you can access from it" is flawed on two counts:    1) every node in the entire document is accessible from any node in the  document.  2) your intent in making this statement is to have each node be  representative of the subtree for which it is the root.  This is a subset of  what is reachable from the node, but more importantly it defies the use of  the term 'set'.  The XPath spec is quite clear about the fact that a  node-set contains no duplicates.  If the intended meaning of 'node' is 'self  plus all descendants including namespaces and attributes', then it should be  impossible for me to produce a node-set containing an element and a child of  that element since the child is already implicitly included by virtue of  including its parent.  Current implementations permit a child to be a  node-set with its parent, substantiating the view of node-set as a 'set of  nodes', not a set of subtree roots.    Moreover, the view that xpointers 'point to things' rather than 'return  things' has little to do with the problem and serves only to cloud the  issue.  Nonetheless, the XPath specification says "Each function in the  function library is specified using a function prototype, which gives the  return type...", which substantiates the view that the id() function  *returns* a node-set. So, XPointer's claim that "XPointers don't _return_  anything, they _point_ to things" simply means that they return a node-set  that 'points to' or indicates certain nodes (locations in the case of  Xpointer).    However, the problem is and has always been about what do you do with the  'pointer'?  What does it mean to 'dereference' the pointer.  Applications of  XPath and XPointer are free to define what they intend to do with the output  result of the XPath or Xpointer expression. In the case of XPath, I have  interpreted the node-set as a set of nodes because that's what the W3C chose  to call it and because that's how XPath expression evaluators act.  So,  within XPath serialization and c14n, the act of dereferencing a node-set  produces the text of precisely and only those nodes that are actually in the  node-set.    There is no substantiation within XPath to interpret a node-set as a  subtree-root-set because a node and its child can appear in the node-set.    Finally, the emails from DeRose [1] and Clark [2] are in the dsig archive.    [1]  http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/2000AprJun/0170.html  [2]  http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/2000AprJun/0166.html    They are about the interpretation of an expression like    id("E")/descendant-or-self::node()    which will only produce a node-set containing E and its descendant elements,  PIs, comments, and text, but will exclude the namespace and attribute nodes  of E and its descendant elements.  In your prior email [3], you used the  term 'exfoliated', by which one must assume you meant that you found no  evidence that id("E") would produce a result that was devoid of the  descendants, namespaces and attributes of E.  My reference those emails from  Clark and DeRose was intended to substantiate the point that indeed the  result of id("E") is 'exfoliated' and further that, by design, the namespace  and attribute nodes are omitted from descendant class axes (which also  implicitly substantiates the viewpoint that one should create a node-set  indicating a node AND its descendants when one INTENDS TO indicate or 'point  to' the node AND its descendants).    [3]  http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/2000AprJun/0224.html    John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com        

      Hi Joseph,    Yes, we're doing the omit thing.  The XPath transform currently views the  node-set result of an expression as a 'set' that can contain all nodes of  the document or any subset.  Nodes in the set get rendered to the output,  and nodes not in the set get omitted from the output.    However, there seems to be this desire to misuse the term set and have a  node in a node-set (or location-set) indicate itself plus all of its  descendants (including attributes and namespaces).  Such an interpretation  leaves the interesting ambiguity of whether or not each node's absence from  the set was intentional.    I suggested the possibility of changing to <keep> and <omit> if the W3C  actually wants node-sets to be interpreted as something other than a set.  I'm trying to think of a name for it, but it's kind of unusual, so not many  options are presenting themselves.  How about calling it "subtree-root-set"?  The only problem with this is that trees are defined recursively, so there  would be the question of what happens when a 'subtree-root-set' contains a  subtree root that is a descendant of another subtree root in the set.    Somehow, the interpretation of node-set as a set seems much more clean.    John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com      -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Joseph M. Reagle  Jr.  Sent: Monday, June 05, 2000 2:39 PM  Subject: RE: Default transforms  Importance: High      Good point. While the Clark's response [1] to your original email [2] seemed  to state that this is acceptable behaviour (that it was their intent only to  return the node from the id() function call, and none of its children), this  is not in keeping with the text about XPtr Bare Names which states:            The bare name form of addressing is provided for HTML compatibility.          ... To provide an analog of the HTML fragment identifier behavior          (for resources with XML media types, which may include XML-          compliant HTML) when the identifier that has been provided in the          target resource is syntactically an XML Name          http://www.w3.org/TR/xptr#synth-2.1.2    I think this is a problem beyond our own employment of XPtr and an  inconsistency in the XPtr spec itself. I'll forward this on ...    Regardless, with your <keep> proposal, are these element going to populate  the actual XML instances being signed? Are we going back to the omit thing?      [1]  http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/2000AprJun/0166.html    http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/2000AprJun/0165.html      At 02:15 PM 6/5/00 -0700, John Boyer wrote:   >Hi Joseph,   >   >The one point I'd make is that our expectations regarding URI="#E" are not   >the same as a call to the XPath id("E").  The XPath transform only renders   >nodes in the indicated node-set.  The id function returns a node-set   >containing the identified element, but all of its descendants are not in  the   >node-set.  So if E has the following markup:   >   >   ><elem id="E">I am signed.</elem>   >   >We expect URI="#E" to generate the entire line above, but the XPath   >expression id("E") would only generate:   >   ><elem></elem>   >   >Under our current design, you'd have to tell the XPath to include all of  the   >descendants.  This was the source of my angst earlier over the meaning of   >descendant-or-self::node() because I'd like to say:   >   >id("E")/descendant-or-self::node()   >   >but this doesn't give me the attributes and namespace declarations, so the   >result would be:   >   ><elem>I am signed.</elem>   >   >Furthermore, it appears to be syntactically invalid to put anything after   >the slash that would give me *all* of the nodes.  Therefore, URI="#E" must   >be stated as being equal to an XPath transform with the following   >expression:   >   >(//. | //@ | //namespace::*)[count(ancestor-or-self::* | id("E")) ==   >count(ancestor-or-self::*)]   >   >The beginning parenthetic means to consider all nodes in the whole tree in   >the node-set, and the square-bracketed expression determines whether E is   >the given element node or any of its ancestors.  Only the element E and  its   >descendants (including namespace and attribute nodes) will pass this test.   >   >By the way, we could change the XPath transform to make this a little   >simpler by adding two expressions, <keep> and <omit>.  The idea would be   >that any node in the keep set would have itself and all of its descendants   >(including namespace and attribute nodes) rendered automatically, except   >nodes in the omit set.  A node in the omit set, and all of its descendants   >(including namespaces and attributes) would be omitted from rendering,   >except those in the keep set, and so on.  Naturally, it should be an error   >if the intersection of the two sets is non-empty (equivalently, if the  size   >of the union is not equal to the sum of the sizes of the two sets).   >   >With this paradigm, URI="#E" would be equal to an Xpath transform with   ><keep>id("E")</keep> as a parameter and no <omit> parameter.   >   >Perhaps the chairs should bat this formulation around for a while and talk   >to the implementers about it because it might make sense to parameterize   >c14n in the same way.   >   >John Boyer   >Software Development Manager   >PureEdge Solutions Inc. (formerly UWI.Com)   >Creating Binding E-Commerce   >jboyer@PureEdge.com   >   >   >-----Original Message-----   >From: w3c-ietf-xmldsig-request@w3.org   >[mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Joseph M. Reagle   >Jr.   >Sent: Monday, June 05, 2000 1:41 PM   >To: Petteri Stenius   >Cc: IETF/W3C XML-DSig WG   >Subject: Re: Default transforms   >   >   >At 11:26 AM 6/5/00 +0300, Petteri Stenius wrote:   > >Chapter 4.3.3 of [1] reads:   > >   > >"[URI] permits identifiers that specify a fragment identifier via a   > >separating number/pound symbol '#'. (The meaning of the fragment is   >defined   > >by the resource's MIME type). XML Signature applications MUST support  the   > >XPointer 'bare name' [Xptr] shortcut after '#' so as to identify IDs   >within   > >XML documents. The results are serialized as specified in section   > >6.6.3:XPath Filtering. For example,"   > >   > >   > >My interpretation of 2.1.1 is that there is *no* default serialization  or   > >canonicalization algorithm. But reading 4.3.3 would suggest that XPath  is   > >used by default.   >   >Hi Petteri. There was a time when I advocated "clean-URIs" such that if   >anything beyond merely dereferencing a URI via its protocol scheme was   >needed, it had to be explicitly represented in a transform. But there's no   >such thing as a 'clean-URI' so we support URIs with fragment identifiers.   >When the dereferenced object is XML, that means it's an XPtr expression.  We   >REQUIRE implementations to support the 'bare name' [1], which is a short   >hand of the XPath id() function [2].   >   >So generally speaking there is no default transforms. BUT, if a fragment   >identifier is used within a <Reference URI="..."> that identifies an XML   >resource, that means XPtr processing is done and the results need to be   >serialized according to 6.6.3 [3]. Note, not all XPtr expressions that  might   >fit in the URI will be supported by Signature applications.   >   >I don't find the fact that people are specifying transforms in the URI to  be   >very 'clean' but at least it's consistent with the rest of the world (or  so   >I'm told <smile>). That's why we recommend:   >   >        Regardless, such fragment identification and addressing   >        SHOULD be given under Transforms (not as part of the URI)   >        so that they can be fully identified and specified. For instance,   >        one could reference a fragment of a document that is encoded   >        by using the Reference URI to identify the resource, and one   >        Transform to specify decoding, and a second to specify an   >        XPath selection.   >        http://www.w3.org/TR/xmldsig-core/#sec-Reference   >   >Is this agreeable to your reading? Should we change the text to make   >something clearer?   >   >[1] http://www.w3.org/TR/xptr#synth-2.1.2   >[2] http://www.w3.org/TR/xpath#section-Node-Set-Functions   >[3] http://www.w3.org/TR/xmldsig-core/#sec-XPath   >   >_________________________________________________________   >Joseph Reagle Jr.   >W3C Policy Analyst                mailto:reagle@w3.org   >IETF/W3C XML-Signature Co-Chair   http://www.w3.org/People/Reagle/   >    _________________________________________________________  Joseph Reagle Jr.  W3C Policy Analyst                mailto:reagle@w3.org  IETF/W3C XML-Signature Co-Chair   http://www.w3.org/People/Reagle/        

      Hi Rick,    I considered this feedback, as shown in the latest c14n issues document, but  came to the conclusion that I did not see anything confusing about    "The content of the doc element is NOT the string #xC2#xA9 but rather the  two octets whose hexadecimal values are C2 and A9, which is the UTF-8  encoding of the UCS codepoint for the copyright symbol (C)."    which appears as the only note in the example.  It seems impossible to miss.    John Boyer  Team Leader, Software Development  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Rick Jelliffe  Sent: Wednesday, December 13, 2000 1:45 AM  Subject: Canonical XML 3.6        S. 3.6 of Canonical XML is still confusing, in that the notation is not  explained.    It would be better to give a hex dump of the whole document     < d  o c  >      <  / d  o c >   3c64 6f63 3eC2 a93c 2f64 6f63 3e    Cheers  Rick Jelliffe        

      Paul,    Actually, in the sentence directly after the one from which you cited, I  quote:    "The Unicode 16-bit encoding form is identical to the ISO/IEC 10646  transformation format UTF-16."    As to 'badly' misreading the UTF-8 spec, perhaps you could define how this  differs in your mind from simply misreading.  Your characterization seems a  bit harsh considering I've already said that I don't have any access to  UCS-2 documentation, so I am having to guess from all of the shrouded half  statements in the documents that I do have.  The examples in Section 4 do in  fact have triplets of UCS-2 characters that represent 'something', and I  have no way of knowing really whether this is considered to be a single  defined sequence as far as UCS-2 is concerned or whether it represents  characters in a three character word, or whether two of the three 16-bit  values represent a single thing.    It would be more helpful, since you seem to know, to tell us whether or not  UCS-2 == Unicode, which is the single most important bit of information we  need.  If UCS-2 != Unicode, does UCS-2 have the same representation power as  UCS-4?  This would be the second most important bit of information we need.    John Boyer  Team Leader, Software Development  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        

      By the way, I retract the statement "Obviously this is not good for XML  Base".  I forgot to take that out.  By the time I got finished writing the  document, it was clear that the reason xml:base should be omitted from  canonical forms had to do with the different perspective-- that one is  creating a new output document.  Since xml:base is intended to help with the  input of documents, the point neither adds nor detracts from the intended  utility of xml:base. Rather, it simply helps to clarify the conditions under  which xml:base is useful.    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of John Boyer  Sent: Friday, July 28, 2000 1:05 PM  Subject: Possible solution for XML Base problem      Thanks Kevin.    I had suspected that it is impossible for most XML processors to distinguish  content obtained from external entities due to section 4.4.2 of XML 1.0.    However, I've also given some additional thought to this whole problem of  having c14n change the base URL when it pulls external entities into the  document, and I now feel that I need further convincing that this is a bad  thing.    I think that c14n does the right thing with respect to the XML 1.0 default  base URI.  Moreover, this consideration leads me to believe that  preservation of xml:base in canonicalized documents is faulty.  Obviously  this is not good for XML Base.    It seems to me that relative URIs related to XML syntax seem to get used and  discarded (e.g. SystemLiteral) or replaced by absolute URIs (e.g. XPath  handling of namespaces).  As long as XPath and hence XSLT implementations  respect the XML 1.0 requirement to given a different base URI to content  derived from external entities, then everything should work fine. Based on  Kevin's feedback, I suspect there may be implementations that do not  conform, but at least the specifications are consistent so hopefully the  implementations will be fixed.    As for content that is defined to be a relative URI by an application, the  content is treated like opaque character data.  No generic XML specification  (like C14N or XSLT) can possibly know that the data is supposed to be a  relative URI.  Therefore, if the generic XML application (e.g. C14N) does  something like generate internal content from an external entity reference,  then the fact that the default base URI for that internal content is now the  new document is actually the correct thing to do.  In the case of C14N, if  the output is consumed by the application that can process the canonicalized  XML, the base URI is in fact set properly for that application to be able to  use its relative URIs.    The only place where we run into trouble is with the actual use of xml:base.  If I have an element E containing a relative URI that was formerly obtained  by replacing an external entity reference, and if the replacement occurs  within an element A that has an xml:base, then the xml:base will apply to E.    The xml:base supposedly indicates the original source document.  If it does  not, then it is incorrectly set.  Once the document has been canonicalized,  though, the source document is the canonical form, so the xml:base should be  removed until a permanent home for the canonical form is found.    In short, XML base is used for input, whereas c14n is about output.  Please  give some thought to a counterexample to the idea of omitting xml:base from  the c14n output.    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>          -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Kevin Regan  Sent: Thursday, July 27, 2000 2:31 PM  Subject: RE: DSig comments on XML Base        I have no access to the XML processor.  My library receives DOM Document  and Element objects when creating the signature.  When verifying the  Signature a deligate to the user to find and parse the URI.  I'm not  sure I totally understand the discussion that had taken place, but  I would say that I have no way of distinguishing which parts of  the source came from external entities, and forcing the user to  structure the DOM subtree that I am signing in a particular way is  a big no no.  Currently, the only thing that my library requires  is that the user hand me a DOM Document or Element that has been  parsed with a validating parser (with ignorable whitespace not  included).    --Kevin    -----Original Message-----  From: John Boyer [mailto:jboyer@PureEdge.com]  Sent: Thursday, July 27, 2000 1:59 PM  Subject: RE: DSig comments on XML Base      Hi Jonathan,    OK, that makes some sense.  What you're saying is that we should have  c14n  extend the Xpath data model by adding an xml:base to the top level  element  of external entities.    This must be done by modifying the XML processor that generates the  node-set.  I wonder how easy this is for implementers.    I agree with you that trying to read between the lines on XML 1.0 is a  waste  of time, but I disagree with the implication that this is what I'm  doing.  There are quite specific lines that tell an XML processor developer that  they need not distinguish between content derived within the document  versus  content derived externally.    So, TAMURA Kent, Kevin Regan and others: could you please let us know if  you  can do this?  If so, then I'd like to do what you suggest Jonathan, then  place a note about the residual problem with base URI for top-level PIs.    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        

      Hi all,    So far, I've seen two issues for the here() function.    The first was raised by Kent, who asked what to return for he<!-- -->re().  Good one!  The XPointer folks are going to need to solve this too, but I  think the answer is to return the text node containing the 'h' of here().    The second issue is a very serious and difficult problem surrounding the  feasibility of actually setting up a return value for here().    For those who may just be joining this thread, and because noone has yet  said what the problem actually is, I'm going to assume that the problem is  as follows (please correct if there is some other problem in addition to  this one):    The overarching design we have is that an octet stream is passed from  transform to transform indicating the data on which the transform must act.  It is this data for which the XPath transform creates a node-set.  In order  to set up a return value for here(), we require a node-set representative of  the current document containing the XPath expression.  These are two  different node-sets.    The here() function defined in XPointer (and defined by the Xpath transform)  is actually only useful when the current document's node-set and the XPath  evaluation node-set are one and the same.  The $signature-id variable is a  way to make an indication of a node that will be created when the XPath  transform input is converted from an octet stream into a node-set.    I do not see a clear way to resolve this problem at this time.  However,  there is also a problem with the $signature-id proposal that lead us to do  something like here() in the first place.    The problem is that $signature-id is being set equal to the value of an  attribute that happens to be called 'id'.  Any number of elements could have  such an attribute, and all could use the same 'id' value as the signature in  order to have themselves omitted from the digest value computed over the  result of the XPath expression being evaluated.  Furthermore, having these  equivalent 'id' values is permissible under non-validating XML parsers and  also under validating parsers if the 'id' attribute is not actually of type  ID (and we have no way of knowing this).  Hence, security risk.    As well, enveloped signatures were not the only use for here().  At the  Victoria FTF, Mariano Consens championed the here() function because it  allowed the signature of elements whose positions relative to the Signature  element were predefined and maintained under movement of those signatures to  other documents.  For example, suppose one wanted to create a signed e-check  in which the check element was identified by id="C" and the signature  element immediately followed the check element.  Now suppose one wants to  move 10 such signed checks into a compound document.  The identical id  settings would not pass a validating XML parser, so the id="C" cannot  actually be used.  To solve the problem, here() would be used to help  identify "the sibling element immediately preceding 'this' signature".    The idea behind here() is that it is supposed to uniquely identify the  Signature element of the signature currently being created.  Perhaps we can  give more thought to how to fix it since the $signature-id and all related  ideas have a fairly serious problem and given that there are uses beyond  enveloped signatures.    Finally, note that I would've preferred a more generic mechanism for the  XPath transform in which we allowed the Signature element creator to set up  any desired variable context rather than having the one specific, implicit  variable named $signature-id.  However, I am loathe to ask for this change  at this late stage unless it solved a specific problem, and as we can see  from $signature-id, variables can easily cause more problems than they  solve.    John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Kevin Regan  Sent: Monday, July 24, 2000 10:36 AM  Subject: Re: XMLDSIG proposal: enveloped signatures, xpath and here()        Isn't the Id attribute for Signature optional?  In this  case, I don't think that it can be used as a general way  of identifying the Signature node from within the spec (although  applications may set an Id for the Signature node and use  it in other ways).    --Kevin      On Sun, 23 Jul 2000, TAMURA Kent wrote:    >  > In message "XMLDSIG proposal: enveloped signatures, xpath and here()"  >     on 00/07/17, Merlin Hughes <merlin@baltimore.ie> writes:  > > After implementing the transforms from WD-xmldsig-core-20000711  > > I have been left with some conceptual troubles over the  > > specification of the enveloped signature and XPath transforms;  > > and, in particular, here().  >  > These troubles are the same as I wrote in the following mail:  > > Date: Mon, 3 Jul 2000 14:16:06 +0900  > > From: TAMURA Kent <kent@trl.ibm.co.jp>  > > To: w3c-ietf-xmldsig@w3.org  > > Subject: Transform I/O is a sequence of octets  >  >  > In message "XMLDSIG proposal: enveloped signatures, xpath and here()"  >     on 00/07/17, Merlin Hughes <merlin@baltimore.ie> writes:  > > If the latter, then why not eliminate the here()  > > function and replace it with an XPath variable that  > > corresponds to the Id of the Signature.  > >  > > The resulting XPath definition of the enveloped signature  > > transform would be:  > >  > > <XPath xmlns:dsig="&dsig;">  > >   (//. | //@* | //namespace::*)  > >  > [not(ancestor-or-self::dsig:Signature[attribute::Id=$signature-id])]  > > </XPath>  >  > I prefer this proposal.  This is simpler and easier to implement  > than here().  >  > --  > TAMURA Kent @ Tokyo Research Laboratory, IBM  >        

      Hi TAMURA-san,    In section 5.4 of the XPath spec, the namespace URI for all namespace nodes  is declared to be NULL, so the comparison as defined always works (the  primary key is always the same).    Another way to put this is that I intend option A below.  I haven't seen  option B used elsewhere, and I don't think there would be any benefit in  deriving one here.    Thanks,  John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of TAMURA Kent  Sent: Monday, April 10, 2000 8:42 PM  Subject: Re: XPath Transform, 3rd version        In message "XPath Transform, 3rd version"      on 00/04/06, "John Boyer" <jboyer@PureEdge.com> writes:  > TAMURA-san: You posted a question about order of namespace nodes.  The  > paragraph about serializing the namespace and attribute axes states that  the  > primary key for lex order of nodes on these axes is the namespace URI, so  I  > don't know what the problem is.  Do you see a problem with using namespace  > URI (e.g. are you thinking we need to always add the default definition  for  > xmlns to the initial evaluation context)?    A namespace declaration has no namespace, that is to say, there  is no namespace binding on "xmlns" prefix.  A URI as the value  of a namespace declaration is not its namespace.  So, there are  two interpretations:      a) Namespace declaration has no namespace URI.  The primary    key is empty.  The secondary key is a local name (the declared    prefix.)      b) Regards the value of a namespace declaration as namespace    URI.  The primary key is the URI.  The secondary key is a    localname (the declared prefix.)    --  TAMURA Kent @ Tokyo Research Laboratory, IBM        

      Actually, it does not take a fundamental redesign to add this feature.  It  would simply require a new axis like all-descendants.  Furthermore, I  expressed an opinion that it seemed overly cumbersome to indicate the entire  parse tree *because* the ability to apply certain tests to every node (e.g.  give me every node except those having a certain ancestor) is quite useful  in a variety of circumstances.  You declared that you didn't believe there  was a problem.  Is there some reason for this belief (i.e. something that  would follow the word *because*)?    John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com      -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of James Clark  Sent: Wednesday, May 24, 2000 7:40 PM  Subject: Re: Meaning of /descendant-or-self::node()      John Boyer wrote:    > Do you think there is any possibility that this might get fixed at some  > point in the future?    I don't think there is any possibility whatever that the meaning of  /descendant-or-self::node() will change.  You can't fundamentally  redesign a spec after it's become a Recommendation. (I don't agree, by  the way, that the current design is flawed in this respect, but that's  academic at this point.)    James        

      Hi Anli,    The newlines are included.  They are represented by text nodes in the XPath  data model, so we don't need to add extra linefeeds to get the multiline  effect.    So, if the document element and all its content are on one line, then so it  will be in the output, but if the document element contains new lines, they  will appear in the output.      John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Anli Shundi  Sent: Wednesday, July 05, 2000 5:42 AM  Subject: no newlines after end-element tags in c14n ?      The new canonicalization does not seem to specify whether  a newline is appended after end-element tags.  It mentions those  after processing instructions and comments, though.    Does this mean that the canonical output would be a single line,  unpleasant to the eye like:    <root attrib1="dsadsa"><son  attr="fdsfds"><daughter>value</daughter></son></root>    I would have expected something along the lines of    <root attrib1="dsadsa">  <son attr="fdsfds">  <daughter>value</daughter>  </son>  </root>    Am I overlooking something pretty obvious ?    Anli Shundi    Institute for Data Communications Systems  University of Siegen  Germany        

      I wonder what the reason was for that exception.  It seems to me that a node  test which does not include a namespace prefix should use the default  namespace.    Nonetheless, the spec has made the exception, and it was the intent of the  example that the given Reference element be placed in a Signature element  with an xmlns set to &dsig; in accordance with our specification.    Therefore, I agree that the example needs to be tweaked, and I also agree  that your modification would suffice.  For the same of brevity, though, I  will probably tweak the example to be that given below unless there is some  objection:      <Transform Algorithm="http://www.w3.org/TR/1999/REC-xpath-19991116">      <XPath xmlns:dsig="&dsig;">  (//. | //@* | //namespace::*)[not(ancestor-or-self::dsig:Signature)]      </XPath>  </Transform>    I've modified the Xpath's initial evaluation context to include a namespace  declaration for dsig, which can then be used to namespace qualify the  Signature elements more compactly.    This will have an even better impact on the latter example as well as the  one for enveloped signature.  I should be able to incorporate this change  this Thursday.    ***************************************  John Boyer,  Software Development Manager    PureEdge Solutions (formerly UWI.Com)  Creating Binding E-Commerce    v:250-479-8334, ext. 143 f:250-479-3772  1-888-517-2675  http://www.PureEdge.com  ***************************************      -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of TAMURA Kent  Sent: Monday, June 19, 2000 5:44 PM  Subject: XPath examples in the spec.      Chapter 6 of the spec. has some XPath examples.  The following  is one of them:           <Transform Algorithm="http://www.w3.org/TR/1999/REC-xpath-19991116">           <XPath>(//. | //@* |  //namespace::*)[not(ancestor-or-self::Signature)]           </XPath>         </Transform>    This expression has element name 'Signature' without a prefix.  Accoding to XPath 1.0, non-prefixed name like it must not have  namespace.  This example does not work because the Signature  element must have the 'http://www.w3.org/2000/02/xmldsig#'  namespace.    I think that we can write like '*[local-name()="Signature" and  namespace-uri() ="http://www.w3.org/2000/02/xmldsig#"' in such  cases.      Third paragraph of http://www.w3.org/TR/1999/REC-xpath-19991116#node-tests  This is the same way expansion is done for element type  names in start and end-tags except that the default  namespace declared with xmlns is not used: if the QName  does not have a prefix, then the namespace URI is null.    --  TAMURA Kent @ Tokyo Research Laboratory, IBM        

      Hi Kent,    It is easy enough to change the examples, but the purpose of the examples is  to show how XML can change as the result of c14n.  If one is using a  validating parser, one is expected to be able to modify the examples to  account for this.  It's really easy; you put DTD declarations into the  document until it validates, and all of your DTD declarations are removed,  so the canonical form is unchanged.    So, clearly I am most interested in your troubles with the non-validating  version of Xerces.  It certainly appears to me that Xerces does not fully  comply with XML 1.0 if it does not read attribute types and provide them to  the application for use.  It's DOM call may decide not to work, but even if  you have to implement id searching yourself, the attribute type should at  least be available for you to do this.  If not, IBM needs to do a patch for  you.    It would actually be better to get tools out there that can process the  examples as they are than it would be to let this go and have  non-interoperable signatures because even the major vendors don't follow the  spec closely enough for the ever scrutinous sha-1 hash.    John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>      -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of TAMURA Kent  Sent: Friday, November 17, 2000 12:39 AM  Subject: Re: AW: Call for Implementation: Canonical XML Becomes a W3C  Candidate Recommendation        In message "RE: AW: Call for Implementation: Canonical XML Becomes a W3C  Candidate   Recommendation"      on 00/11/10, "John Boyer" <jboyer@PureEdge.com> writes:  > As well, your assertion that the Xerces DOM parser cannot select by id  > unless using validation seems, on the surface, to contradict IBM's  > interoperability report since they are most certainly using Xerces and yet  > were able to complete example 3.7.  >  > Moreover, if the id() function is something you have to implement, it is  not  > actually very hard to implement as long as 1) the parser correctly types  the  > id attribute when not validating, and 2) it is easy to hook your resulting  > id() function into the Xpath implementation that evaluates the expression  > given in example 3.7.  Are you saying that one of these two things isn't  > working.    The Document.getElementsById() method of Xerces-J's DOM  implementation works only with the validating parser.  while I  tested the example 3.7, the parser output many validation  errors.  Fortunately, the parser does not stop parsing and  validation on a validation error.    In general, a validating XML processor MAY stop parsing on a  validation error, and a non-validating XML processor need not  process attribute types.  We would not get correct results of  example 3.4 and 3.7 with such XML processors.  I think example  3.4 and 3.7 have to be modified so that they become valid  documents.    --  TAMURA Kent @ Tokyo Research Laboratory, IBM        

      Hi Martin,    I am personally OK with this approach, but I wonder how many existing  documents it will rule out signing.    For example, unless I'm misreading rfc2396, <e xmlns="string"/> is now  deprecated.  It seems ludicrous that I cannot sign well-formed document.  It  is as if it is not well-formed, which contradicts the plenary's own  intentions.    I think instead that we should focus on the intent of the plenary as  manifested in Answer 4 of [1], which indicates that we should be calling  these things namespace *names*, not namespace URIs.  We want conformant  software to retain the original namespace name; we don't care about URIs.    [1] http://www.w3.org/2000/09/xppa#47802880    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: Martin J. Duerst [mailto:duerst@w3.org]  Sent: Monday, September 11, 2000 7:20 PM  Subject: RE: C14N: Non-absolutized URIs      At 00/09/11 17:03 -0700, John Boyer wrote:  ><jonathan>  >No, the fact that XPath permits application-dependent behavior means only  >that the plenary has forced it (along with all other groups) to accept  >application-depedent behavior.  ></jonathan>  >  ><john>Right, and as an application of XPath, we are choosing the behavior  >that is most appropriate to our application.  No matter how much the  plenary  >wants to force things on dsig, there is nothing they can do to change the  >behavior of a sha-1 hash.  We MUST have a single behavior, therefore we  MUST  ></john>    No, if you follow the recommendation of the plenary (which I think you  should  do), then the right way is to say that relative URI's behaviour is  undefined,  and that they therefore should not be used for signatures. C14N applications  may/should/must issue a warning when they find one of these when the are  used to prepare for signing.      Regards,   Martin.        

      Oops, yes I used incorrect terminology.  This replacement should be  satisfactory:    Furthermore, as I pointed out to the dsig group yesterday, and with which  you indicate agreement below, we are free to process an Xpath node-set or  XPointer location-set in any manner necessary.  Therefore, the XPointer  URI="#E" can  be processed by XPath serialization (or by the new c14n) by processing  E plus all nodes that have E as an ancestor.  In other words,  subtree(id("E")).  =================================    For the sake of ensuring that there is a resolution whether or not a  subtree() function exists, let me reiterate that, without the subtree()  function, we can still define the processing of the XPointer URI="#E" in  terms of Xpath serialization (or by the new c14n) by using the following  expression:    (//. | //@ | //namespace::*)[count(ancestor-or-self::* | id("E")) =  count(ancestor-or-self::*)]    (The Xpath transform processes nodes on the node-set and omits nodes not in  the node-set).    John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com        -----Original Message-----  From: connolly@w3.org [mailto:connolly@w3.org]  Sent: Thursday, June 08, 2000 10:43 AM  w3t-tech@w3.org; w3c-ietf-xmldsig@w3.org  Subject: Re: XPTr bare names and XPATH id()      John Boyer wrote:  >  [... lots of stuff that I agree with deleted ...]    > Furthermore, as I pointed out to the dsig group yesterday, and with which  > you indicate agreement below, we are free to define the XPointer URI="#E"  as  > indicating E plus all nodes that have E as an ancestor.  In other words,  > subtree(id("E")).    Not so. The XPointer spec says what #E means for XML, and it  says that it means the same thing that #xpointer(id("E")) means.  http://www.w3.org/TR/2000/CR-xptr-20000607#bare-names    You can't change the relationship between #E and  #xpointer(id("E")) without changing the XPointer spec.      --  Dan Connolly, W3C http://www.w3.org/People/Connolly/        

      Attached is a new version of the XPath transform, which now has far less  content except for describing how to initialize the new c14n.  Also, the function this() was changed back to here() because the XPointer  group accepted our definition of the function.    I also tweaked the ending of the Enveloped signature transform because there  is no longer an independent notion of XPath serialization (it's all in c14n  now).  No substantive change was made to that document.    The only unusual point is that, in reviewing the old XPath transform  material, I realized that the c14n spec, Section 5 is missing material on  what to do when an XPath expression does not return a node-set.  The  material about taking the string value of numbers, booleans and string, then  expressing it in UTF-8 will be added to the next c14n in Section 5.  As  well, the editorial tweaks suggested by Joseph will be incorporated.    John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com          text/html attachment: transforms6.htm          

      Hi Henry,    Actually, there isn't much doom and gloom going on, and we seem to be doing  better than being close to a resolution.  We already have a number of  resolutions.  All of this began very simply when I pointed out a necessary  correction to the dsig spec because there was a difference between what the  xpath expression id("E") returns versus what our spec claimed would be the  serialized result.    Most of what you wrote below explains the basic notions of XPath, which I  have been actively working with for almost a year now.  There is no  confusion on my part regarding these basic issues, and I have indeed written  much of the same material in recent emails.    However, I would disagree on one minor point: the definition of string-value  does not provide a definition of subtree that includes namespace and  attribute nodes.  Please look again at the definition of string value,  especially the string-value description for element nodes [1], which states  that the string value of an element is the concatenation of the string  values of its *text node descendants*.  In other words, no visitation of  namespace and attribute nodes is performed by the string-value DFS  algorithm.  This entire thread would have been very small if namespace and  attribute nodes were included in descendancy because we could've just  serialized the node-set result of    id("E")/descendant-or-self::node()    Despite this minor point, I am glad that you (and Daniel Veillard [2]) agree  that applications are free to use node-sets in any way that is convenient,  since I believe it makes the most sense for the purpose of serializing or  canonicalizing XML to treat a node-set as a set of nodes, where inclusion in  the set means inclusion in the textual output, and exclusion from the set  means exclusion from the textual output.  The major source of our prior  disagreement seems to have been the assertion that a node-set should always  indicate subtree roots, which was not justified by subsequent comments that  Xpointers are pointers taht indicate what is accessible (since everything is  accessible from any point in the tree).    Furthermore, as I pointed out to the dsig group yesterday, and with which  you indicate agreement below, we are free to define the XPointer URI="#E" as  indicating E plus all nodes that have E as an ancestor.  In other words,  subtree(id("E")).    This segues nicely to my final question.  As I pointed out in prior emails,  the actual XPath expression that corresponds to the above definition of  URI="#E" is somewhat clumsy, but it is possible to say what we mean to say  in an XPath expression.  This is why I claim that we do not, in fact, have a  doom-and-gloom problem. However, you made the statement that defining a  subtree() function would "be counterproductive, as that function flattens  the tree and loses information in doing so."  Notwithstanding Dan Veillard's  comments to the contrary [2], I do not think this is the case.  When we  create a node-set containing the entire subtree, the document order of the  nodes retains the information necessary for us to create a canonical form or  a serialization that can be passed to a digest algorithm (where document  order for namespace and attribute nodes is defined by sorting [3, 4]).  Could you please explain if this does not adequately address your concern  about a flattened tree?    In conclusion, then, I really do not think we disagree on much if anything  now that we have both familiarized ourselves with the other's position.    [1] http://www.w3.org/TR/xpath#element-nodes  [2]  http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/2000AprJun/0231.html  [3] http://www.w3.org/TR/xml-c14n  [4] http://www.w3.org/TR/xmldsig-core/#sec-XPath    John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com      -----Original Message-----  From: Henry S. Thompson [mailto:ht@cogsci.ed.ac.uk]  Sent: Thursday, June 08, 2000 2:57 AM  w3t-tech@w3.org; w3c-ietf-xmldsig@w3.org  Subject: Re: XPTr bare names and XPATH id()      "John Boyer" <jboyer@PureEdge.com> writes:    Let's back up and try again -- I feel like I've arrived late to a  party where everyone is already deep in a doom-and-gloom-laden  discussion about the awful consequences of something which hasn't  actually happened.  I think we're not actually very far from a  resolution, with your messages on another thread pointing the way, if  we reconceptualise a bit.    1) Nodesets.  Nodesets are introduced into the XPath data model to  represent the semantics of XPath expressions.  The intrinsic semantics  of a node set is a _disjunction_.   The interpretation of a nodeset as  the value of an XPath expression is:  "Each of the members of this set  satisfies the expression".    This is _really_ important: the value of the XPath expression '//foo'  is the set of all element nodes in a document whose name is 'foo' --  each of them, independently, is an answer to the instruction "Find me  something be starting from the root and looking for a 'foo' element".  Similarly, the value of the XPath expression 'id(baz)' is the set of  all element nodes in a document whose declared-as-type-id attribute  has the value 'foo'.  Now XML validity constraints (which must be in  play or we wouldn't know which attributes are of type id) require that  at most one such element exists, so the nodeset is either empty or  singleton.    It would be seriously incompatible with this fundamental aspect of  XPath to include in result nodesets nodes which did _not_ satisfy the  expression.    2) Nodes as results.  XPath expressions have values, which are  nodesets.  XPointer uses XPath expressions to pick out one or more  points in XML documents.  This is made clear as early as the  introduction [1], which uses words such as 'locate', 'address',  'choice', 'reference', 'target', etc.  It is entirely up to  applications what semantics they attach to such locations: "The  structures located with XPointer can be used as link targets or for  any other application-specific purpose".    In particular, it is clearly open to applications to specify that the  location picked out by an XPointer, whether short-frag, explicit-id or  other XPointer, is used by DSig as the root of a document subtree.  XML Schema, XInclude and XPath itself take this approach, so there's  plenty of precedent.    3) What does an XPointer point to?  The XPath REC introduces a data  model to answer this question [2].  It is clear from this exposition,  in particular from the definition of 'string-value', that the document  subtree rooted in a particular node is well-defined.    Net: XPointer is just fine for your purposes, all that is required is  to state that the DSig interpretation of an XPointer is as picking out  the entire document subtree rooted at the node identified by that  pointer.  You do _not_ need to do this by defining a further XPath  function such as your suggested 'subtree' -- indeed to do so what be  counterproductive, as that function flattens the tree and loses  information in doing so.    Hope this helps -- if not I suspect a 'phone call is the next step.    ht    [1] http://www.w3.org/TR/xptr#N598  [2] http://www.w3.org/TR/xpath#data-model  --    Henry S. Thompson, HCRC Language Technology Group, University of Edinburgh            W3C Fellow 1999--2001, part-time member of W3C Team       2 Buccleuch Place, Edinburgh EH8 9LW, SCOTLAND -- (44) 131 650-4440      Fax: (44) 131 650-4587, e-mail: ht@cogsci.ed.ac.uk       URL: http://www.ltg.ed.ac.uk/~ht/        

      Hi Doug,    John,      Thank you for the opportunity to comment on this updated draft.  My  previous suggestions seem to have been addressed quite well in this version.  I have a few new questions:      a.. In section 2.1 (with regard to the third paragraph), please confirm  that comments in the internal subset are always discarded, regardless of any  Boolean flag controlling overall handling of comment nodes.  Words to this  effect may be a worthwhile addition to this section.      b..      c.. <john>They are, by virtue of eliminating the DTD as listed in  section 1.1.  I will add a parenthetic statement to clarify this in Section  2.1 as requested.</john>      a..      b.. In the bullets near the end of section 2.2, the term "sorted  lexicographically" is ambiguous.  Do you mean that namespace and attribute  nodes are output in order from least to greatest lexicographically?  Or,  greatest to least?  (The later examples show the first.)    <john>Lexicographically literally means 'dictionary order', which is  ascending in the chosen alphabet (UTF-8 in our case), so I did not think  there was ambiguity here.</john>      In the same bullets, why are attribute nodes output using an order derived  from the namespace URI values?  Such a requirement seems more appropriate if  the Canonical XML recommendation includes namespace re-writing rules.  As  things are now, why not sort the attributes using the namespace prefix as  the primary key?      <john>They are sorted by namespace URI because this follows more closely  the intent of XML Names, which is to identify namespaces by URI+localname,  not by prefix+localname.  Thus, the effect of the sort is to group together  all attributes that are in the same namespace.  Though not a requirement for  producing an unambiguous canonical form, it is preferrable, particularly if  one factors in the optics of *appearing* to violate the intent of XML names  by sorting with prefixes, even if one is not technically violating the  intent.</john>      a.. In the last two bullets in section 2.3, the addition of leading #xA  characters according to the given rules will add such characters in most  contexts.  Comments and processing instructions are likely to occur within  the document and will thus have a greater document order than the document  element.  I believe you meant to limit this addition to processing  instructions and comment nodes with a greater document order than the end of  the document element.    <john>Actually, I meant what was said, which is that the leading and  trailing #xA are added to *children of the root node* with the document  order characteristics given in Section 2.3.  Only comments outside of the  top-level document element can be children of the root node.      a.. As an example of the previous point, the "Canonical Form  (commented)" example in the table of section 3.1 should (according to the  existing rules) have a leading #xA prior to "Comment 1."      b..      c.. <john>Actually, the point of examples was to make sure everybody  understood exactly what was meant by the prose in the specification.  There  should not be a leading #xA prior to Comment 1 because it is a child of  element <doc>, not a child of the root node.</john>      d..      e.. Since validating XML processors are required to normalize (remove)  any leading or trailing whitespace in an attribute value where that  attribute is declared to be of a type other than CDATA, the canonical form  for the normId element in section 3.4 should be <normId id="'    	 '"></normId>.  That is, this example should not have a space  between the enclosing quotation marks and the first and last apostrophes.    <john>Agreed.  In [1], I mentioned this to Karlinger.      [1]  http://lists.w3.org/Archives/Public/w3c-ietf-xmldsig/2000JulSep/0492.html      So, in summary, I intend to fix example 3.4 in the way described in [1],  and I intend to add a parenthetic clarifying the loss of comments in DTDs  due to loss of DTDs in Section 2.1.  Good?      Thanks,    John Boyer      </john>      thanx,        doug      Doug Bunting    cXML Standards Manager    Ariba, Inc.      -----Original Message-----    From: John Boyer [mailto:jboyer@PureEdge.com]    Sent: September 11, 2000 14:51    To: Doug Bunting; TAMURA Kent; Muraw3c@Attglobal. Net; Anli Shundi;  lesch@w3.org; Martin J. Duerst; Petteri Stenius    Subject: Last Call        Hi all,      You are getting this email because the new September 7 version of C14N [1]  addresses last call issues that include changes based on your feedback.  It  would be very helpful if you could have a look at the last call issues list  [2], read the resolutions, and send an email to the dsig group to indicate  either that you are satisfied that your issue was resolved or if you require  further changes.      PLEASE SEND YOUR RESPONSE TO THE DSIG GROUP so I can provide links from  the last call document to your affirmation.      Thanks for your patience and kind attention to this matter.  We would like  to submit for candidate recommendation next week, so if you could cut some  time out of this week to do this, I would really appreciate it.      [1] http://www.w3.org/TR/2000/WD-xml-c14n-20000907    [2] http://www.w3.org/Signature/2000/09/06-c14n-last-call-issues.html      Thanks,           John Boyer          Development Team Leader,          Distributed Processing and XML          PureEdge Solutions Inc.          Creating Binding E-Commerce          v: 250-479-8334, ext. 143  f: 250-479-3772          1-888-517-2675   http://www.PureEdge.com                                

      Hi Gregor,    Excellent work. I see that now.  The list of children of root does not  include text nodes, so I can add a sentence to c14n section 1 explicitly  stating that there are no text node children of root, then tweak the c14n of  PIs and comments to say that the closing ?> or --> will be followed by a  single #xA if the node is a child of the root.    Note to implementers:  this makes 2 confirmed changes so far    1) The change above will (and obviously must) happen.  2) Also recall earlier comments on this list that mean we must change text  node rendering to include changing all '>' characters to > (as was the  case in the prior c14n spec).  Based on XML [1] rules 10, 15 and 16, this  change is not needed for PIs, comments, attributes and namespaces.    Thank you,  John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com      -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Gregor Karlinger  Sent: Saturday, June 03, 2000 2:19 AM  Subject: RE: Comment on Canonical XML draft of 2000-06-01, clause A.3      Ups, no references included ...    [1] XML Information Set: http://www.w3.org/TR/xml-infoset#infoitem.document  [2] XML XPath Language: http://www.w3.org/TR/xpath#root-node  [3] XML 1.0: http://www.w3.org/TR/REC-xml#sec-white-space    > Since neither the XML Infoset [1] nor the XPath data model [2] allow text  > children in the root element, I don't see a good foundation for your  > interpretation of [3].    Gregor  ---------------------------------------------------------------  Gregor Karlinger  mailto://gregor.karlinger@iaik.at  http://www.iaik.at  Phone +43 316 873 5541  Institute for Applied Information Processing and Communications  Austria  ---------------------------------------------------------------        

      <Tom>       Actually, John, a UCS-2 BOM in big-endian order (U+FEFF) is a valid  UCS character known as "zero width no break space".  One in little-endian  order is not.  This is documented, among other places, in section 3.8  (Special Character Properties) of version 2.0 of the Unicode standard.       If you follow the table at the top of page 3 of RFC 2279, you will  always encode a character in the minimal number of bytes.  This table  appears on the same page as the surrogate pair warning, so if there is no  need to warn implementors about surrogate pairs in our spec there is also  no need to warn them about overlong character encodings.              Tom Gindin  </Tom>  <john>  Obviously I agree about the surrogate pair and overlong character warnings.  1) Martin's message didn't specify the overlong stuff, so I'm curious if he  has other warnings that *don't* come across in RFC2279.  Like you, I feel  that we have referred to RFC2279, so things that are clear in that RFC need  not be repeated.  2) The BOM may be a valid UCS character, but it is not a valid UTF-8 byte  sequence.  Martin's message asserted that it was valid UTF-8, which is what  I disagreed with.  Indeed, everything between 0 and 7FFFFFFF is a valid UCS  character (even if most have not been assigned to symbols yet).    John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>  </john>    "John Boyer" <jboyer@PureEdge.com> on 08/25/2000 02:13:37 PM          "Joseph M. Reagle Jr." <reagle@w3.org>  Subject:  RE: UTF-8 and BOM        Hi Martin,    At the last teleconference, Joseph decided we would leave it as is (comment  about BOM but not surrogates) because there was not consensus to change it  either way.    Although I am still not convinced of its necessity, I really don't mind one  way or the other, and will most likely be adding the BOM comment to the  next  C14N draft just because it doesn't seem to hurt anything.    Could you point me to some source I can cite which implies that a BOM at  the  front of UTF-8 is actually legal UTF-8? (e.g. an URL to ISO 10646 Annex R,  and a paragraph would help).  I ask because, according to RFC2279, a BOM  does not legally decode into a UCS character, so a conformant  implementation  would seemingly never generate a BOM, and it would throw an exception if  asked to decode one.  This is why I believe, in the absence of evidence to  the contrary, that the BOM comment is superfluous (but also why I don't  think it hurts to keep it).    On your last point about using too many bytes, are you referring to cases  such as having the eleven x bits of a two byte sequence containing  something  less than 80 (e.g. C0 80 in place of 00)?  That type of error came across  pretty clearly in RFC2279, so I don't think another RFC would be necessary,  but are there other cases that don't come across in RFC2279?    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Martin J. Duerst  Sent: Friday, August 25, 2000 2:09 AM  Subject: RE: UTF-8 and BOM      At 00/08/23 11:47 -0700, John Boyer wrote:  >I actually think we need to remove the comment about BOM *and* not put in  a  >comment about surrogate pairs.    No. You have to keep the comment about the BOM, because both  with and without a bom is legal UTF-8.    You better remove the comment about surrogates, because encoding  individual surrogates in UTF-8 is illegal. There are other things  that are illegal and still are sometimes done (e.g. using more  than the necessary number of bytes), and if we wanted to list  all of them, we would write another RFC for UTF-8, I guess.      Regards,    Martin.            >There does not seem to be any such thing as a need for a BOM for UTF-8.  As  >for surrogate pairs...  RFC2279 [1] clearly states that  >  >A) The only correct way to convert from UTF-16 to UTF-8 is through UCS-4  >B) The only correct way to convert from UTF-16 to UCS-4 is to fix the  >surrogate pairs.  >  >Moreover, RFC2781 [2] clearly states how to fix the surrogate pairs.  It  >does not seem necessary to add more text that tells the implementer how to  >transcode.  This job has been done by these other RFCs [1,2], both of  which  >are referenced in the XML Dsig WD.  >  >[1] www.ietf.org/rfc/rfc2279.txt  >[2] www.ietf.org/rfc/rfc2781.txt  >  >John Boyer  >Development Team Leader,  >Distributed Processing and XML  >PureEdge Solutions Inc.  >Creating Binding E-Commerce  >v: 250-479-8334, ext. 143  f: 250-479-3772  >1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>  >  >  >  >  >-----Original Message-----  >From: w3c-ietf-xmldsig-request@w3.org  >[mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of tgindin@us.ibm.com  >Sent: Wednesday, August 23, 2000 10:39 AM  >To: Joseph M. Reagle Jr.  >Cc: w3c-ietf-xmldsig@w3.org; duerst@w3.org  >Subject: Re: UTF-8 and BOM  >  >  >      If we retain wording excluding BOM's from UTF-8, as we currently  have  >it, I think that we should exclude surrogates as well.  >      The current text in section 6.5.1 reads "converts the character  >encoding to UTF-8 (without any byte order mark (BOM)) ", and corresponding  >text in section 7 reads "that coded character set is UTF-8 (without a byte  >order mark (BOM))"  The new text should probably read "... UTF-8 (without  a  >byte order mark (BOM) and with surrogate pairs converted to UCS-4 before  >conversion to UTF-8)" in both of these places.  I realize that RFC 2279  >(not 2379) explicitly requires surrogate conversion while it fails to  >mention BOM's for some reason, but the two issues are similar and many  >implementors do not understand the surrogate issue.  The wording about  >surrogates in versions 2.0 of the Unicode standard is actually somewhat  >similar to the wording about the "reversed byte order mark" U+FFFE.  >  >           Tom Gindin  >        

      Hi Rick    <rick>  I missed it, twice!  Or at least on two separate occassions I read the  text, got identically confused and then later both times figured out what  was going on (only to forget).  In both cases, I think I assumed that  there was a typo and the & had been missed out from the things that looked  like numeric character references.  </rick>    I agree the form better.    The above is an example of what appears to be going on with this example.  It should read 'I don't agree that the suggested form is better', but the  above is how it goes if one doesn't read every second word.    The point is that misunderstandings are bound to occur if one creates one's  own interpretation of how to fix what are initially perceived to be errors.  It is easy to imagine inserting the word 'is' at the second to last  position, but it isn't what I meant.  It is preferable to look at all the  words in the sentence before assessing what I meant.    <rick>  I think it is bad speccing to present something that looks like XML but  isnt.  </rick>    Unfortunately, your suggested fix also looks like XML, and one still has to  read the notes to decipher what is really meant.  I don't think it's a bad  specification because it requires the reader to read the whole example  before trying to implement what the example suggests.    To wit, if I were to change the contents of the canonical form box to the  way you suggested, it is quite conceivable that we would receive letters  saying 'I was confused because I thought the hex dump had to come after the  doc end tag, and I didn't read the notes till later so I had to develop all  of this hex dumping code that I don't really need.  So, the spec should be  changed to say that the canonical form is <doc>#xC2#xA9</doc>, and it should  have a note explaining that the content between the doc tags are two bytes  expressed in hexadecimal'. 8-)    <rick>  Having the explantation after the event is not much help, because the  confusion has already ocurred.  </rick>    The explanation has to appear somewhere, and what you see in 3.6 is the  standard format used in all of the examples.    <rick>  I hope you will consider my option.    Cheers  Rick Jelliffe  </rick>    I've done this because it has come up before.  I chose the method you  currently see because it is the method of denoting hex characters in the  output that appears in examples in XML 1.0 second edition (and in the XML  erratum from which the example is drawn).  I agree that the example in c14n  takes a slightly different form, but it was the closest I could find to  having a standard way of expressing a hex character in an example.  Moreover, it seems to me that none of the suggested changes for what the  canonical form box should contain are better because one always has to read  the notes to realize that what is shown is not the actual canonical form but  rather a notation representative of the canonical form.  This was the point  of the (humorous) hypothetical feedback above.        

      Hi Jonathan,    Right, section 6.6.3.4 is referring to the serialize() function defined in  the XPath transform spec in section 6.6.3.3.  You suggested that I should  take serialize() out because I haven't justified keeping it, yet your  rationale for removing it is based on its existence.    So, I'm deducing that what you mean is that we should keep the description  of how we will serialize a node-set, but don't add it to the function  library.  The justifications I gave for putting it in the function library  (and hence making it available to users) were    1) The method defined by XPath for adding functionality to XPath is adding  to the function library.  The serialize functionality was therefore added as  a function.    2) If a user decides to use XPath string function to modify the result, then  they can do so with an explicit serialize function.    Finally, whether serialize() stays as a function or a description is not a  big deal to me, but I do not believe that your desire to hide serialize()  has anything to do with my question.  Whether implicit or explicit,  serialize will either generate the BOM and XMLDecl or it will not.  It can  only generate the BOM and XMLDecl if it was previously preserved by the  parse. This has nothing to do with whether serialize() is implicit or  explicit.    John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  jboyer@PureEdge.com      -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Jonathan Marsh  Sent: Friday, March 17, 2000 3:43 PM  Subject: RE: Xpath transform changes and questions      > -----Original Message-----  > From: John Boyer [mailto:jboyer@PureEdge.com]  >  > Hi Jonathan,  >  > Perhaps I've missed something huge here.  You said that node-sets are  > automatically serialized.  Could you please point out where  > in the XPath  > spec it says anything about this?    I was referring to the XML Sig spec section 6.6.3.4: "If the result of the  XPath expression is a node-set, then the XPath transform output is the  string result of calling serialize() on the node-set."    So as a user I don't have to call serialize() every time myself, it gets  invoked automatically if my expression returns a nodeset.  Or am I missing  something?    >  > Thanks,  > John Boyer  > Software Development Manager  > PureEdge Solutions, Inc. (formerly UWI.Com)  > jboyer@PureEdge.com  >  >  > -----Original Message-----  > From: Jonathan Marsh [mailto:jmarsh@microsoft.com]  > Sent: Friday, March 17, 2000 3:06 PM  > To: 'John Boyer'; TAMURA Kent; IETF/W3C XML-DSig WG  > Cc: Martin J. Duerst; Christopher R. Maden; James Clark  > Subject: RE: Xpath transform changes and questions  >  >  >  >  > > -----Original Message-----  > > From: John Boyer [mailto:jboyer@PureEdge.com]  > > Sent: Friday, March 17, 2000 12:48 PM  > > To: TAMURA Kent; IETF/W3C XML-DSig WG  > > Cc: Jonathan Marsh; Martin J. Duerst; Christopher R. Maden;  > > James Clark  > > Subject: Xpath transform changes and questions  > >  > >  > > Hi,  > >  > > I have a few concerns that I think can be worked out, so I am  > > requesting  > > feedback on the information below.  If everything works out,  > > then yes, we  > > could remove parse() and exact order.  > >  > > 1) On parse(),  > >  > > I would be in favor of dumping parse() if we can solve ALL of the  > > implementation problems it solves.  It  solved some  > > interesting, but not too  > > important problems for XPath transform users, but it also  > > specified how  > > implementers were to solve certain problems.  > >  > > Please have a closer look at the output expectations of  > > serialize().  The  > > serialize() function cannot operate without several features  > > of parse().  In  > > particular,  > >  > > i) Serialization of the root node requires that we output the  > > byte order  > > mark and xmldecl read by parse() on input.  If parse() is not  > > under our  > > control, we cannot specify that it retains this information.  >  > It seems useful that the BOM and encoding are preserved through  > re-serializing the document.  If these are inputs to the serialization  > mechanism, this is added incentive not to expose the  > serialization mechanism  > as a function.  Otherwise these would have to be passed  > through as variables  > (as you are doing) and users must not forget to use them, and  > must use them  > appropriately (e.g. not change them), if they want correct results.  >  > If serialization is not exposed as a function, but is performed  > automatically, these problems are avoided.  Since it seems that this  > capability already exists (nodesets are automatically  > serialized), at least  > the simple cases are already handled.  Thus an explicit  > serialize() and BOM  > and encoding variables seems to be an advanced feature.  It's  > necessity in  > solving important problems should be weighed against its potential for  > abuse.  I haven't seen you justify your design yet.  Mainly  > I'm curious  > here, not trying to kill serialize().  Of course, if you  > can't justify it,  > drop it.  >  > > This would  > > seem to suggest that root node serialization should result in  > > the empty  > > string, which in turn suggests that serialize should output in UTF-8  > > regardless of the input encoding.  That would be OK with me.  > >  > > ii) Attribute and namespace serialization require a namespace  > > prefix.  Based  > > on a new read of XPath I believe this information must be  > > available, but I  > > want to be sure.  >  > Note in XPath that Namepace Nodes are different in quantity  > and position  > than the attributes used to declare namespaces.  Your current  > serialization  > does not take this into account.  >  > On the other hand, serialization does not necessarily have to  > be limited to  > the XPath Data Model.  This model of a document is used when  > locating the  > nodes, but given a document and a set of locations, your  > serializer can  > describe what to do on it's own terms.  Specifically, any namespace  > attributes in the source are copied through unchanged, and namepace  > attributes are added to elements taken out of scope (e.g.  > parents trimmed)  > to represent the namespace nodes of that element.  Retain the  > prefixes in  > all cases - otherwise QNames in content (e.g. XPaths) will  > break under the  > transformation.  Maybe the experts will have some comments on  > this idea...  >  > > iii) If everything else checks out, we can get rid of exact  > > order and just  > > use lex order provided that lex ordering in UTF-16 results in  > > the same order  > > as lex ordering in UTF-8 (which is Christopher Maden's claim).  > >  > > Also, parse() has an additional feature that would need to be  > > dealt with in  > > some other way:  > >  > > iv) If the parser used to implement parse() is  > > non-validating, then parse()  > > is required to throw an exception if it encounters an  > > external reference  > > that would cause it to interpret the document differently  > > than a validating  > > parser.  This exception is necessary since an unverifiable  > > signature is  > > different than an invalid signature.  >  > I don't see that moving parsing out of parse() changes this.  The  > restriction still applies, and needs to be stated.  An  > implementation would  > either need to initialize their parser to provide such an  > exception during  > parsing, or do some post-parsing pre-filtering checks.  >  > > 2) On eliminating exprBOM and exprEncoding.  > >  > > Sounds fine.  Sounds like any difference of encoding  > between the Xpath  > > expression and the transform input will be handled implicitly  > > by the XPath  > > transform implementation.  > >  > >  > > 3) On automatic serialization,  > >  > > There was some concern that serialization should be automatic  > > ("why call  > > serialize() when that's always what we want to do").  Please  > > see the first  > > paragraph of section 6.6.3.4, which already includes this feature.  >  > The question perhaps is better stated as "why do we need an  > explicit way to  > serialize, instead of always relying on the default that nodesets are  > serialized?  >  > For one thing, this design deeply entwines serialization with  > pruning of the  > tree, which makes it difficult to use off-the-shelf  > serialization components  > in an implementation.  >  > For another, I would not in general expect XPath  > implementations to handle  > large strings such serialize() generates particularly  > efficiently, since  > such strings are at this point pretty rare.  For example, I  > can't really  > imagine returning strings from XPath asynchronously, which I  > would expect  > from a serializing component.  >  > > Thus if we remove parse(), then there is no *need* to start  > > expressions with  > > a function call.  > >  > >  > > 4) On providing an initial namespace context  > >  > > We can provide an initial namespace context as is done in XPointer.  > >  > > I was reviewing how XPath handles namespaces, and realized  > that it is  > > different than what I had previously understood, and it seems  > > broken (so  > > there must be some good reason why it is done the way its  > > done, or maybe I'm  > > just misreading the spec).  > >  > > Section 2.3 says "A QName in the node test is expanded into  > > an expanded-name  > > using the namespace declarations from the expression context.  > > This is the  > > same way expansion is done for element type names in start  > > and end-tags  > > except that the default namespace declared with xmlns is not  > > used: if the  > > QName does not have a prefix, then the namespace URI is null  > > (this is the  > > same way attribute names are expanded). It is an error if the  > > QName has a  > > prefix for which there is no namespace declaration in the expression  > > context".  > >  > > This seems to indicate that the input XML document's  > > namespace declarations  > > are ignored and the expression context's namespace  > > declarations are used  > > solely.  >  > Yes.  Prefixes are scoped, and can change throughout the  > document, so it is  > not possible to use these declarations in a global context  > such as an XPath.  > Also, the namespace rec implies that prefixes can be changed without  > changing the underlying names.  Since XPath has it's own namespace  > declarations, it is unaffected by prefix changes in the  > source document.  >  > > When XPath claims to be XML namespace compliant, I thought  > > that meant it  > > would interpret a node's namespace in the context of the namespace  > > declarations in the document, but that appears not to be  > > true.  To clear  > > this up, suppose I have an element x:E, and the document  > > containing this  > > element associates x with www.w3.org, but the expression  > > context associates  > > x with www.ietf.org, then which value will the  > > namespace-uri() function  > > applied to x:E return?  >  > namespace-uri(x:E) will either return the namespace declared  > in the context  > (www.ietf.org) or an empty string if no element {www.ietf.org  > : E) exists in  > the document, which appears to be the case in your question.  > In short,  > XPath cannot talk about an element without knowing it's full  > name, including  > the namespace uri.  This is an essential component to it's namespace  > awareness.  >  > > If it returns www.ieft.org, then although it seems weird to  > me that we  > > aren't using the namespace declarations in the document, it  > > would at least  > > be good in the sense that it implies XPath implementations have the  > > namespace prefix kicking around for serialize().  > >  > > It also would mean that Jonathan Marsh is correct in  > > requiring an initial  > > namespace context since we could not do ANY namespace  > > comparisons without it  > > (the XPath seems to say that it is an error to use a QName  > > containing a  > > namespace prefix in an expression if that namespace prefix is  > > not defined in  > > the expression context).  >  > Yep.  This really isn't a problem for XPaths appearing in XML  > documents,  > since there is a ready set of namespace declarations (and an  > existing syntax  > for declaring them) to pass into XPath.  We couldn't actually  > make this part  > of XPath because certain uses of XPath do not appear in an  > XML document  > context - namely XPointers embedded in URIs.  >  > I don't veiw this issue as a conceptual mistake, but as a  > cheap fix with  > large author simplicity benefits.  It's virtually free (no new syntax  > needed) - just add one line saying that the namespaces are  > initialized to  > the namespaces in scope on the <xpath> element.  >  > > I would appreciate your feedback, esp. from those who have  > > sent prior emails  > > and therefore seem to be most interested in how this turns  > > out.  If you  > > would please give this some extra priority, I will prepare an  > > alternative  > > document for consideration before or during the meeting in  > Adelaide (I  > > regret that I will not be at that meeting, but I will be at  > > the following  > > one in Victoria ;-).  > >  > > John Boyer  > > Software Development Manager  > > PureEdge Solutions, Inc. (formerly UWI.Com)  > > jboyer@PureEdge.com  > >  > >  > > -----Original Message-----  > > From: w3c-ietf-xmldsig-request@w3.org  > > [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of TAMURA Kent  > > Sent: Friday, March 17, 2000 12:59 AM  > > To: IETF/W3C XML-DSig WG  > > Subject: Re: XSL WG comments on XML Signatures  > >  > >  > >  > > > <John>  > > > XPath filtering will not be substantially rewritten.  Based  > > on Clark's  > > > feedback, we can remove the parse function and instead  > > simply assert that  > > > the transform input is parsed and provided to XPath as a  > > node set.  The  > > > notions of lex and exact order will be removed (since we  > > cannot directly  > > > specify the parse).  > >  > > That's good!  It would be easy to understand, easy to implement,  > > easy to use.  > >  > > --  > > TAMURA Kent @ Tokyo Research Laboratory, IBM  > >  >        

      Hi Petteri,    Yes, my mistake.  I've done that right in the past, but I missed the  ancestor-or-self problem in that particular example.    I will change the example to the much more simple act of omitting the whole  signature element from the DigestValue calculation since it is A) easier,  and B) not harmful.    This will be done in the upcoming version that changes from having a  serialize function to simply describing how to serialize.    John Boyer  Software Development Manager  PureEdge Solutions, Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com      -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Petteri Stenius  Sent: Thursday, April 06, 2000 8:55 AM  Subject: XPath transformation sample        Hello,    If I understand the XPath transformation spec correctly then the sample  XPath expression for SignatureValue and DigestValue exclusion are wrong.    The sample expression returns a node-set that does not contain the  *elements* SignatureValue and DigestValue but does actually contain their  *text* child nodes!      I've attached sample output from our current preliminary XPath  transformation implementation:    - out.xml is a signed XML document I use as input for the XPath  transformation (the SignatureValue is not correct, it's not a signed value  but the plain digest)    - xpath.txt is the output from a separate XPath transformation, with each  node from the node-set serialized on a separate row    The XPath expression is as follows:    /descendant-or-self::node()[  not(self::dsig:SignatureValue and parent::dsig:Signature[@dsig:Id='S1'])  and not(self::dsig:DigestValue and ancestor::*[3 and @dsig:Id='S1'])  ]    A simple working XPath expression would be:    /descendant-or-self::node()[  not(ancestor-or-self::dsig:Signature[@dsig:Id='S1'])  ]    This expression would exclude the entire Signature element.    Petteri    --  Petteri Stenius                            Petteri.Stenius@remtec.fi  Remtec Systems, Ltd.                           Office +358-9-5259240                                                   Fax +358-9-52592411  http://www.remtec.fi/                         Mobile +358-50-5506161        

      I just noticed in the latest XPath serialization and c14n specs, the  namespace axis processing says that the node with prefix 'xml' should be  omitted if it is equal to the value defined in Namespaces in XML.  Actually,  this should say that the namespace node with *local name* of 'xml', which  declares the xml prefix, should be omitted if it is equal to the value  defined in Namespaces in XML [1].  This will be fixed shortly, but it seemed  implementers would want to know this ASAP.    [1] http://www.w3.org/TR/REC-xml-names/    Also, note that if the new definition of c14n works out, then there will be  no need for a separate XPath serialization spec, so that would be removed  from the DSig specification.    John Boyer  Software Development Manager  PureEdge Solutions Inc. (formerly UWI.Com)  Creating Binding E-Commerce  jboyer@PureEdge.com        

      Thanks Kevin.    I had suspected that it is impossible for most XML processors to distinguish  content obtained from external entities due to section 4.4.2 of XML 1.0.    However, I've also given some additional thought to this whole problem of  having c14n change the base URL when it pulls external entities into the  document, and I now feel that I need further convincing that this is a bad  thing.    I think that c14n does the right thing with respect to the XML 1.0 default  base URI.  Moreover, this consideration leads me to believe that  preservation of xml:base in canonicalized documents is faulty.  Obviously  this is not good for XML Base.    It seems to me that relative URIs related to XML syntax seem to get used and  discarded (e.g. SystemLiteral) or replaced by absolute URIs (e.g. XPath  handling of namespaces).  As long as XPath and hence XSLT implementations  respect the XML 1.0 requirement to given a different base URI to content  derived from external entities, then everything should work fine. Based on  Kevin's feedback, I suspect there may be implementations that do not  conform, but at least the specifications are consistent so hopefully the  implementations will be fixed.    As for content that is defined to be a relative URI by an application, the  content is treated like opaque character data.  No generic XML specification  (like C14N or XSLT) can possibly know that the data is supposed to be a  relative URI.  Therefore, if the generic XML application (e.g. C14N) does  something like generate internal content from an external entity reference,  then the fact that the default base URI for that internal content is now the  new document is actually the correct thing to do.  In the case of C14N, if  the output is consumed by the application that can process the canonicalized  XML, the base URI is in fact set properly for that application to be able to  use its relative URIs.    The only place where we run into trouble is with the actual use of xml:base.  If I have an element E containing a relative URI that was formerly obtained  by replacing an external entity reference, and if the replacement occurs  within an element A that has an xml:base, then the xml:base will apply to E.    The xml:base supposedly indicates the original source document.  If it does  not, then it is incorrectly set.  Once the document has been canonicalized,  though, the source document is the canonical form, so the xml:base should be  removed until a permanent home for the canonical form is found.    In short, XML base is used for input, whereas c14n is about output.  Please  give some thought to a counterexample to the idea of omitting xml:base from  the c14n output.    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>          -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Kevin Regan  Sent: Thursday, July 27, 2000 2:31 PM  Subject: RE: DSig comments on XML Base        I have no access to the XML processor.  My library receives DOM Document  and Element objects when creating the signature.  When verifying the  Signature a deligate to the user to find and parse the URI.  I'm not  sure I totally understand the discussion that had taken place, but  I would say that I have no way of distinguishing which parts of  the source came from external entities, and forcing the user to  structure the DOM subtree that I am signing in a particular way is  a big no no.  Currently, the only thing that my library requires  is that the user hand me a DOM Document or Element that has been  parsed with a validating parser (with ignorable whitespace not  included).    --Kevin    -----Original Message-----  From: John Boyer [mailto:jboyer@PureEdge.com]  Sent: Thursday, July 27, 2000 1:59 PM  Subject: RE: DSig comments on XML Base      Hi Jonathan,    OK, that makes some sense.  What you're saying is that we should have  c14n  extend the Xpath data model by adding an xml:base to the top level  element  of external entities.    This must be done by modifying the XML processor that generates the  node-set.  I wonder how easy this is for implementers.    I agree with you that trying to read between the lines on XML 1.0 is a  waste  of time, but I disagree with the implication that this is what I'm  doing.  There are quite specific lines that tell an XML processor developer that  they need not distinguish between content derived within the document  versus  content derived externally.    So, TAMURA Kent, Kevin Regan and others: could you please let us know if  you  can do this?  If so, then I'd like to do what you suggest Jonathan, then  place a note about the residual problem with base URI for top-level PIs.    Thanks,  John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        

      Hi Gregor,    You're absolutely right.  In a burst of youthful exuberance, I wrote that--  before I realized we actually needed to be pushing full node-sets through  the transform sequence.    I have attached a new copy of the "editors' copy" with this fixed.  The  change to base-64 is not large, and it is marked in brown (with strikeout in  grey).    Actually, your email has been doubly helpful in refocusing my attention on  this transform because I think it now addresses something that would've been  an interoperability issue.  As currently specified, it is clear that  comments and processing instructions should also be removed should they  appear.  This imposes some additional work on implementers because you can't  just obtain the stuff between the start and end tags and assume can be  passed directly to a base-64 decoder.  It has to remove all comments and PIs  as well as all start and end tags appearing within the content.    It was my original intention to satisfy what I believe is everyone's  preference that use of the base-64 transform should not REQUIRE a preceding  XPath transform to isolate the text node from its parent element, but the  expression self::text() does a lot more work than handle the base case of  one element with a single text node inside.  On the one hand, the WG may  feel this is too much for this transform, but I think it will be challenging  to  define formally what we mean (i.e. to write an XPath expression that  just shaves the outermost element tags).    Thanks for your careful attention to the proposed changes :).    John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: Gregor Karlinger [mailto:gregor.karlinger@iaik.at]  Sent: Friday, August 25, 2000 7:37 AM  Ed Simon  Subject: AW: Proposed processing model for Reference and Transforms      Hello John,    I think there is a problem with the new text for the base64 transform  (section 6.6.2):    It says: "... If an XPath node-set (or sufficiently functional alternative)  is  given as input, then it is converted to an octet stream by taking the  string-value of the node-set ..."    According to XPath, the text value for an element node is the concatenation  of  all text node values it bears. The text value for a text node is its  character  data. Consider following simple example:      <Element>Text</Element>    If I generate the octet stream according to the new proposal, I think I  would  get:      TextText    since there are two nodes in the input node set, namely the element and the  single text node it bears.    I remember that we had the same problem with the specification of the  serialization  result in Canonical XML. Maybe some additional text should be added here to  make it  clear how the conversion to an octet stream should actually behave.    Regards, Gregor  ---------------------------------------------------------------  Gregor Karlinger  mailto://gregor.karlinger@iaik.at  http://www.iaik.at  Phone +43 316 873 5541  Institute for Applied Information Processing and Communications  Austria  ---------------------------------------------------------------                text/html attachment: Overview.html          

      Hi Paul,    OK, so a given XML application's document that does not use xml:base has  also has the problem that it does not know whether or not the content came  from an external parsed entity.  Point taken.    However, this should not be used as a reason not to fix xml:base.  The  problem I'm raising *IS* with XML Base.  The fact that it also happens  without XML Base does not mean  that the problem isn't with XML Base.    Moreover, the 'Included if validating' terminology does in fact reference by  hypertext link the definition of 'included', so my use of that section's  phrasing is indeed appropriate, and it again brings up the question:    Should we be introducing an attribute beginning with xml: that seems to  violate section 4.4.2 of the XML 1.0 spec?    John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Paul Grosso  Sent: Thursday, July 27, 2000 10:16 AM  Subject: RE: DSig comments on XML Base      At 16:07 2000 07 26 -0700, John Boyer wrote:  >-----Original Message-----  >From: Paul Grosso [mailto:pgrosso@arbortext.com]  >Sent: Wednesday, July 26, 2000 12:29 PM  >  >What does C14N do about relative URIs in external entities in the  >absence of any xml:base  >  ><john>  >c14n is not a big consumer of xml:base per se.  It will use it the same way  >that Xpath will use it, namely for resolving relative URIs in namespace  >declarations, unless the W3C decides  to stick with the Namespaces  >recommendation and patch XPath so that relative URIs are not absolutized  (in  >which case, c14n will not directly use xml:base at all).  ></john>    My point above is that the issue you have isn't with XML Base,  because all XML Base does is give you another way to set the  base URI, but you already have the problem of different base  URIs in different external entities even if XML Base is not  considered.    >  >and how does xml:base cause a problem that  >isn't already there with external entities?  >  ><john>  >The problem isn't with any functionality that c14n needs, but rather with  >the interpretation of a document being different from the canonicalized  >document.  XML Base is (or will be) a recommendation that all XML  >applications should resolve relative URIs *whereever they may be in the  >application content* by using the rules given in xml:base.    No, it is not.  XML Base as a spec merely provides the way for  a resource of MIME type */xml to specify the base URI within  the document content (see RFC 2396 section 5.1.1).  It does NOT  say how to determine what is a relative URI and which relative  URIs should be resolved.  It isn't even normative about how to  resolve a relative URI given one and the base URI--it merely  restates what RFC 2396 says normatively about this.  It is the  job of any spec using XML Base to describe how to determine what  it means to that application for something to be a relative URI  within the application content.  C14N is one such application.    >An application uses an XML processor to obtain XML content, so the  >application is unlikely to know whether the content was the result of an  >external entity or an internal entity because this information is not  >reported to the application.  >  >So, suppose the application has an element E containing char data that the  >application knows is a relative URI.  Further, suppose an ancestor element  >of E contains an xml:base attribute.  How does the application know whether  >or not to apply the xml:base to the relative URI?    If the application is built on the Infoset, then the infoset carries  correct base URI info on each element.    In addition, suppose there are no xml:base attributes at all.  Then  how does your application know which external entity's URI to use  as the base URI to resolve the relative URI?  If you can solve this  issue, you can probably handle xml:base, and if you can't solve this  issue, then you've already got a problem that has nothing to do with  XML Base.    >See below for more...  ></john>  >  >See also some of the following:  >  >http://lists.w3.org/Archives/Public/www-xml-linking-comments/2000JulSep/005  6  >http://lists.w3.org/Archives/Public/www-xml-linking-comments/2000JulSep/004  7  >http://lists.w3.org/Archives/Public/www-xml-linking-comments/2000JulSep/006  2  >  >and the rest of the many messages in this archive on this issue.  >  ><john>  >In these emails, you rationalize the fact that xml:base should not apply to  >external entities by using the following citation from XML 1.0 from section  >4.2.2 [1]:    Actually, this is not a rationale for what xml:base should do, it is  quoted in support of the position that relative URIs in external  entities--having nothing to do with XML Base--should be resolved  relative to the base URI of the external entity in which they appear.    >"Unless otherwise provided by information outside the scope of this  >specification (e.g. a special XML element type defined by a particular DTD,  >or a processing instruction defined by a particular application  >specification), relative URIs are relative to the location of the resource  >within which the entity declaration occurs"  >  >[1] http://www.w3.org/TR/REC-xml#sec-external-ent  >  >I have several comments about this.  >  >Firstly, the citation justifies a *default* base URI, so there is no  >justification for explicitly cutting off xml:base, which is used to  override  >the default established by the citation.    You are using different terminology than RFC 2396 which talks of  "Establishing a Base URI" (section 5.1) and then gives a four  level way to determine the base URI.  XML Base is precisely the  first level way (5.1.1. Base URI within Document Content) out of  those four ways to determine the base URI, whereas the URI of the  external entity (see RFC 2396 5.1.3. Base URI from the Retrieval URI)  is the third level way.  (Note that the term "entity" in Section 5.1.2  Base URI from the Encapsulating Entity of RFC 2396 is used in the  MIME encapsulation sense, not the XML external parsed entity sense.)    >Secondly, the citation explicitly allows for the possibility that overrides  >to this default behavior are possible.  Therefore, the citation  >substantiates the possibility that xml:base could be applied to descendant  >content derived from external entities.  I do not see the citation  >justifying or mandating that xml:base settings should not apply to content  >derived from external entities.  >  >Thirdly, I provided a compelling citation from the XML 1.0 spec that seems  >to override your interpretation of [1].  The following can be read at [2]:  >  >[2] http://www.w3.org/TR/REC-xml#included  >  >"4.4.2 Included  >  >An entity is included when its replacement text is retrieved and processed,  >in place of the reference itself, as though it were part of the document at  >the location the reference was recognized. The replacement text may contain  >both character data and (except for parameter entities) markup, which must  >be recognized in the usual way, except that the replacement text of  entities  >used to escape markup delimiters (the entities amp, lt, gt, apos, quot) is  >always treated as data. (The string "AT&T;" expands to "AT&T;" and the  >remaining ampersand is not recognized as an entity-reference delimiter.) A  >character reference is included when the indicated character is processed  in  >place of the reference itself."    I'm not trying to be a Philadelphia lawyer here--no question that the  XML 1.0 spec is not clear on this issue.  The problem is that 4.2.2  "Included" (if you look at the preceding table) is really only used  for internal entities; the table entry for external entities links  to 4.2.3 "Included If Validating" which doesn't have any wording that  is really helpful for our debate.    >The key phrase is *as though it were part of the document at the location  >the reference was recognized*.    And that is true for internal entities.    >The issue I'm raising is that applications  >do not know that content was derived by internal or external means because  >the content appears as though it were part of the document.  Therefore,  >application cannot use of xml:base when its setting is given by an ancestor  >element.    But that is the tail wagging the dog.  Applications should be built  on the Infoset (or equivalent model), and the infoset should provide  the necessary base URI info for whatever needs the application may  have.  And this is necessary even in the absence of XML Base.    paul        

      Hi Paul,    Yes, my prior email incorrectly used BMP to refer to the 17 encoding planes  available to UTF-16.  This occured while skimming over UTF-7, which I  assumed was just another way of doing UTF-8 but in fact seems only capable  of encoding the BMP.    So, in any prior email, my statements about the BMP should actually have  been directed to "the set of 17 character planes available to UTF-16".  In  my mind, it would seem that the BMP is misnamed since we seem to need a lot  of stuff outside of it to meet the basic language needs of earthlings.  Perhaps UTF-16 should become the Basic Multilingual "3-space".  :)    Anyway, Jeff's point about UCS-2 != Unicode has now hit home thanks to some  of the examples in the UTF-8 spec.  These examples clearly show triplets of  UCS-2 values being used to form a single character, which does not appear to  be permissible under UTF-16.  Since the Unicode manual is quite clear on the  equivalence between Unicode and UTF-16 (p. 19), this would mean that UCS-2  != Unicode.    So it would seem that we need to include UCS-2 in the list of things that  should not have NFC applied.    This leads us to your suggestion, which is to say "REQUIRED to use  Normalization Form C [NFC] when converting an XML document to the UCS  character domain from a non-UCS encoding".    Based on what I've read over the last two days, this does not work for me.  The XML standard makes it clear that you can actually encode a document in  native UCS-4.  You do not have to use UTF-8 or UTF-16.  So, the statement  you suggest would be interpreted as requiring NFC on UTF-8 and UTF-16  encodings, since the UCS encoding is something different.    Moreover, taking into account your suggestion to pretend UTF-7 never existed  combined with Tom's suggestion that we should explicitly say what Unicode  means, the following is probably the best so far:    "REQUIRED to use Normalization Form C [NFC] when converting an XML document  to the UCS character domain from an encoding other than a UCS encoding,  UTF-8, UTF-16, UTF-16BE, and UTF-16BE".    I said 'so far' because I was interested in your statements about 'local  encodings' that are for private use in planes 15 and 16.  Would you mind  telling us a little more about that?  I think we're OK from a signature  mechanics standpoint, but I just want to be sure that it is safe to push to  the application the responsibility for capturing the context of private  regions.    Thanks,  John Boyer  Team Leader, Software Development  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        >   While nothing currently exists out there,    This is also not true: there are private use areas allocated in  planes 15 and 16.    >  I think ISO/IEC 10646-2 is supposed to change that fact, so it  >would be helpful for us to change our sentence about the conditions  >under which we expect the application of Normalization Form C to  >occur.    This all started with a statement:    "REQUIRED to use Normalization Form C [NFC] when converting an XML  document to the UCS character domain from a non-Unicode encoding".    This was a bit of shorthand on the part of whoever wrote it. Simply  change "a non-Unicode encoding" to "any non-UCS encoding" or "any  local encoding".      >In conclusion, it would be helpful to know whether anyone thinks  >UTF-7  >(<http://www.ietf.org/rfc/rfc2152.txt>http://www.ietf.org/rfc/rfc2152.txt)  >should be included since it does claim to be a format for encoding  >Unicode characters.    Oh God no. UTF-7 was a mistake and has, thankfully, never been widely  adopted. The only real use of UTF-7 is in IMAP and everyone there  deeply regrets it. Pretend that you never heard of UTF-7.    --Paul Hoffman, Director  --Internet Mail Consortium        

      Hi Gregor,    Thanks for writing.  Please respond to this letter even if you agree with  its content since Joseph has asked that we document positive acknowledgement  of the resolution of issues raised by the WG (esp. if we intend the  resolution to be not to change anything).    First, note that there is no requirement to use XPath to build the required  part of C14N.  One's implementation must only behave in the same way, which  includes replacing the CDATA sections with their character content.  The  section about text nodes that you cited [XPath, Section 5.7] mentions CDATA  sections in the discussion of text nodes, but it is in order to say  *exactly* the same thing we are saying:    "Character data is grouped into text nodes. As much character data as  possible is grouped into each text node: a text node never has an  immediately following or preceding sibling that is a text node."    "Each character within a CDATA section is treated as character data."    I believe it is best to make it clear up front that CDATA sections will be  replaced rather than burying it in text node processing because it is easier  for people who don't implement with XPath to see what must be done to make a  logically equivalent structure appropriate to their purposes.    My opinion is that the discussion of the processing model should be based on  the data model, unencumbered by details of how to create the data model.  To  me, this is esp. important given that some may choose to actually implement  based on XPath (e.g. in order to perform document subsetting), and such  people want to read the processing model to figure out how to process the  data structure they have.    As to your point about whether this concatenation is a common feature of XML  processors, hopefully it is clear that it doesn't matter.  Concatenation of  successive blocks of character data is a trivial task.  Implementers can  either choose to do it in their data structure, or they can acknowledge that  since they are consecutive in the input, simply outputing the text as  encountered suffices.    It is important to note that while many processors may report separate  character blocks for CDATA sections, they are not required (and some do not)  distinguish that the text came from a CDATA section because:    "CDATA sections may occur anywhere character data may occur; they are used  to escape blocks of text containing characters which would otherwise be  recognized as markup."  [XML, Section 2.7]    (In other words, CDATA sections are a simple escaping mechanism).    [XML] http://www.w3.org/TR/1998/REC-xml-1998021  [XPath] http://www.w3.org/TR/1999/REC-xpath-19991116    John Boyer  Development Team Leader,  Distributed Processing and XML  PureEdge Solutions Inc.  Creating Binding E-Commerce  v: 250-479-8334, ext. 143  f: 250-479-3772  1-888-517-2675   http://www.PureEdge.com <http://www.pureedge.com/>        -----Original Message-----  From: w3c-ietf-xmldsig-request@w3.org  [mailto:w3c-ietf-xmldsig-request@w3.org]On Behalf Of Gregor Karlinger  Sent: Wednesday, September 13, 2000 5:58 AM  Subject: Canonical XML Comment (CDATA)      Hi John,    In section 2.1 there are listed the requirements for an XML  processor to be used to create a node set:     3. replace CDATA sections with their character content    I am not sure, but I don't think this is standard behaviour of  the widespread XML parser implementations.    Wouldn't it be better to skip this requirement and instead  add a sencence to the explanation how to serialize Text nodes  in section 2.2?    The XPath data model also mentions CDATA sections in the  explanation of the data model [1].    [1] http://www.w3.org/TR/xpath#section-Text-Nodes    Regards, Gregor  ---------------------------------------------------------------  Gregor Karlinger  mailto://gregor.karlinger@iaik.at  http://www.iaik.at  Phone +43 316 873 5541  Institute for Applied Information Processing and Communications  Austria  ---------------------------------------------------------------        

