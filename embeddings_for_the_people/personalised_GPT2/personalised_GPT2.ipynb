{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model, GPT2LMHeadModel\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-2 Usage Notes\n",
    "\n",
    " - Use `past` in GPT-2 computations: <br> `past` is the ouput of a GPT-2 `model()` call and also its input; put `past` of previous output into next input to save computations\n",
    " \n",
    " - logit(p) = log(p/1-p) -> sigmoid(logit(p)) = p <br> can just use softmax (equiv to sigmoid for multivariate) and log on top\n",
    " \n",
    " - use prob_tensor.gather(dim, index_tensor) to extract probabilities of occurred words from distributions (tensors must be same dimensionality!) <br> => seems like ouput of GPT-2 is already words' probs extracted (but then do sigmoid instead of softmax)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0226 17:15:28.877851 140415505782592 configuration_utils.py:254] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /home/valentin/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.699bbd1c449e9861456f359d6daa51bd523ac085b4b531ab0aad5a55d091e942\n",
      "I0226 17:15:28.880422 140415505782592 configuration_utils.py:290] Model config GPT2Config {\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"do_sample\": false,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"finetuning_task\": null,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "I0226 17:15:29.333458 140415505782592 modeling_utils.py:458] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at /home/valentin/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# remove when training\n",
    "# model.eval()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Tokenize and Convert to IDs with GPT-2 Tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../w3c-emails/emails.pkl\", \"rb\") as handle:\n",
    "#     emails = pickle.load(handle)\n",
    "    mail_bodies_raw = [e.body_raw for e in pickle.load(handle)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "with torch.no_grad():\n",
    "    ids = [torch.tensor(tokenizer.encode(body_str, add_special_tokens=True)) \n",
    "           for body_str in tqdm(mail_bodies_raw)]\n",
    "    \n",
    "    with open(\"GPT2_email_token_ids.pkl\", \"wb\") as handle:\n",
    "        pickle.dump(ids, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "(start from here once tokenisation done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"GPT2_email_token_ids.pkl\", \"rb\") as handle:\n",
    "    ids = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_up(mail_tensor, n=511, k=20):\n",
    "    if mail_tensor.shape[0] <= n:\n",
    "        return (mail_tensor, )\n",
    "    \n",
    "    unfolded = mail_tensor.unfold(0, n, n-k)\n",
    "    covered = unfolded.shape[0]-unfolded.shape[1]\n",
    "   \n",
    "    return tuple(v for v in unfolded) + (mail_tensor[covered:],)\n",
    "\n",
    "\n",
    "# same as \n",
    "def split_crude(mail_tensor, n=1024):\n",
    "    if mail_tensor.shape[0] <= n:\n",
    "        return mail_tensor.unsqueeze(0)\n",
    "    \n",
    "    split_up = mail_tensor.split(n)\n",
    "    if split_up[-1].shape != split_up[0].shape:\n",
    "        return torch.stack(split_up[:-1])\n",
    "    return torch.stack(split_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove when training\n",
    "with torch.no_grad():\n",
    "    for mail_token_ids in ids[:50]:\n",
    "        print(mail_token_ids.shape)\n",
    "        token_batch = split_crude(mail_token_ids)\n",
    "        print(token_batch.shape)\n",
    "        \n",
    "        loss, logits, _ = model(token_batch, labels=token_batch)#, past=past)\n",
    "        probs = logits.softmax(-1)\n",
    "        word_probs = probs.gather(-1, token_batch.unsqueeze(-1))\n",
    "        email_prob = word_probs.log2().sum()\n",
    "\n",
    "        \n",
    "        print(\"------\")\n",
    "        print(email_prob)\n",
    "        print(word_probs.squeeze(-1)[0, :10])       \n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
    "# loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "opt = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train and evaluate using tf.keras.Model.fit()\n",
    "history = model.fit(train_dataset, epochs=2, steps_per_epoch=115,\n",
    "                    validation_data=valid_dataset, validation_steps=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = split_crude(ids[0])\n",
    "model(first)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## FOR TRAINING USE\n",
    "\n",
    "`python3 run_language_modeling.py --output_dir=output --model_type=gpt2 --model_name_or_path=gpt2 --do_train --train_data_file=train_file --line_by_line`\n",
    "\n",
    " - `--line_by_line` indicates one sample per line to spearate e-mails, `\"\\n\"` inside e-mails converted to `\" \"`\n",
    " - perhaps use `--block_size=128/256/512` (rather than GPT-2's default of 1024) -> loose fewer tokens at the ends of long emails\n",
    " - \n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain-Adapt GPT-2 to W3C E-mails\n",
    "\n",
    " - pre-train an instance of GPT-2 on entire (subset of) w3c-email corpus <br>\n",
    "   -> will reduce perplexity and thus increase sensitivity of LMs\n",
    " - use this LM as starting point to train personalised LMs \n",
    " - also reserve a test set? -> i.e. some e-mails which no custom-trained LM has seen before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PREPARING TRAINING\n",
    "\n",
    " - [x] get authors with certain ranks according to their frequency of authoring\n",
    " - [ ] collect e-mails from authors and put into their own files\n",
    " - [ ] split train and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def senders_by_ranks(emails, ls_of_ranks):\n",
    "    sndr_cnts = Counter(e.sender for e in emails)\n",
    "    ranks_sndr = {r:s for r, (s, c) in enumerate(sndr_cnts.most_common())}\n",
    "    \n",
    "    for r in ls_of_ranks:\n",
    "        cur_s = ranks_sndr[r]\n",
    "        yield [m for m in emails if m.sender == cur_s]\n",
    "\n",
    "def emails_to_dataset():\n",
    "    ranks = [2**i for i in range(10)]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../w3c-emails/emails.pkl\", \"rb\") as handle:\n",
    "    emails = pickle.load(handle)\n",
    "#     mail_bodies_raw = [e.body_raw for e in pickle.load(handle)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(jonathan chetwynd <jonathan@signbrowser.free-online.co.uk>,\n",
       " '      I completely agree with your statement 1 concerning the relation of graphics  in a picture being of greater significance than the icons of which it is  built.    Giotto is said to be one of the first to illustrate this point successfully  in a fresco in the Arena chapel at Padua (1305-8).  Two methods are tried.  Text is used to support individual icons, alternatively an allegorical  picture is used.  Both systems work.    One of my present concerns is how (narrative) turning points are structured  on the www. Anyone got any ideas?      jay@peepo.com    Please send us links to your favourite websites.  Our site www.peepo.com is a drive thru.  When you see a link of interest, click on it.  Move the mouse to slow down.  It is a graphical aid to browsing the www.  We value your comments.        ')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails[0].sender, emails[0].body_raw.replace(\"\\n\", \"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18886 143963\n",
      "[1, 2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
      "[1659, 1594, 1228, 1074, 716, 551, 337, 179, 88, 41]\n",
      "[0.0115, 0.0111, 0.0085, 0.0075, 0.005, 0.0038, 0.0023, 0.0012, 0.0006, 0.0003]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'senders_by_ranks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2f12f0bbea28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mless_mails\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msenders_by_ranks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memails\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'senders_by_ranks' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sndr_cnts = Counter(e.sender for e in emails)\n",
    "\n",
    "rs, cs = list(zip(*[(r, c) for r, (_, c) in enumerate(sndr_cnts.most_common())]))\n",
    "\n",
    "plt.figure(1, )\n",
    "plt.subplot(221)\n",
    "plt.loglog(rs, cs, '.')\n",
    "\n",
    "rng = [2**i for i in range(10)]\n",
    "rng_cs = [cs[i] for i in rng]\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.loglog(rng, rng_cs, '.')\n",
    "\n",
    "print(len(sndr_cnts), len(emails))\n",
    "print(rng, rng_cs, [round(c/len(emails), 4) for c in rng_cs], sep=\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "less_mails = list(senders_by_ranks(emails, rng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051867493731028114\n",
      "0.07836735827955794\n"
     ]
    }
   ],
   "source": [
    "len(less_mails)\n",
    "\n",
    "print(len([m for s_ls in less_mails for m in s_ls])/len(emails))\n",
    "\n",
    "\n",
    "less2 = list(senders_by_ranks(emails, range(1, 10)))\n",
    "print(len([m for s_ls in less2 for m in s_ls])/len(emails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sndr_body_tups = [(m_ls[0].sender,[m.body_raw for m in m_ls]) for m_ls in less_mails]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
