{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from declarations_new.ledger import Universe\n",
    "from declarations_new.entities import EntityUniverse, EntityInstance\n",
    "from declarations_new.corpus import EmailCorpus, Conversation\n",
    "from declarations_new.emails import Email\n",
    "from declarations_new.topics import TopicModel, TopicInstance\n",
    "from declarations_new.entity_linking import EntityLinker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Conversation objects and construct Triples\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1888/1888 [00:08<00:00, 214.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1888 ,  6260\n",
      "2014-08-18 23:39:41-04:00 ,  2020-05-13 19:53:51+03:00\n"
     ]
    }
   ],
   "source": [
    "mailinglist = \"public-credentials\" # \"ietf-http-wg\"\n",
    "\n",
    "with open(f\"email_data/{mailinglist}/all.json\") as handle:\n",
    "    mail_dicts = json.load(handle)\n",
    "\n",
    "convos = [(subj_str, mail_ls) for period, subj_d in mail_dicts.items() \n",
    "                for subj_str, mail_ls in subj_d.items()]\n",
    "\n",
    "def to_conv(tup):\n",
    "    return Conversation.from_email_dicts(*tup)\n",
    "\n",
    "conversations = list(tqdm(map(to_conv, convos), total=len(convos)))\n",
    "\n",
    "corpus = EmailCorpus.from_conversations(conversations, vectorise_default=True)\n",
    "print(len(corpus), \", \", corpus.n_emails)\n",
    "print(corpus.start_time, \", \", corpus.end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = TopicModel(corpus, 20, max_iter=1)\n",
    "\n",
    "lda.assign_topics_to_emails()\n",
    "lda.assign_topics_to_conversations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = lda.determine_n_components(range(10, 30, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(n, m.bound_) for n, m in models.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Conversations and Emails assigned to each Topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_per_topic = {t: [] for t in lda.topics}\n",
    "convos_per_topic = {t: [] for t in lda.topics}\n",
    "\n",
    "for k, v_ls in Universe.evidenced_by.items():\n",
    "    if isinstance(k, TopicInstance):\n",
    "        for v in v_ls:\n",
    "            if isinstance(v, Conversation):\n",
    "                convos_per_topic[k.topic].append(v)\n",
    "            elif isinstance(v, Email):\n",
    "                emails_per_topic[k.topic].append(v)\n",
    "            else:\n",
    "                raise ValueError(\"Neither Conversation or Email!\")\n",
    "\n",
    "print(\"Conversations per Topic:\\n\\t\",\n",
    "     [(t.index, len(ls)) for t, ls in convos_per_topic.items()], \"\\n\")\n",
    "print(\"Emails per Topic:\\n\\t\",\n",
    "     [(t.index, len(ls)) for t, ls in emails_per_topic.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Recognition and Linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linker = EntityLinker()\n",
    "\n",
    "linker.to_WikiData_entities(list(EntityUniverse.entities.values())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linker.enrich_email_bodies(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 10\n",
    "corpus[j][0].body.entities#[0].entity.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Universe.evidenced_by), len(Universe.mentioned_in), len(EntityUniverse.entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[e for e in EntityUniverse.entities.values() if type(e) == EntityInstance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[e for e in EntityUniverse.entities.values() if e.instance_score is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter([type(e).__name__ for e in EntityUniverse.entities.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neo4j\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from neo4j_defs2 import *\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"pwd\"), encrypted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear(tx):\n",
    "    tx.run(\"\"\"MATCH (x)\n",
    "            DETACH DELETE x\"\"\")\n",
    "\n",
    "    \n",
    "with driver.session() as session:\n",
    "    session.write_transaction(clear)\n",
    "    for conv in tqdm(corpus[:50]):\n",
    "        session.write_transaction(put_conversation, conv)\n",
    "        for email in conv:\n",
    "            session.write_transaction(put_email, email)\n",
    "            \n",
    "\n",
    "    for entity in tqdm(EntityUniverse.entities):\n",
    "        session.write_transaction(put_entity, entity, entity.__class__.__name__)\n",
    "            \n",
    "\n",
    "# with driver.session() as session:\n",
    "#     session.write_transaction(clear)\n",
    "#     for c in tqdm(convos[:100]):\n",
    "#         session.write_transaction(add_conversation, c)\n",
    "#         session.write_transaction(add_documents, c)\n",
    "#         session.write_transaction(add_mentions, c)\n",
    "            \n",
    "#         for email in c:\n",
    "#             session.write_transaction(add_person,email.sender)\n",
    "#             session.write_transaction(add_person,email.receiver)\n",
    "#             session.write_transaction(add_talked_to,email.sender,email.receiver)\n",
    "            \n",
    "# #             session.write_transaction(add_named_entities, email)\n",
    "            \n",
    "#         for i in c.interlocutors:\n",
    "#             session.write_transaction(connect_conversation, i.name, c)\n",
    "            \n",
    "            \n",
    "#     sorted_convos = sorted(convos, key=lambda (c1, c2): c1 <)\n",
    "#     pairs = zip(sorted_convos[:-1], sorted_convos[1:])\n",
    "    \n",
    "#     for c1, c2 in pairs:\n",
    "#         session.write_transaction(add_earlier_than, email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Identify Quoted Texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance as levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e in convos[1]:\n",
    "    print(e.body)\n",
    "    print(\"____________________\\n\\n\\n\\n\\n____________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "latest = convos[i][-1]\n",
    "\n",
    "for l in latest.body.split(\"\\n\"):\n",
    "    if not l.strip():\n",
    "        continue\n",
    "    print(\":\", l)\n",
    "    \n",
    "    for e_ in convos[1][:-1]:\n",
    "        quoted = [l_ for l_ in e_.body.split(\"\\n\") if levenshtein(l, l_) < (min(len(l), len(l_))/2)]\n",
    "        \n",
    "        print(quoted)\n",
    "        \n",
    "    print(\"\\n---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in convos[1]:\n",
    "    print(e.sender, e.receiver)\n",
    "    print(e.body)\n",
    "    \n",
    "    print(\"__________________\\n\\n\\n__________________\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
